wandb: Currently logged in as: r-v-doorn1 (royvdoorn). Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.
  warnings.warn(
Loss of batch at epoch 1 : 0.9111835360527039
Loss of batch at epoch 1 : 0.9068112373352051
Loss of batch at epoch 1 : 0.9030163884162903
Loss of batch at epoch 1 : 0.8958898782730103
Loss of batch at epoch 1 : 0.894436776638031
Loss of batch at epoch 1 : 0.8877887725830078
Loss of batch at epoch 1 : 0.8872388005256653
Loss of batch at epoch 1 : 0.886553168296814
Loss of batch at epoch 1 : 0.8862224221229553
Loss of batch at epoch 1 : 0.8918232917785645
Loss of batch at epoch 1 : 0.8864729404449463
Loss of batch at epoch 1 : 0.8856985569000244
Loss of batch at epoch 1 : 0.8779792785644531
Loss of batch at epoch 1 : 0.876133918762207
Loss of batch at epoch 1 : 0.8814627528190613
Loss of batch at epoch 1 : 0.8829208612442017
Loss of batch at epoch 1 : 0.884585976600647
Loss of batch at epoch 1 : 0.8801713585853577
Loss of batch at epoch 1 : 0.8822962045669556
Loss of batch at epoch 1 : 0.8818116188049316
Loss of batch at epoch 1 : 0.8761404156684875
Loss of batch at epoch 1 : 0.8779752850532532
Loss of batch at epoch 1 : 0.8740760684013367
Loss of batch at epoch 1 : 0.8752541542053223
Loss of batch at epoch 1 : 0.8765330910682678
Loss of batch at epoch 1 : 0.8743550777435303
Loss of batch at epoch 1 : 0.8848913908004761
Loss of batch at epoch 1 : 0.8766112923622131
Loss of batch at epoch 1 : 0.8772892355918884
Loss of batch at epoch 1 : 0.8744833469390869
Loss of batch at epoch 1 : 0.8767790794372559
Loss of batch at epoch 1 : 0.876419186592102
Loss of batch at epoch 1 : 0.8749038577079773
Loss of batch at epoch 1 : 0.8786328434944153
Loss of batch at epoch 1 : 0.8665351867675781
Loss of batch at epoch 1 : 0.8800380229949951
Loss of batch at epoch 1 : 0.8741573691368103
Loss of batch at epoch 1 : 0.8793919086456299
Loss of batch at epoch 1 : 0.8796542882919312
Loss of batch at epoch 1 : 0.8728972673416138
Loss of batch at epoch 1 : 0.8778542876243591
Loss of batch at epoch 1 : 0.8788194060325623
Loss of batch at epoch 1 : 0.8815935850143433
Loss of batch at epoch 1 : 0.8761193752288818
Loss of batch at epoch 1 : 0.8757047653198242
Loss of batch at epoch 1 : 0.8737443089485168
Loss of batch at epoch 1 : 0.8711475133895874
Loss of batch at epoch 1 : 0.8724454045295715
Loss of batch at epoch 1 : 0.8716371059417725
Loss of batch at epoch 1 : 0.8800225257873535
Loss of batch at epoch 1 : 0.8791666626930237
Loss of batch at epoch 1 : 0.873852014541626
Loss of batch at epoch 1 : 0.8752074837684631
Loss of batch at epoch 1 : 0.8751037120819092
Loss of batch at epoch 1 : 0.8693315386772156
Loss of batch at epoch 1 : 0.8803611397743225
Loss of batch at epoch 1 : 0.8724527359008789
Loss of batch at epoch 1 : 0.8688658475875854
Loss of batch at epoch 1 : 0.8700448274612427
Loss of batch at epoch 1 : 0.8844937086105347
Loss of batch at epoch 1 : 0.8728582859039307
Loss of batch at epoch 1 : 0.8747137784957886
Loss of batch at epoch 1 : 0.8662601709365845
Loss of batch at epoch 1 : 0.8703868389129639
Loss of batch at epoch 1 : 0.8700457215309143
Loss of batch at epoch 1 : 0.8712170124053955
Loss of batch at epoch 1 : 0.873554527759552
Loss of batch at epoch 1 : 0.8673350214958191
Loss of batch at epoch 1 : 0.874663770198822
Loss of batch at epoch 1 : 0.8712069988250732
Loss of batch at epoch 1 : 0.8719483613967896
Loss of batch at epoch 1 : 0.8704351186752319
Loss of batch at epoch 1 : 0.8732759356498718
Loss of batch at epoch 1 : 0.8737171292304993
Loss of batch at epoch 1 : 0.8764826059341431
Loss of batch at epoch 1 : 0.8723272085189819
Loss of batch at epoch 1 : 0.8749343752861023
Loss of batch at epoch 1 : 0.8697063326835632
Loss of batch at epoch 1 : 0.8730095028877258
Loss of batch at epoch 1 : 0.8772643208503723
Loss of batch at epoch 1 : 0.8744809627532959
Loss of batch at epoch 1 : 0.8742972016334534
Loss of batch at epoch 1 : 0.8662649989128113
Loss of batch at epoch 1 : 0.8750781416893005
Loss of batch at epoch 1 : 0.867632269859314
Loss of batch at epoch 1 : 0.8721314668655396
Loss of batch at epoch 1 : 0.8712774515151978
Loss of batch at epoch 1 : 0.8666766881942749
Loss of batch at epoch 1 : 0.871241569519043
Loss of batch at epoch 1 : 0.8724433183670044
Loss of batch at epoch 1 : 0.8729875087738037
Loss of batch at epoch 1 : 0.8737577795982361
Loss of batch at epoch 1 : 0.8709666728973389
Loss of batch at epoch 1 : 0.8691232800483704
Loss of batch at epoch 1 : 0.8676819205284119
Loss of batch at epoch 1 : 0.8720541000366211
Loss of batch at epoch 1 : 0.87424635887146
Loss of batch at epoch 1 : 0.8763911128044128
Loss of batch at epoch 1 : 0.8755611181259155
Loss of batch at epoch 1 : 0.8738349080085754
Loss of batch at epoch 1 : 0.8747507929801941
Loss of batch at epoch 1 : 0.8686836957931519
Loss of batch at epoch 1 : 0.8731082081794739
Loss of batch at epoch 1 : 0.8698922395706177
Loss of batch at epoch 1 : 0.8758019804954529
Loss of batch at epoch 1 : 0.8779852986335754
Loss of batch at epoch 1 : 0.8714463710784912
Loss of batch at epoch 1 : 0.8761236071586609
[2024-03-09 11:34:07,175] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -9) local_rank: 0 (pid: 3591632) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
========================================================
train.py FAILED
--------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
--------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-03-09_11:34:07
  host      : gcn29.local.snellius.surf.nl
  rank      : 0 (local_rank: 0)
  exitcode  : -9 (pid: 3591632)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 3591632
========================================================
slurmstepd: error: Detected 1 oom_kill event in StepId=5492431.0. Some of the step tasks have been OOM Killed.
srun: error: gcn29: task 0: Out Of Memory
srun: Terminating StepId=5492431.0

JOB STATISTICS
==============
Job ID: 5492431
Cluster: snellius
User/Group: scur0756/scur0756
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 05:03:36 core-walltime
Job Wall-clock time: 00:16:52
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
