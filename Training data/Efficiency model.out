wandb: Currently logged in as: r-v-doorn1 (royvdoorn). Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.
  warnings.warn(
Loss of batch at epoch 1 : 3.8352341651916504
Loss of batch at epoch 1 : 3.652486562728882
Loss of batch at epoch 1 : 3.5127131938934326
Loss of batch at epoch 1 : 3.4496607780456543
Loss of batch at epoch 1 : 3.334533452987671
Loss of batch at epoch 1 : 3.2961924076080322
Loss of batch at epoch 1 : 3.208242177963257
Loss of batch at epoch 1 : 3.2208118438720703
Loss of batch at epoch 1 : 3.0747923851013184
Loss of batch at epoch 1 : 2.9765000343322754
Loss of batch at epoch 1 : 2.9009850025177
Loss of batch at epoch 1 : 2.8985564708709717
Loss of batch at epoch 1 : 2.9017765522003174
Loss of batch at epoch 1 : 2.8584823608398438
Loss of batch at epoch 1 : 2.7427237033843994
Loss of batch at epoch 1 : 2.6481881141662598
Loss of batch at epoch 1 : 2.643663167953491
Loss of batch at epoch 1 : 2.6709868907928467
Loss of batch at epoch 1 : 2.62113356590271
Loss of batch at epoch 1 : 2.56013822555542
Loss of batch at epoch 1 : 2.5063908100128174
Loss of batch at epoch 1 : 2.4571645259857178
Loss of batch at epoch 1 : 2.4777426719665527
Loss of batch at epoch 1 : 2.426745891571045
Loss of batch at epoch 1 : 2.37768816947937
Loss of batch at epoch 1 : 2.3805360794067383
Loss of batch at epoch 1 : 2.29392671585083
Loss of batch at epoch 1 : 2.309189796447754
Loss of batch at epoch 1 : 2.3719022274017334
Loss of batch at epoch 1 : 2.216916799545288
Loss of batch at epoch 1 : 2.2830617427825928
Loss of batch at epoch 1 : 2.2293765544891357
Loss of batch at epoch 1 : 2.2278614044189453
Loss of batch at epoch 1 : 2.142946720123291
Loss of batch at epoch 1 : 2.0555570125579834
Loss of batch at epoch 1 : 2.1322338581085205
Loss of batch at epoch 1 : 2.1228954792022705
Loss of batch at epoch 1 : 2.06563138961792
Loss of batch at epoch 1 : 2.051523208618164
Loss of batch at epoch 1 : 2.0722036361694336
Loss of batch at epoch 1 : 2.0760996341705322
Loss of batch at epoch 1 : 2.156039237976074
Loss of batch at epoch 1 : 2.0688984394073486
Loss of batch at epoch 1 : 2.076228141784668
Loss of batch at epoch 1 : 1.9014025926589966
Loss of batch at epoch 1 : 1.9174745082855225
Loss of batch at epoch 1 : 2.085895538330078
Loss of batch at epoch 1 : 1.9376641511917114
Loss of batch at epoch 1 : 1.894873023033142
Loss of batch at epoch 1 : 1.896385908126831
Loss of batch at epoch 1 : 1.8853439092636108
Loss of batch at epoch 1 : 1.8805619478225708
Loss of batch at epoch 1 : 1.8566052913665771
Loss of batch at epoch 1 : 1.910226583480835
Average train loss of epoch 1: 0.04994510482548777
Average validation loss of epoch 1: 0.03809230496184995
Loss of batch at epoch 2 : 1.7372715473175049
Loss of batch at epoch 2 : 1.8283706903457642
Loss of batch at epoch 2 : 1.8524636030197144
Loss of batch at epoch 2 : 1.8734465837478638
Loss of batch at epoch 2 : 1.8260080814361572
Loss of batch at epoch 2 : 1.8781965970993042
Loss of batch at epoch 2 : 1.8267868757247925
Loss of batch at epoch 2 : 1.7536747455596924
Loss of batch at epoch 2 : 1.6703773736953735
Loss of batch at epoch 2 : 1.732545018196106
Loss of batch at epoch 2 : 1.6911283731460571
Loss of batch at epoch 2 : 1.7860058546066284
Loss of batch at epoch 2 : 1.7248972654342651
Loss of batch at epoch 2 : 1.84951913356781
Loss of batch at epoch 2 : 1.719420313835144
Loss of batch at epoch 2 : 1.7275291681289673
Loss of batch at epoch 2 : 1.715399146080017
Loss of batch at epoch 2 : 1.8051525354385376
Loss of batch at epoch 2 : 1.7310123443603516
Loss of batch at epoch 2 : 1.6665098667144775
Loss of batch at epoch 2 : 1.7682116031646729
Loss of batch at epoch 2 : 1.6131539344787598
Loss of batch at epoch 2 : 1.6710538864135742
Loss of batch at epoch 2 : 1.5447200536727905
Loss of batch at epoch 2 : 1.8070400953292847
Loss of batch at epoch 2 : 1.7674592733383179
Loss of batch at epoch 2 : 1.7273536920547485
Loss of batch at epoch 2 : 1.6499534845352173
Loss of batch at epoch 2 : 1.6338845491409302
Loss of batch at epoch 2 : 1.6742799282073975
Loss of batch at epoch 2 : 1.687997579574585
Loss of batch at epoch 2 : 1.6326731443405151
Loss of batch at epoch 2 : 1.608215570449829
Loss of batch at epoch 2 : 1.6249544620513916
Loss of batch at epoch 2 : 1.569602370262146
Loss of batch at epoch 2 : 1.5559666156768799
Loss of batch at epoch 2 : 1.6283150911331177
Loss of batch at epoch 2 : 1.5779592990875244
Loss of batch at epoch 2 : 1.6950198411941528
Loss of batch at epoch 2 : 1.502369999885559
Loss of batch at epoch 2 : 1.5527927875518799
Loss of batch at epoch 2 : 1.5102925300598145
Loss of batch at epoch 2 : 1.662750005722046
Loss of batch at epoch 2 : 1.5316524505615234
Loss of batch at epoch 2 : 1.5507142543792725
Loss of batch at epoch 2 : 1.601449966430664
Loss of batch at epoch 2 : 1.488162636756897
Loss of batch at epoch 2 : 1.516059398651123
Loss of batch at epoch 2 : 1.5483852624893188
Loss of batch at epoch 2 : 1.5614311695098877
Loss of batch at epoch 2 : 1.523492455482483
Loss of batch at epoch 2 : 1.4771777391433716
Loss of batch at epoch 2 : 1.5238734483718872
Loss of batch at epoch 2 : 1.502502679824829
Average train loss of epoch 2: 0.03356483750061992
Average validation loss of epoch 2: 0.030970146359016598
Loss of batch at epoch 3 : 1.4855198860168457
Loss of batch at epoch 3 : 1.5778814554214478
Loss of batch at epoch 3 : 1.4755498170852661
Loss of batch at epoch 3 : 1.4478636980056763
Loss of batch at epoch 3 : 1.554370641708374
Loss of batch at epoch 3 : 1.470624566078186
Loss of batch at epoch 3 : 1.5152307748794556
Loss of batch at epoch 3 : 1.4374206066131592
Loss of batch at epoch 3 : 1.4565256834030151
Loss of batch at epoch 3 : 1.4401307106018066
Loss of batch at epoch 3 : 1.4663159847259521
Loss of batch at epoch 3 : 1.5460296869277954
Loss of batch at epoch 3 : 1.4771814346313477
Loss of batch at epoch 3 : 1.4247468709945679
Loss of batch at epoch 3 : 1.4621468782424927
Loss of batch at epoch 3 : 1.3803458213806152
Loss of batch at epoch 3 : 1.4820013046264648
Loss of batch at epoch 3 : 1.4878712892532349
Loss of batch at epoch 3 : 1.4477758407592773
Loss of batch at epoch 3 : 1.535601019859314
Loss of batch at epoch 3 : 1.4166007041931152
Loss of batch at epoch 3 : 1.3741798400878906
Loss of batch at epoch 3 : 1.4564343690872192
Loss of batch at epoch 3 : 1.3915085792541504
Loss of batch at epoch 3 : 1.3814735412597656
Loss of batch at epoch 3 : 1.3811280727386475
Loss of batch at epoch 3 : 1.5091805458068848
Loss of batch at epoch 3 : 1.4033704996109009
Loss of batch at epoch 3 : 1.423140525817871
Loss of batch at epoch 3 : 1.4461714029312134
Loss of batch at epoch 3 : 1.3234000205993652
Loss of batch at epoch 3 : 1.418017864227295
Loss of batch at epoch 3 : 1.4269137382507324
Loss of batch at epoch 3 : 1.3647782802581787
Loss of batch at epoch 3 : 1.4659727811813354
Loss of batch at epoch 3 : 1.3182131052017212
Loss of batch at epoch 3 : 1.343936800956726
Loss of batch at epoch 3 : 1.342276692390442
Loss of batch at epoch 3 : 1.5872882604599
Loss of batch at epoch 3 : 1.3343709707260132
Loss of batch at epoch 3 : 1.3628603219985962
Loss of batch at epoch 3 : 1.3967825174331665
Loss of batch at epoch 3 : 1.3721296787261963
Loss of batch at epoch 3 : 1.3473492860794067
Loss of batch at epoch 3 : 1.4110960960388184
Loss of batch at epoch 3 : 1.4113847017288208
Loss of batch at epoch 3 : 1.3034329414367676
Loss of batch at epoch 3 : 1.317323923110962
Loss of batch at epoch 3 : 1.4425057172775269
Loss of batch at epoch 3 : 1.3604692220687866
Loss of batch at epoch 3 : 1.3175373077392578
Loss of batch at epoch 3 : 1.4090516567230225
Loss of batch at epoch 3 : 1.3521816730499268
Loss of batch at epoch 3 : 1.3339784145355225
Average train loss of epoch 3: 0.02868468018945604
Average validation loss of epoch 3: 0.027094552011200874
Loss of batch at epoch 4 : 1.3503544330596924
Loss of batch at epoch 4 : 1.284608244895935
Loss of batch at epoch 4 : 1.3393739461898804
Loss of batch at epoch 4 : 1.33069908618927
Loss of batch at epoch 4 : 1.293038249015808
Loss of batch at epoch 4 : 1.3693562746047974
Loss of batch at epoch 4 : 1.2183138132095337
Loss of batch at epoch 4 : 1.244225025177002
Loss of batch at epoch 4 : 1.2996066808700562
Loss of batch at epoch 4 : 1.2984004020690918
Loss of batch at epoch 4 : 1.2362295389175415
Loss of batch at epoch 4 : 1.3008016347885132
Loss of batch at epoch 4 : 1.2228444814682007
Loss of batch at epoch 4 : 1.2972412109375
Loss of batch at epoch 4 : 1.2527140378952026
Loss of batch at epoch 4 : 1.3060895204544067
Loss of batch at epoch 4 : 1.24038565158844
Loss of batch at epoch 4 : 1.2634871006011963
Loss of batch at epoch 4 : 1.2797549962997437
Loss of batch at epoch 4 : 1.2986069917678833
Loss of batch at epoch 4 : 1.3816661834716797
Loss of batch at epoch 4 : 1.2634583711624146
Loss of batch at epoch 4 : 1.3157304525375366
Loss of batch at epoch 4 : 1.25325608253479
Loss of batch at epoch 4 : 1.2449628114700317
Loss of batch at epoch 4 : 1.2142150402069092
Loss of batch at epoch 4 : 1.2715739011764526
Loss of batch at epoch 4 : 1.276732325553894
Loss of batch at epoch 4 : 1.2588449716567993
Loss of batch at epoch 4 : 1.2795815467834473
Loss of batch at epoch 4 : 1.3421036005020142
Loss of batch at epoch 4 : 1.2309457063674927
Loss of batch at epoch 4 : 1.3059722185134888
Loss of batch at epoch 4 : 1.3152689933776855
Loss of batch at epoch 4 : 1.2807483673095703
Loss of batch at epoch 4 : 1.2349212169647217
Loss of batch at epoch 4 : 1.2160969972610474
Loss of batch at epoch 4 : 1.1937718391418457
Loss of batch at epoch 4 : 1.302883267402649
Loss of batch at epoch 4 : 1.3131061792373657
Loss of batch at epoch 4 : 1.2173253297805786
Loss of batch at epoch 4 : 1.2668956518173218
Loss of batch at epoch 4 : 1.3227198123931885
Loss of batch at epoch 4 : 1.1689049005508423
Loss of batch at epoch 4 : 1.2280583381652832
Loss of batch at epoch 4 : 1.1962543725967407
Loss of batch at epoch 4 : 1.2615448236465454
Loss of batch at epoch 4 : 1.3054286241531372
Loss of batch at epoch 4 : 1.2098441123962402
Loss of batch at epoch 4 : 1.258230209350586
Loss of batch at epoch 4 : 1.2139501571655273
Loss of batch at epoch 4 : 1.241274356842041
Loss of batch at epoch 4 : 1.261683464050293
Loss of batch at epoch 4 : 1.150377869606018
Average train loss of epoch 4: 0.02558792376357998
Average validation loss of epoch 4: 0.02554275692512692
Loss of batch at epoch 5 : 1.2268240451812744
Loss of batch at epoch 5 : 1.2232340574264526
Loss of batch at epoch 5 : 1.2775187492370605
Loss of batch at epoch 5 : 1.1922824382781982
Loss of batch at epoch 5 : 1.2387148141860962
Loss of batch at epoch 5 : 1.1702706813812256
Loss of batch at epoch 5 : 1.258702039718628
Loss of batch at epoch 5 : 1.1753857135772705
Loss of batch at epoch 5 : 1.1598827838897705
Loss of batch at epoch 5 : 1.3299678564071655
Loss of batch at epoch 5 : 1.1979708671569824
Loss of batch at epoch 5 : 1.1413182020187378
Loss of batch at epoch 5 : 1.1607685089111328
Loss of batch at epoch 5 : 1.139176368713379
Loss of batch at epoch 5 : 1.1175432205200195
Loss of batch at epoch 5 : 1.1598331928253174
Loss of batch at epoch 5 : 1.2429293394088745
Loss of batch at epoch 5 : 1.2298667430877686
Loss of batch at epoch 5 : 1.2486099004745483
Loss of batch at epoch 5 : 1.1731388568878174
Loss of batch at epoch 5 : 1.2538844347000122
Loss of batch at epoch 5 : 1.1984106302261353
Loss of batch at epoch 5 : 1.1660304069519043
Loss of batch at epoch 5 : 1.1425646543502808
Loss of batch at epoch 5 : 1.1676342487335205
Loss of batch at epoch 5 : 1.1059892177581787
Loss of batch at epoch 5 : 1.1160916090011597
Loss of batch at epoch 5 : 1.1638916730880737
Loss of batch at epoch 5 : 1.1112374067306519
Loss of batch at epoch 5 : 1.1370210647583008
Loss of batch at epoch 5 : 1.1418724060058594
Loss of batch at epoch 5 : 1.184382677078247
Loss of batch at epoch 5 : 1.1901752948760986
Loss of batch at epoch 5 : 1.0739997625350952
Loss of batch at epoch 5 : 1.2357630729675293
Loss of batch at epoch 5 : 1.2350568771362305
Loss of batch at epoch 5 : 1.0858113765716553
Loss of batch at epoch 5 : 1.2174627780914307
Loss of batch at epoch 5 : 1.1925259828567505
Loss of batch at epoch 5 : 1.2392467260360718
Loss of batch at epoch 5 : 1.230185627937317
Loss of batch at epoch 5 : 1.1631890535354614
Loss of batch at epoch 5 : 1.118680477142334
Loss of batch at epoch 5 : 1.1685220003128052
Loss of batch at epoch 5 : 1.148486852645874
Loss of batch at epoch 5 : 1.1889562606811523
Loss of batch at epoch 5 : 1.0842080116271973
Loss of batch at epoch 5 : 1.1687415838241577
Loss of batch at epoch 5 : 1.1301183700561523
Loss of batch at epoch 5 : 1.1344859600067139
Loss of batch at epoch 5 : 1.1554594039916992
Loss of batch at epoch 5 : 1.0927966833114624
Loss of batch at epoch 5 : 1.1258107423782349
Loss of batch at epoch 5 : 1.2094794511795044
Average train loss of epoch 5: 0.023727455452540812
Average validation loss of epoch 5: 0.02304431645557134
Loss of batch at epoch 6 : 1.127764105796814
Loss of batch at epoch 6 : 1.137294054031372
Loss of batch at epoch 6 : 1.0833892822265625
Loss of batch at epoch 6 : 1.1054081916809082
Loss of batch at epoch 6 : 1.1331095695495605
Loss of batch at epoch 6 : 1.1708595752716064
Loss of batch at epoch 6 : 1.0587055683135986
Loss of batch at epoch 6 : 1.1558289527893066
Loss of batch at epoch 6 : 1.1195470094680786
Loss of batch at epoch 6 : 1.1065672636032104
Loss of batch at epoch 6 : 1.2356688976287842
Loss of batch at epoch 6 : 1.1189229488372803
Loss of batch at epoch 6 : 1.1103121042251587
Loss of batch at epoch 6 : 1.0171352624893188
Loss of batch at epoch 6 : 1.12944495677948
Loss of batch at epoch 6 : 1.0422916412353516
Loss of batch at epoch 6 : 1.0626308917999268
Loss of batch at epoch 6 : 1.1096793413162231
Loss of batch at epoch 6 : 1.0518358945846558
Loss of batch at epoch 6 : 1.1210910081863403
Loss of batch at epoch 6 : 1.0431346893310547
Loss of batch at epoch 6 : 1.0112944841384888
Loss of batch at epoch 6 : 1.0883924961090088
Loss of batch at epoch 6 : 1.1008808612823486
Loss of batch at epoch 6 : 1.0794448852539062
Loss of batch at epoch 6 : 1.1261708736419678
Loss of batch at epoch 6 : 1.1917084455490112
Loss of batch at epoch 6 : 1.0212119817733765
Loss of batch at epoch 6 : 1.0504270792007446
Loss of batch at epoch 6 : 1.2127431631088257
Loss of batch at epoch 6 : 1.0674837827682495
Loss of batch at epoch 6 : 1.0689585208892822
Loss of batch at epoch 6 : 1.0491048097610474
Loss of batch at epoch 6 : 0.9891911149024963
Loss of batch at epoch 6 : 1.0847015380859375
Loss of batch at epoch 6 : 1.1122912168502808
Loss of batch at epoch 6 : 1.160793662071228
Loss of batch at epoch 6 : 1.049026370048523
Loss of batch at epoch 6 : 1.045464277267456
Loss of batch at epoch 6 : 1.1526987552642822
Loss of batch at epoch 6 : 1.195801854133606
Loss of batch at epoch 6 : 1.0344058275222778
Loss of batch at epoch 6 : 1.033496618270874
Loss of batch at epoch 6 : 1.0445172786712646
Loss of batch at epoch 6 : 1.089904546737671
Loss of batch at epoch 6 : 1.0766760110855103
Loss of batch at epoch 6 : 1.000187635421753
Loss of batch at epoch 6 : 1.092050313949585
Loss of batch at epoch 6 : 1.089717149734497
Loss of batch at epoch 6 : 1.1289511919021606
Loss of batch at epoch 6 : 1.0066770315170288
Loss of batch at epoch 6 : 1.017454743385315
Loss of batch at epoch 6 : 1.004967212677002
Loss of batch at epoch 6 : 1.0544230937957764
Average train loss of epoch 6: 0.02194616846222767
Average validation loss of epoch 6: 0.02146272948293975
Loss of batch at epoch 7 : 1.0333707332611084
Loss of batch at epoch 7 : 1.0614084005355835
Loss of batch at epoch 7 : 1.0564844608306885
Loss of batch at epoch 7 : 1.05855131149292
Loss of batch at epoch 7 : 1.0296986103057861
Loss of batch at epoch 7 : 1.0972076654434204
Loss of batch at epoch 7 : 0.9455239176750183
Loss of batch at epoch 7 : 0.9227069020271301
Loss of batch at epoch 7 : 1.0053743124008179
Loss of batch at epoch 7 : 1.043503999710083
Loss of batch at epoch 7 : 1.040496826171875
Loss of batch at epoch 7 : 1.0484328269958496
Loss of batch at epoch 7 : 1.0341721773147583
Loss of batch at epoch 7 : 0.9961646199226379
Loss of batch at epoch 7 : 1.0790497064590454
Loss of batch at epoch 7 : 1.1532540321350098
Loss of batch at epoch 7 : 1.0006405115127563
Loss of batch at epoch 7 : 1.0909935235977173
Loss of batch at epoch 7 : 1.1262415647506714
Loss of batch at epoch 7 : 1.0739604234695435
Loss of batch at epoch 7 : 1.0075031518936157
Loss of batch at epoch 7 : 0.956313967704773
Loss of batch at epoch 7 : 1.1295580863952637
Loss of batch at epoch 7 : 1.0528240203857422
Loss of batch at epoch 7 : 0.9841111302375793
Loss of batch at epoch 7 : 1.120311975479126
Loss of batch at epoch 7 : 1.0663951635360718
Loss of batch at epoch 7 : 1.0775043964385986
Loss of batch at epoch 7 : 1.0320638418197632
Loss of batch at epoch 7 : 1.0219866037368774
Loss of batch at epoch 7 : 0.9954203963279724
Loss of batch at epoch 7 : 1.0292916297912598
Loss of batch at epoch 7 : 0.9931171536445618
Loss of batch at epoch 7 : 1.0504060983657837
Loss of batch at epoch 7 : 0.9526599049568176
Loss of batch at epoch 7 : 1.0350620746612549
Loss of batch at epoch 7 : 0.987809419631958
Loss of batch at epoch 7 : 1.0938479900360107
Loss of batch at epoch 7 : 1.0413129329681396
Loss of batch at epoch 7 : 1.0591976642608643
Loss of batch at epoch 7 : 1.0155327320098877
Loss of batch at epoch 7 : 1.00624680519104
Loss of batch at epoch 7 : 1.013758659362793
Loss of batch at epoch 7 : 1.0189738273620605
Loss of batch at epoch 7 : 1.0310680866241455
Loss of batch at epoch 7 : 0.9786648750305176
Loss of batch at epoch 7 : 0.9917306303977966
Loss of batch at epoch 7 : 1.007536768913269
Loss of batch at epoch 7 : 0.98880535364151
Loss of batch at epoch 7 : 1.042460322380066
Loss of batch at epoch 7 : 0.98453688621521
Loss of batch at epoch 7 : 0.9867128133773804
Loss of batch at epoch 7 : 1.0474706888198853
Loss of batch at epoch 7 : 0.9837261438369751
Average train loss of epoch 7: 0.020792068697962858
Average validation loss of epoch 7: 0.020418255417435256
Loss of batch at epoch 8 : 0.9362743496894836
Loss of batch at epoch 8 : 0.9583526253700256
Loss of batch at epoch 8 : 0.9776657819747925
Loss of batch at epoch 8 : 0.9845102429389954
Loss of batch at epoch 8 : 1.0537137985229492
Loss of batch at epoch 8 : 0.9709676504135132
Loss of batch at epoch 8 : 0.9675325155258179
Loss of batch at epoch 8 : 0.9949000477790833
Loss of batch at epoch 8 : 1.0340536832809448
Loss of batch at epoch 8 : 0.9491288065910339
Loss of batch at epoch 8 : 1.0066559314727783
Loss of batch at epoch 8 : 0.9492830038070679
Loss of batch at epoch 8 : 0.9852118492126465
Loss of batch at epoch 8 : 0.9044930934906006
Loss of batch at epoch 8 : 1.0283935070037842
Loss of batch at epoch 8 : 1.0037469863891602
Loss of batch at epoch 8 : 0.9038993120193481
Loss of batch at epoch 8 : 1.017224907875061
Loss of batch at epoch 8 : 0.969436526298523
Loss of batch at epoch 8 : 0.9300364851951599
Loss of batch at epoch 8 : 1.0272393226623535
Loss of batch at epoch 8 : 0.984681248664856
Loss of batch at epoch 8 : 0.99980628490448
Loss of batch at epoch 8 : 1.0164555311203003
Loss of batch at epoch 8 : 0.9744625687599182
Loss of batch at epoch 8 : 1.0016530752182007
Loss of batch at epoch 8 : 0.9843081831932068
Loss of batch at epoch 8 : 1.0315303802490234
Loss of batch at epoch 8 : 0.9933968186378479
Loss of batch at epoch 8 : 0.963061511516571
Loss of batch at epoch 8 : 1.033762812614441
Loss of batch at epoch 8 : 0.9133734703063965
Loss of batch at epoch 8 : 0.9134898781776428
Loss of batch at epoch 8 : 0.979163646697998
Loss of batch at epoch 8 : 0.9558002948760986
Loss of batch at epoch 8 : 0.9666125774383545
Loss of batch at epoch 8 : 0.900571346282959
Loss of batch at epoch 8 : 0.9628264307975769
Loss of batch at epoch 8 : 1.014491081237793
Loss of batch at epoch 8 : 0.9052411317825317
Loss of batch at epoch 8 : 0.9767268896102905
Loss of batch at epoch 8 : 0.937057614326477
Loss of batch at epoch 8 : 0.9858166575431824
Loss of batch at epoch 8 : 1.0499820709228516
Loss of batch at epoch 8 : 0.9720841646194458
Loss of batch at epoch 8 : 0.922332763671875
Loss of batch at epoch 8 : 1.0837081670761108
Loss of batch at epoch 8 : 0.9772337675094604
Loss of batch at epoch 8 : 1.0099369287490845
Loss of batch at epoch 8 : 1.0010676383972168
Loss of batch at epoch 8 : 0.9646508097648621
Loss of batch at epoch 8 : 1.053282380104065
Loss of batch at epoch 8 : 0.9758051037788391
Loss of batch at epoch 8 : 1.0616036653518677
Average train loss of epoch 8: 0.01979787141374014
Average validation loss of epoch 8: 0.01972665690412425
Loss of batch at epoch 9 : 0.9717246890068054
Loss of batch at epoch 9 : 0.8970632553100586
Loss of batch at epoch 9 : 1.044032096862793
Loss of batch at epoch 9 : 0.9218528270721436
Loss of batch at epoch 9 : 0.9212300181388855
Loss of batch at epoch 9 : 0.9464723467826843
Loss of batch at epoch 9 : 0.9636191725730896
Loss of batch at epoch 9 : 0.8746733069419861
Loss of batch at epoch 9 : 0.9612842202186584
Loss of batch at epoch 9 : 0.9384356737136841
Loss of batch at epoch 9 : 0.9221048355102539
Loss of batch at epoch 9 : 0.9703584313392639
Loss of batch at epoch 9 : 0.9416065216064453
Loss of batch at epoch 9 : 0.9685574769973755
Loss of batch at epoch 9 : 0.9788987040519714
Loss of batch at epoch 9 : 0.939337432384491
Loss of batch at epoch 9 : 0.9492939114570618
Loss of batch at epoch 9 : 0.9520806074142456
Loss of batch at epoch 9 : 0.9601937532424927
Loss of batch at epoch 9 : 0.9828948378562927
Loss of batch at epoch 9 : 0.9706225991249084
Loss of batch at epoch 9 : 0.8948700428009033
Loss of batch at epoch 9 : 0.9575347304344177
Loss of batch at epoch 9 : 0.9169057607650757
Loss of batch at epoch 9 : 0.8988776206970215
Loss of batch at epoch 9 : 0.9993975758552551
Loss of batch at epoch 9 : 0.9315369129180908
Loss of batch at epoch 9 : 0.9909351468086243
Loss of batch at epoch 9 : 0.8714564442634583
Loss of batch at epoch 9 : 0.8928124308586121
Loss of batch at epoch 9 : 0.944465160369873
Loss of batch at epoch 9 : 1.0065926313400269
Loss of batch at epoch 9 : 0.9379514455795288
Loss of batch at epoch 9 : 0.977347195148468
Loss of batch at epoch 9 : 0.9097968339920044
Loss of batch at epoch 9 : 0.959015429019928
Loss of batch at epoch 9 : 0.9353078603744507
Loss of batch at epoch 9 : 0.9911537170410156
Loss of batch at epoch 9 : 0.9577843546867371
Loss of batch at epoch 9 : 0.9198681116104126
Loss of batch at epoch 9 : 0.8618757128715515
Loss of batch at epoch 9 : 1.0071055889129639
Loss of batch at epoch 9 : 0.9642797708511353
Loss of batch at epoch 9 : 0.9267289638519287
Loss of batch at epoch 9 : 0.8614498376846313
Loss of batch at epoch 9 : 0.9286380410194397
Loss of batch at epoch 9 : 0.8554686307907104
Loss of batch at epoch 9 : 0.9241426587104797
Loss of batch at epoch 9 : 0.9077724814414978
Loss of batch at epoch 9 : 0.8774929046630859
Loss of batch at epoch 9 : 0.9359709620475769
Loss of batch at epoch 9 : 0.9417819976806641
Loss of batch at epoch 9 : 0.8791539669036865
Loss of batch at epoch 9 : 0.9444315433502197
Average train loss of epoch 9: 0.01892690110153187
Average validation loss of epoch 9: 0.018728760356453534
Loss of batch at epoch 10 : 0.9475056529045105
Loss of batch at epoch 10 : 0.9119136929512024
Loss of batch at epoch 10 : 0.8964020013809204
Loss of batch at epoch 10 : 0.8634364604949951
Loss of batch at epoch 10 : 0.9306660294532776
Loss of batch at epoch 10 : 0.8496996760368347
Loss of batch at epoch 10 : 0.8707872033119202
Loss of batch at epoch 10 : 0.8619661331176758
Loss of batch at epoch 10 : 0.9123746156692505
Loss of batch at epoch 10 : 0.8831459879875183
Loss of batch at epoch 10 : 0.936963677406311
Loss of batch at epoch 10 : 0.9013885855674744
Loss of batch at epoch 10 : 0.9705693125724792
Loss of batch at epoch 10 : 0.9255268573760986
Loss of batch at epoch 10 : 0.919300377368927
Loss of batch at epoch 10 : 0.9315944314002991
Loss of batch at epoch 10 : 0.9124142527580261
Loss of batch at epoch 10 : 0.8575982451438904
Loss of batch at epoch 10 : 0.9319957494735718
Loss of batch at epoch 10 : 0.836971640586853
Loss of batch at epoch 10 : 0.8888386487960815
Loss of batch at epoch 10 : 0.8994652628898621
Loss of batch at epoch 10 : 0.856151819229126
Loss of batch at epoch 10 : 1.004263997077942
Loss of batch at epoch 10 : 0.8898499011993408
Loss of batch at epoch 10 : 0.9550173878669739
Loss of batch at epoch 10 : 0.9200813174247742
Loss of batch at epoch 10 : 0.9476842880249023
Loss of batch at epoch 10 : 0.900766909122467
Loss of batch at epoch 10 : 0.9905503392219543
Loss of batch at epoch 10 : 0.891080915927887
Loss of batch at epoch 10 : 0.8601217865943909
Loss of batch at epoch 10 : 0.8501543998718262
Loss of batch at epoch 10 : 0.940344512462616
Loss of batch at epoch 10 : 0.9110103845596313
Loss of batch at epoch 10 : 0.9034149646759033
Loss of batch at epoch 10 : 0.9220452904701233
Loss of batch at epoch 10 : 0.9391835927963257
Loss of batch at epoch 10 : 0.8678460121154785
Loss of batch at epoch 10 : 0.8839336633682251
Loss of batch at epoch 10 : 0.8494698405265808
Loss of batch at epoch 10 : 0.9168883562088013
Loss of batch at epoch 10 : 0.902458667755127
Loss of batch at epoch 10 : 0.8793178200721741
Loss of batch at epoch 10 : 0.8364428281784058
Loss of batch at epoch 10 : 0.8270338177680969
Loss of batch at epoch 10 : 0.851526141166687
Loss of batch at epoch 10 : 0.860622227191925
Loss of batch at epoch 10 : 0.9239765405654907
Loss of batch at epoch 10 : 0.9179452061653137
Loss of batch at epoch 10 : 0.9059016108512878
Loss of batch at epoch 10 : 0.8799368739128113
Loss of batch at epoch 10 : 0.8909981846809387
Loss of batch at epoch 10 : 0.9426527619361877
Average train loss of epoch 10: 0.018169977132556508
Average validation loss of epoch 10: 0.018266557443021525
Loss of batch at epoch 11 : 0.8265678882598877
Loss of batch at epoch 11 : 0.870408833026886
Loss of batch at epoch 11 : 0.865647554397583
Loss of batch at epoch 11 : 0.9020269513130188
Loss of batch at epoch 11 : 0.8884490132331848
Loss of batch at epoch 11 : 0.8952252268791199
Loss of batch at epoch 11 : 0.9139551520347595
Loss of batch at epoch 11 : 0.8636523485183716
Loss of batch at epoch 11 : 0.885442852973938
Loss of batch at epoch 11 : 0.8702170848846436
Loss of batch at epoch 11 : 0.9591495990753174
Loss of batch at epoch 11 : 0.871314287185669
Loss of batch at epoch 11 : 0.9104099273681641
Loss of batch at epoch 11 : 1.004316806793213
Loss of batch at epoch 11 : 0.8196694254875183
Loss of batch at epoch 11 : 0.863469123840332
Loss of batch at epoch 11 : 0.9787679314613342
Loss of batch at epoch 11 : 0.8377364873886108
Loss of batch at epoch 11 : 0.80772864818573
Loss of batch at epoch 11 : 0.9591734409332275
Loss of batch at epoch 11 : 0.8580043315887451
Loss of batch at epoch 11 : 0.9175863265991211
Loss of batch at epoch 11 : 0.9081246852874756
Loss of batch at epoch 11 : 0.8624696731567383
Loss of batch at epoch 11 : 0.9323021769523621
Loss of batch at epoch 11 : 0.8624827861785889
Loss of batch at epoch 11 : 0.8230273723602295
Loss of batch at epoch 11 : 0.8863714337348938
Loss of batch at epoch 11 : 0.9138585925102234
Loss of batch at epoch 11 : 1.017768383026123
Loss of batch at epoch 11 : 0.8542076945304871
Loss of batch at epoch 11 : 0.8407013416290283
Loss of batch at epoch 11 : 0.8932205438613892
Loss of batch at epoch 11 : 0.8660546541213989
Loss of batch at epoch 11 : 0.8659482598304749
Loss of batch at epoch 11 : 0.8586087226867676
Loss of batch at epoch 11 : 0.8183534741401672
Loss of batch at epoch 11 : 0.9077274203300476
Loss of batch at epoch 11 : 0.9137894511222839
Loss of batch at epoch 11 : 0.8188356757164001
Loss of batch at epoch 11 : 0.9002816081047058
Loss of batch at epoch 11 : 0.9506641030311584
Loss of batch at epoch 11 : 0.794884204864502
Loss of batch at epoch 11 : 0.8526437282562256
Loss of batch at epoch 11 : 0.8224201202392578
Loss of batch at epoch 11 : 0.8832465410232544
Loss of batch at epoch 11 : 0.7688913345336914
Loss of batch at epoch 11 : 0.8781825304031372
Loss of batch at epoch 11 : 0.8775733709335327
Loss of batch at epoch 11 : 0.8549281358718872
Loss of batch at epoch 11 : 0.8524875640869141
Loss of batch at epoch 11 : 0.8740596771240234
Loss of batch at epoch 11 : 0.8405910730361938
Loss of batch at epoch 11 : 0.8310942053794861
Average train loss of epoch 11: 0.01769780222384942
Average validation loss of epoch 11: 0.01753704957287721
Loss of batch at epoch 12 : 0.873495876789093
Loss of batch at epoch 12 : 0.8917089104652405
Loss of batch at epoch 12 : 0.8520559072494507
Loss of batch at epoch 12 : 0.792170524597168
Loss of batch at epoch 12 : 0.8033358454704285
Loss of batch at epoch 12 : 0.8794113397598267
Loss of batch at epoch 12 : 0.8669677376747131
Loss of batch at epoch 12 : 0.8791237473487854
Loss of batch at epoch 12 : 0.9018210768699646
Loss of batch at epoch 12 : 0.8210555911064148
Loss of batch at epoch 12 : 0.817430853843689
Loss of batch at epoch 12 : 0.8648079633712769
Loss of batch at epoch 12 : 0.9653031229972839
Loss of batch at epoch 12 : 0.9229115843772888
Loss of batch at epoch 12 : 0.8019493222236633
Loss of batch at epoch 12 : 0.885587751865387
Loss of batch at epoch 12 : 0.8689493536949158
Loss of batch at epoch 12 : 0.8654755353927612
Loss of batch at epoch 12 : 0.8783543705940247
Loss of batch at epoch 12 : 0.903123676776886
Loss of batch at epoch 12 : 0.8099716305732727
Loss of batch at epoch 12 : 0.7991151809692383
Loss of batch at epoch 12 : 0.7851131558418274
Loss of batch at epoch 12 : 0.822848379611969
Loss of batch at epoch 12 : 0.8562542200088501
Loss of batch at epoch 12 : 0.7707846164703369
Loss of batch at epoch 12 : 0.847385048866272
Loss of batch at epoch 12 : 0.8238203525543213
Loss of batch at epoch 12 : 0.8088237643241882
Loss of batch at epoch 12 : 0.8909788131713867
Loss of batch at epoch 12 : 0.7931382656097412
Loss of batch at epoch 12 : 0.9437671899795532
Loss of batch at epoch 12 : 0.788655698299408
Loss of batch at epoch 12 : 0.807974636554718
Loss of batch at epoch 12 : 0.916167676448822
Loss of batch at epoch 12 : 0.8189096450805664
Loss of batch at epoch 12 : 0.7661250829696655
Loss of batch at epoch 12 : 0.8326141238212585
Loss of batch at epoch 12 : 0.8672704100608826
Loss of batch at epoch 12 : 0.7813383936882019
Loss of batch at epoch 12 : 0.7934902906417847
Loss of batch at epoch 12 : 0.890475332736969
Loss of batch at epoch 12 : 0.8135871887207031
Loss of batch at epoch 12 : 0.7807232141494751
Loss of batch at epoch 12 : 0.7980658411979675
Loss of batch at epoch 12 : 0.8839054703712463
Loss of batch at epoch 12 : 0.8112203478813171
Loss of batch at epoch 12 : 0.8787526488304138
Loss of batch at epoch 12 : 0.8699948787689209
Loss of batch at epoch 12 : 0.7631471157073975
Loss of batch at epoch 12 : 0.8571409583091736
Loss of batch at epoch 12 : 0.8839472532272339
Loss of batch at epoch 12 : 0.8243477940559387
Loss of batch at epoch 12 : 0.8863690495491028
Average train loss of epoch 12: 0.01702810633618766
Average validation loss of epoch 12: 0.01715540323995982
Loss of batch at epoch 13 : 0.8547732830047607
Loss of batch at epoch 13 : 0.8045480847358704
Loss of batch at epoch 13 : 0.7369862198829651
Loss of batch at epoch 13 : 0.8611829876899719
Loss of batch at epoch 13 : 0.8399097919464111
Loss of batch at epoch 13 : 0.9280061721801758
Loss of batch at epoch 13 : 0.892939031124115
Loss of batch at epoch 13 : 0.7903232574462891
Loss of batch at epoch 13 : 0.8167694807052612
Loss of batch at epoch 13 : 0.7681050300598145
Loss of batch at epoch 13 : 0.7886832356452942
Loss of batch at epoch 13 : 0.8543139696121216
Loss of batch at epoch 13 : 0.7770952582359314
Loss of batch at epoch 13 : 0.7782914042472839
Loss of batch at epoch 13 : 0.8336742520332336
Loss of batch at epoch 13 : 0.8379532098770142
Loss of batch at epoch 13 : 0.7764246463775635
Loss of batch at epoch 13 : 0.8225095868110657
Loss of batch at epoch 13 : 0.8145540952682495
Loss of batch at epoch 13 : 0.7790315747261047
Loss of batch at epoch 13 : 0.8614467978477478
Loss of batch at epoch 13 : 0.841619074344635
Loss of batch at epoch 13 : 0.8454892635345459
Loss of batch at epoch 13 : 0.7890441417694092
Loss of batch at epoch 13 : 0.9012328386306763
Loss of batch at epoch 13 : 0.8788020610809326
Loss of batch at epoch 13 : 0.8233077526092529
Loss of batch at epoch 13 : 0.853280246257782
Loss of batch at epoch 13 : 0.9277855157852173
Loss of batch at epoch 13 : 0.7926909327507019
Loss of batch at epoch 13 : 0.76874840259552
Loss of batch at epoch 13 : 0.8114281892776489
Loss of batch at epoch 13 : 0.8465790152549744
Loss of batch at epoch 13 : 0.8480456471443176
Loss of batch at epoch 13 : 0.7969282865524292
Loss of batch at epoch 13 : 0.8811346292495728
Loss of batch at epoch 13 : 0.8498898148536682
Loss of batch at epoch 13 : 0.8787361979484558
Loss of batch at epoch 13 : 0.8254533410072327
Loss of batch at epoch 13 : 0.8655523657798767
Loss of batch at epoch 13 : 0.7326710820198059
Loss of batch at epoch 13 : 0.8170183897018433
Loss of batch at epoch 13 : 0.7967939972877502
Loss of batch at epoch 13 : 0.7825831174850464
Loss of batch at epoch 13 : 0.8012322187423706
Loss of batch at epoch 13 : 0.7834908962249756
Loss of batch at epoch 13 : 0.8182132244110107
Loss of batch at epoch 13 : 0.8734562397003174
Loss of batch at epoch 13 : 0.7706403732299805
Loss of batch at epoch 13 : 0.819640040397644
Loss of batch at epoch 13 : 0.7990386486053467
Loss of batch at epoch 13 : 0.8036867380142212
Loss of batch at epoch 13 : 0.7906119227409363
Loss of batch at epoch 13 : 0.7776130437850952
Average train loss of epoch 13: 0.016583253947365543
Average validation loss of epoch 13: 0.01644803538466945
Loss of batch at epoch 14 : 0.8699773550033569
Loss of batch at epoch 14 : 0.7869722843170166
Loss of batch at epoch 14 : 0.8136728405952454
Loss of batch at epoch 14 : 0.7974632978439331
Loss of batch at epoch 14 : 0.7940878868103027
Loss of batch at epoch 14 : 0.8102665543556213
Loss of batch at epoch 14 : 0.7954521775245667
Loss of batch at epoch 14 : 0.7645695209503174
Loss of batch at epoch 14 : 0.84138423204422
Loss of batch at epoch 14 : 0.7962743639945984
Loss of batch at epoch 14 : 0.840160608291626
Loss of batch at epoch 14 : 0.777123212814331
Loss of batch at epoch 14 : 0.8447569608688354
Loss of batch at epoch 14 : 0.725799024105072
Loss of batch at epoch 14 : 0.9054005742073059
Loss of batch at epoch 14 : 0.7591186761856079
Loss of batch at epoch 14 : 0.8605817556381226
Loss of batch at epoch 14 : 0.8123582005500793
Loss of batch at epoch 14 : 0.701144814491272
Loss of batch at epoch 14 : 0.7504879832267761
Loss of batch at epoch 14 : 0.829990029335022
Loss of batch at epoch 14 : 0.7947774529457092
Loss of batch at epoch 14 : 0.8923081755638123
Loss of batch at epoch 14 : 0.7766311168670654
Loss of batch at epoch 14 : 0.8281866908073425
Loss of batch at epoch 14 : 0.8343213796615601
Loss of batch at epoch 14 : 0.8139528632164001
Loss of batch at epoch 14 : 0.7511711120605469
Loss of batch at epoch 14 : 0.7690650820732117
Loss of batch at epoch 14 : 0.7863396406173706
Loss of batch at epoch 14 : 0.8023291826248169
Loss of batch at epoch 14 : 0.7835712432861328
Loss of batch at epoch 14 : 0.7676757574081421
Loss of batch at epoch 14 : 0.863498330116272
Loss of batch at epoch 14 : 0.7740668058395386
Loss of batch at epoch 14 : 0.8134194612503052
Loss of batch at epoch 14 : 0.9185931086540222
Loss of batch at epoch 14 : 0.7917128801345825
Loss of batch at epoch 14 : 0.8442917466163635
Loss of batch at epoch 14 : 0.7918930649757385
Loss of batch at epoch 14 : 0.7740250825881958
Loss of batch at epoch 14 : 0.7835758328437805
Loss of batch at epoch 14 : 0.8389020562171936
Loss of batch at epoch 14 : 0.7917045950889587
Loss of batch at epoch 14 : 0.8076918721199036
Loss of batch at epoch 14 : 0.8520550727844238
Loss of batch at epoch 14 : 0.7110000252723694
Loss of batch at epoch 14 : 0.7596826553344727
Loss of batch at epoch 14 : 0.8165583610534668
Loss of batch at epoch 14 : 0.8050089478492737
Loss of batch at epoch 14 : 0.7940787672996521
Loss of batch at epoch 14 : 0.8531944751739502
Loss of batch at epoch 14 : 0.8511274456977844
Loss of batch at epoch 14 : 0.7855352163314819
Average train loss of epoch 14: 0.01624308779134601
Average validation loss of epoch 14: 0.016359642298534663
Loss of batch at epoch 15 : 0.7403706908226013
Loss of batch at epoch 15 : 0.8102564811706543
Loss of batch at epoch 15 : 0.7875469326972961
Loss of batch at epoch 15 : 0.7009872198104858
Loss of batch at epoch 15 : 0.7840769290924072
Loss of batch at epoch 15 : 0.7855846285820007
Loss of batch at epoch 15 : 0.7496206760406494
Loss of batch at epoch 15 : 0.8052892088890076
Loss of batch at epoch 15 : 0.7657851576805115
Loss of batch at epoch 15 : 0.7996952533721924
Loss of batch at epoch 15 : 0.9034827351570129
Loss of batch at epoch 15 : 0.7108736634254456
Loss of batch at epoch 15 : 0.7869830131530762
Loss of batch at epoch 15 : 0.7775627970695496
Loss of batch at epoch 15 : 0.8084902167320251
Loss of batch at epoch 15 : 0.8716535568237305
Loss of batch at epoch 15 : 0.6887826919555664
Loss of batch at epoch 15 : 0.8532353639602661
Loss of batch at epoch 15 : 0.8562049865722656
Loss of batch at epoch 15 : 0.8098034262657166
Loss of batch at epoch 15 : 0.7875010967254639
Loss of batch at epoch 15 : 0.8574807643890381
Loss of batch at epoch 15 : 0.7926983833312988
Loss of batch at epoch 15 : 0.7321784496307373
Loss of batch at epoch 15 : 0.8243876099586487
Loss of batch at epoch 15 : 0.8103088140487671
Loss of batch at epoch 15 : 0.9178352952003479
Loss of batch at epoch 15 : 0.7118993401527405
Loss of batch at epoch 15 : 0.7573749423027039
Loss of batch at epoch 15 : 0.8303627371788025
Loss of batch at epoch 15 : 0.8205035328865051
Loss of batch at epoch 15 : 0.7688404321670532
Loss of batch at epoch 15 : 0.7642695903778076
Loss of batch at epoch 15 : 0.808837890625
Loss of batch at epoch 15 : 0.7697400450706482
Loss of batch at epoch 15 : 0.7759649157524109
Loss of batch at epoch 15 : 0.8175390362739563
Loss of batch at epoch 15 : 0.7766714692115784
Loss of batch at epoch 15 : 0.74947190284729
Loss of batch at epoch 15 : 0.689352810382843
Loss of batch at epoch 15 : 0.7893598079681396
Loss of batch at epoch 15 : 0.7377154231071472
Loss of batch at epoch 15 : 0.7687941193580627
Loss of batch at epoch 15 : 0.7606424689292908
Loss of batch at epoch 15 : 0.7479093670845032
Loss of batch at epoch 15 : 0.7717433571815491
Loss of batch at epoch 15 : 0.8297185301780701
Loss of batch at epoch 15 : 0.7959775328636169
Loss of batch at epoch 15 : 0.697257936000824
Loss of batch at epoch 15 : 0.8050003051757812
Loss of batch at epoch 15 : 0.8715475797653198
Loss of batch at epoch 15 : 0.8263218998908997
Loss of batch at epoch 15 : 0.8241362571716309
Loss of batch at epoch 15 : 0.8651965856552124
Average train loss of epoch 15: 0.015926372479644617
Average validation loss of epoch 15: 0.01594295084275782
Loss of batch at epoch 16 : 0.7743837833404541
Loss of batch at epoch 16 : 0.8093546628952026
Loss of batch at epoch 16 : 0.7542771100997925
Loss of batch at epoch 16 : 0.8372051119804382
Loss of batch at epoch 16 : 0.8028857707977295
Loss of batch at epoch 16 : 0.8932722806930542
Loss of batch at epoch 16 : 0.7899914383888245
Loss of batch at epoch 16 : 0.7242051959037781
Loss of batch at epoch 16 : 0.8036410808563232
Loss of batch at epoch 16 : 0.8382155299186707
Loss of batch at epoch 16 : 0.784417986869812
Loss of batch at epoch 16 : 0.7354299426078796
Loss of batch at epoch 16 : 0.7494675517082214
Loss of batch at epoch 16 : 0.8093434572219849
Loss of batch at epoch 16 : 0.761400043964386
Loss of batch at epoch 16 : 0.7890419960021973
Loss of batch at epoch 16 : 0.8145799040794373
Loss of batch at epoch 16 : 0.7593779563903809
Loss of batch at epoch 16 : 0.723190188407898
Loss of batch at epoch 16 : 0.6914638876914978
Loss of batch at epoch 16 : 0.8714430332183838
Loss of batch at epoch 16 : 0.7238131761550903
Loss of batch at epoch 16 : 0.798193097114563
Loss of batch at epoch 16 : 0.7731431722640991
Loss of batch at epoch 16 : 0.7524470090866089
Loss of batch at epoch 16 : 0.8003460764884949
Loss of batch at epoch 16 : 0.7407155632972717
Loss of batch at epoch 16 : 0.7966428995132446
Loss of batch at epoch 16 : 0.6968784332275391
Loss of batch at epoch 16 : 0.7453120946884155
Loss of batch at epoch 16 : 0.6860866546630859
Loss of batch at epoch 16 : 0.7113213539123535
Loss of batch at epoch 16 : 0.7381375432014465
Loss of batch at epoch 16 : 0.7628570199012756
Loss of batch at epoch 16 : 0.7987871170043945
Loss of batch at epoch 16 : 0.7834123969078064
Loss of batch at epoch 16 : 0.7981328368186951
Loss of batch at epoch 16 : 0.8765143752098083
Loss of batch at epoch 16 : 0.7314881086349487
Loss of batch at epoch 16 : 0.7117904424667358
Loss of batch at epoch 16 : 0.7647150158882141
Loss of batch at epoch 16 : 0.8019797205924988
Loss of batch at epoch 16 : 0.7604713439941406
Loss of batch at epoch 16 : 0.7885796427726746
Loss of batch at epoch 16 : 0.7592907547950745
Loss of batch at epoch 16 : 0.7396566271781921
Loss of batch at epoch 16 : 0.7697738409042358
Loss of batch at epoch 16 : 0.7977477312088013
Loss of batch at epoch 16 : 0.7077639698982239
Loss of batch at epoch 16 : 0.8106727004051208
Loss of batch at epoch 16 : 0.7434786558151245
Loss of batch at epoch 16 : 0.7577136158943176
Loss of batch at epoch 16 : 0.6771299242973328
Loss of batch at epoch 16 : 0.7972487211227417
Average train loss of epoch 16: 0.015541013984024925
Average validation loss of epoch 16: 0.015518898113006694
Loss of batch at epoch 17 : 0.7292542457580566
Loss of batch at epoch 17 : 0.7230886220932007
Loss of batch at epoch 17 : 0.8008130788803101
Loss of batch at epoch 17 : 0.7402204275131226
Loss of batch at epoch 17 : 0.763764500617981
Loss of batch at epoch 17 : 0.7355191111564636
Loss of batch at epoch 17 : 0.8404231667518616
Loss of batch at epoch 17 : 0.8072664737701416
Loss of batch at epoch 17 : 0.7398650050163269
Loss of batch at epoch 17 : 0.7577848434448242
Loss of batch at epoch 17 : 0.7215235829353333
Loss of batch at epoch 17 : 0.68905109167099
Loss of batch at epoch 17 : 0.7153857350349426
Loss of batch at epoch 17 : 0.7328606247901917
Loss of batch at epoch 17 : 0.7609677910804749
Loss of batch at epoch 17 : 0.7731590867042542
Loss of batch at epoch 17 : 0.8297348022460938
Loss of batch at epoch 17 : 0.826805591583252
Loss of batch at epoch 17 : 0.7108620405197144
Loss of batch at epoch 17 : 0.7173737287521362
Loss of batch at epoch 17 : 0.7320097088813782
Loss of batch at epoch 17 : 0.7630221247673035
Loss of batch at epoch 17 : 0.7452905774116516
Loss of batch at epoch 17 : 0.7782748341560364
Loss of batch at epoch 17 : 0.7413859963417053
Loss of batch at epoch 17 : 0.7900408506393433
Loss of batch at epoch 17 : 0.7283239960670471
Loss of batch at epoch 17 : 0.8057295680046082
Loss of batch at epoch 17 : 0.710928201675415
Loss of batch at epoch 17 : 0.8126592636108398
Loss of batch at epoch 17 : 0.7623183727264404
Loss of batch at epoch 17 : 0.7605514526367188
Loss of batch at epoch 17 : 0.7420008182525635
Loss of batch at epoch 17 : 0.759790301322937
Loss of batch at epoch 17 : 0.7338215112686157
Loss of batch at epoch 17 : 0.7151535749435425
Loss of batch at epoch 17 : 0.6874491572380066
Loss of batch at epoch 17 : 0.7404587864875793
Loss of batch at epoch 17 : 0.6436532735824585
Loss of batch at epoch 17 : 0.8256532549858093
Loss of batch at epoch 17 : 0.7386288046836853
Loss of batch at epoch 17 : 0.7766315937042236
Loss of batch at epoch 17 : 0.6973862648010254
Loss of batch at epoch 17 : 0.736970841884613
Loss of batch at epoch 17 : 0.7705897092819214
Loss of batch at epoch 17 : 0.7090045213699341
Loss of batch at epoch 17 : 0.8436735272407532
Loss of batch at epoch 17 : 0.7393246293067932
Loss of batch at epoch 17 : 0.8044682741165161
Loss of batch at epoch 17 : 0.7462363243103027
Loss of batch at epoch 17 : 0.7853309512138367
Loss of batch at epoch 17 : 0.7148899435997009
Loss of batch at epoch 17 : 0.7780802845954895
Loss of batch at epoch 17 : 0.7582314014434814
Average train loss of epoch 17: 0.015195550270450926
Average validation loss of epoch 17: 0.015226810468166364
Loss of batch at epoch 18 : 0.8021454811096191
Loss of batch at epoch 18 : 0.8009310960769653
Loss of batch at epoch 18 : 0.7686444520950317
Loss of batch at epoch 18 : 0.7259299755096436
Loss of batch at epoch 18 : 0.7441142201423645
Loss of batch at epoch 18 : 0.818658709526062
Loss of batch at epoch 18 : 0.7589301466941833
Loss of batch at epoch 18 : 0.7026416659355164
Loss of batch at epoch 18 : 0.7996582984924316
Loss of batch at epoch 18 : 0.6997150778770447
Loss of batch at epoch 18 : 0.7357555031776428
Loss of batch at epoch 18 : 0.7161296606063843
Loss of batch at epoch 18 : 0.6429664492607117
Loss of batch at epoch 18 : 0.724616527557373
Loss of batch at epoch 18 : 0.7657193541526794
Loss of batch at epoch 18 : 0.6898469924926758
Loss of batch at epoch 18 : 0.735821545124054
Loss of batch at epoch 18 : 0.7286399006843567
Loss of batch at epoch 18 : 0.7349244952201843
Loss of batch at epoch 18 : 0.6783093214035034
Loss of batch at epoch 18 : 0.7049494981765747
Loss of batch at epoch 18 : 0.7103162407875061
Loss of batch at epoch 18 : 0.7739424705505371
Loss of batch at epoch 18 : 0.7363954782485962
Loss of batch at epoch 18 : 0.7875816822052002
Loss of batch at epoch 18 : 0.6898140907287598
Loss of batch at epoch 18 : 0.7244506478309631
Loss of batch at epoch 18 : 0.7566961646080017
Loss of batch at epoch 18 : 0.8006105422973633
Loss of batch at epoch 18 : 0.7889026403427124
Loss of batch at epoch 18 : 0.6920152306556702
Loss of batch at epoch 18 : 0.6929993629455566
Loss of batch at epoch 18 : 0.753275454044342
Loss of batch at epoch 18 : 0.7202103734016418
Loss of batch at epoch 18 : 0.7128505110740662
Loss of batch at epoch 18 : 0.7087640762329102
Loss of batch at epoch 18 : 0.7308927774429321
Loss of batch at epoch 18 : 0.6834438443183899
Loss of batch at epoch 18 : 0.7280676364898682
Loss of batch at epoch 18 : 0.7612271904945374
Loss of batch at epoch 18 : 0.7590627670288086
Loss of batch at epoch 18 : 0.8010830283164978
Loss of batch at epoch 18 : 0.725174069404602
Loss of batch at epoch 18 : 0.7150881290435791
Loss of batch at epoch 18 : 0.7688062787055969
Loss of batch at epoch 18 : 0.7566025257110596
Loss of batch at epoch 18 : 0.7576377391815186
Loss of batch at epoch 18 : 0.6927522420883179
Loss of batch at epoch 18 : 0.7153539657592773
Loss of batch at epoch 18 : 0.7087391018867493
Loss of batch at epoch 18 : 0.8241749405860901
Loss of batch at epoch 18 : 0.711310863494873
Loss of batch at epoch 18 : 0.7444979548454285
Loss of batch at epoch 18 : 0.7604534029960632
Average train loss of epoch 18: 0.014888813283747929
Average validation loss of epoch 18: 0.01478964712483313
Loss of batch at epoch 19 : 0.7265872955322266
Loss of batch at epoch 19 : 0.7445276975631714
Loss of batch at epoch 19 : 0.775108814239502
Loss of batch at epoch 19 : 0.7570520043373108
Loss of batch at epoch 19 : 0.7319791316986084
Loss of batch at epoch 19 : 0.7335834503173828
Loss of batch at epoch 19 : 0.7564574480056763
Loss of batch at epoch 19 : 0.7100273966789246
Loss of batch at epoch 19 : 0.7050262093544006
Loss of batch at epoch 19 : 0.7277566194534302
Loss of batch at epoch 19 : 0.6749199628829956
Loss of batch at epoch 19 : 0.6956297159194946
Loss of batch at epoch 19 : 0.6655532121658325
Loss of batch at epoch 19 : 0.719187319278717
Loss of batch at epoch 19 : 0.7357089519500732
Loss of batch at epoch 19 : 0.7573896646499634
Loss of batch at epoch 19 : 0.7122546434402466
Loss of batch at epoch 19 : 0.7294901013374329
Loss of batch at epoch 19 : 0.7467061877250671
Loss of batch at epoch 19 : 0.7458817958831787
Loss of batch at epoch 19 : 0.7307741641998291
Loss of batch at epoch 19 : 0.6646376252174377
Loss of batch at epoch 19 : 0.7192789316177368
Loss of batch at epoch 19 : 0.7938156127929688
Loss of batch at epoch 19 : 0.793579638004303
Loss of batch at epoch 19 : 0.7326115369796753
Loss of batch at epoch 19 : 0.6931092143058777
Loss of batch at epoch 19 : 0.6797081232070923
Loss of batch at epoch 19 : 0.7691531181335449
Loss of batch at epoch 19 : 0.6763737201690674
Loss of batch at epoch 19 : 0.7809929847717285
Loss of batch at epoch 19 : 0.7263460755348206
Loss of batch at epoch 19 : 0.6687920689582825
Loss of batch at epoch 19 : 0.7312905788421631
Loss of batch at epoch 19 : 0.7128146886825562
Loss of batch at epoch 19 : 0.7206950783729553
Loss of batch at epoch 19 : 0.7850533723831177
Loss of batch at epoch 19 : 0.6635885238647461
Loss of batch at epoch 19 : 0.6638287305831909
Loss of batch at epoch 19 : 0.7383466958999634
Loss of batch at epoch 19 : 0.7560312151908875
Loss of batch at epoch 19 : 0.7616742849349976
Loss of batch at epoch 19 : 0.753633439540863
Loss of batch at epoch 19 : 0.6817391514778137
Loss of batch at epoch 19 : 0.7334704995155334
Loss of batch at epoch 19 : 0.7394281029701233
Loss of batch at epoch 19 : 0.7822889089584351
Loss of batch at epoch 19 : 0.7613482475280762
Loss of batch at epoch 19 : 0.8530856966972351
Loss of batch at epoch 19 : 0.7127296328544617
Loss of batch at epoch 19 : 0.7170376181602478
Loss of batch at epoch 19 : 0.7310316562652588
Loss of batch at epoch 19 : 0.7441058158874512
Loss of batch at epoch 19 : 0.7513056397438049
Average train loss of epoch 19: 0.014740302190574093
Average validation loss of epoch 19: 0.014762859151820944
Loss of batch at epoch 20 : 0.7267305254936218
Loss of batch at epoch 20 : 0.7111457586288452
Loss of batch at epoch 20 : 0.6608656048774719
Loss of batch at epoch 20 : 0.7407960891723633
Loss of batch at epoch 20 : 0.7517341375350952
Loss of batch at epoch 20 : 0.7268856763839722
Loss of batch at epoch 20 : 0.7474148869514465
Loss of batch at epoch 20 : 0.657236635684967
Loss of batch at epoch 20 : 0.7125331163406372
Loss of batch at epoch 20 : 0.7139362096786499
Loss of batch at epoch 20 : 0.6692103743553162
Loss of batch at epoch 20 : 0.755628228187561
Loss of batch at epoch 20 : 0.711811900138855
Loss of batch at epoch 20 : 0.6783072352409363
Loss of batch at epoch 20 : 0.7843943238258362
Loss of batch at epoch 20 : 0.7564473748207092
Loss of batch at epoch 20 : 0.6769088506698608
Loss of batch at epoch 20 : 0.6927856206893921
Loss of batch at epoch 20 : 0.69844651222229
Loss of batch at epoch 20 : 0.7969704866409302
Loss of batch at epoch 20 : 0.6669406294822693
Loss of batch at epoch 20 : 0.6704220175743103
Loss of batch at epoch 20 : 0.6826181411743164
Loss of batch at epoch 20 : 0.7757890820503235
Loss of batch at epoch 20 : 0.6693276762962341
Loss of batch at epoch 20 : 0.8177095651626587
Loss of batch at epoch 20 : 0.6806936860084534
Loss of batch at epoch 20 : 0.6954302787780762
Loss of batch at epoch 20 : 0.7005890607833862
Loss of batch at epoch 20 : 0.731842577457428
Loss of batch at epoch 20 : 0.7095453143119812
Loss of batch at epoch 20 : 0.6644684672355652
Loss of batch at epoch 20 : 0.7510197162628174
Loss of batch at epoch 20 : 0.7491689324378967
Loss of batch at epoch 20 : 0.7339439392089844
Loss of batch at epoch 20 : 0.7597214579582214
Loss of batch at epoch 20 : 0.7310906648635864
Loss of batch at epoch 20 : 0.6227230429649353
Loss of batch at epoch 20 : 0.7200707197189331
Loss of batch at epoch 20 : 0.6614241600036621
Loss of batch at epoch 20 : 0.9060477018356323
Loss of batch at epoch 20 : 0.7133539319038391
Loss of batch at epoch 20 : 0.6893888115882874
Loss of batch at epoch 20 : 0.6791397333145142
Loss of batch at epoch 20 : 0.6994257569313049
Loss of batch at epoch 20 : 0.6656119227409363
Loss of batch at epoch 20 : 0.7197231650352478
Loss of batch at epoch 20 : 0.7819908261299133
Loss of batch at epoch 20 : 0.7167376279830933
Loss of batch at epoch 20 : 0.6866645812988281
Loss of batch at epoch 20 : 0.6679075360298157
Loss of batch at epoch 20 : 0.7015336751937866
Loss of batch at epoch 20 : 0.7057817578315735
Loss of batch at epoch 20 : 0.6559867858886719
Average train loss of epoch 20: 0.014396570617356703
Average validation loss of epoch 20: 0.01455531778560343

JOB STATISTICS
==============
Job ID: 5614166
Cluster: snellius
User/Group: scur0756/scur0756
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 2-15:12:27
CPU Efficiency: 61.11% of 4-07:26:06 core-walltime
Job Wall-clock time: 05:44:47
Memory Utilized: 108.64 GB
Memory Efficiency: 30.18% of 360.00 GB
