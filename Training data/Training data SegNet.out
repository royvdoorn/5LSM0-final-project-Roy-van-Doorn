wandb: Currently logged in as: r-v-doorn1 (royvdoorn). Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.
  warnings.warn(
Loss of batch at epoch 1 : 2.987037181854248
Loss of batch at epoch 1 : 2.8698668479919434
Loss of batch at epoch 1 : 2.759807825088501
Loss of batch at epoch 1 : 2.6736512184143066
Loss of batch at epoch 1 : 2.602241277694702
Loss of batch at epoch 1 : 2.4847171306610107
Loss of batch at epoch 1 : 2.4230685234069824
Loss of batch at epoch 1 : 2.3740808963775635
Loss of batch at epoch 1 : 2.3113291263580322
Loss of batch at epoch 1 : 2.2797536849975586
Loss of batch at epoch 1 : 2.193899154663086
Loss of batch at epoch 1 : 2.124027729034424
Loss of batch at epoch 1 : 2.1483700275421143
Loss of batch at epoch 1 : 2.060062885284424
Loss of batch at epoch 1 : 1.9852116107940674
Loss of batch at epoch 1 : 1.9633923768997192
Loss of batch at epoch 1 : 1.9512346982955933
Loss of batch at epoch 1 : 1.8166075944900513
Loss of batch at epoch 1 : 1.8703882694244385
Loss of batch at epoch 1 : 1.712602138519287
Loss of batch at epoch 1 : 1.748319387435913
Loss of batch at epoch 1 : 1.7170323133468628
Loss of batch at epoch 1 : 1.7302782535552979
Loss of batch at epoch 1 : 1.6507987976074219
Loss of batch at epoch 1 : 1.5856980085372925
Loss of batch at epoch 1 : 1.5899449586868286
Loss of batch at epoch 1 : 1.5768921375274658
Loss of batch at epoch 1 : 1.5172529220581055
Loss of batch at epoch 1 : 1.5342212915420532
Loss of batch at epoch 1 : 1.4324781894683838
Loss of batch at epoch 1 : 1.4506487846374512
Loss of batch at epoch 1 : 1.4170351028442383
Loss of batch at epoch 1 : 1.4356889724731445
Loss of batch at epoch 1 : 1.3832625150680542
Loss of batch at epoch 1 : 1.4135600328445435
Loss of batch at epoch 1 : 1.3507542610168457
Loss of batch at epoch 1 : 1.3266810178756714
Loss of batch at epoch 1 : 1.3577133417129517
Loss of batch at epoch 1 : 1.2824714183807373
Loss of batch at epoch 1 : 1.2527824640274048
Loss of batch at epoch 1 : 1.2569390535354614
Loss of batch at epoch 1 : 1.300317645072937
Loss of batch at epoch 1 : 1.1940760612487793
Loss of batch at epoch 1 : 1.1975566148757935
Loss of batch at epoch 1 : 1.1704702377319336
Loss of batch at epoch 1 : 1.19989013671875
Loss of batch at epoch 1 : 1.1543023586273193
Loss of batch at epoch 1 : 1.1784777641296387
Loss of batch at epoch 1 : 1.109999418258667
Loss of batch at epoch 1 : 1.1224089860916138
Loss of batch at epoch 1 : 1.1603997945785522
Loss of batch at epoch 1 : 1.1852816343307495
Loss of batch at epoch 1 : 1.1357513666152954
Loss of batch at epoch 1 : 1.0934081077575684
Average train loss of epoch 1: 0.03428086102053334
Average validation loss of epoch 1: 0.021867732809047507
Loss of batch at epoch 2 : 1.0992025136947632
Loss of batch at epoch 2 : 1.0545457601547241
Loss of batch at epoch 2 : 1.0869715213775635
Loss of batch at epoch 2 : 1.0975898504257202
Loss of batch at epoch 2 : 0.9854135513305664
Loss of batch at epoch 2 : 1.03885817527771
Loss of batch at epoch 2 : 1.0424855947494507
Loss of batch at epoch 2 : 0.9685771465301514
Loss of batch at epoch 2 : 1.0691457986831665
Loss of batch at epoch 2 : 1.0299649238586426
Loss of batch at epoch 2 : 1.0123670101165771
Loss of batch at epoch 2 : 0.9780402779579163
Loss of batch at epoch 2 : 1.0375899076461792
Loss of batch at epoch 2 : 0.9693086743354797
Loss of batch at epoch 2 : 1.0316447019577026
Loss of batch at epoch 2 : 0.964203953742981
Loss of batch at epoch 2 : 1.039077877998352
Loss of batch at epoch 2 : 0.9552925825119019
Loss of batch at epoch 2 : 0.9277054071426392
Loss of batch at epoch 2 : 0.9215066432952881
Loss of batch at epoch 2 : 0.9364468455314636
Loss of batch at epoch 2 : 0.9018303155899048
Loss of batch at epoch 2 : 0.936978816986084
Loss of batch at epoch 2 : 0.9538018107414246
Loss of batch at epoch 2 : 0.9801441431045532
Loss of batch at epoch 2 : 0.9447524547576904
Loss of batch at epoch 2 : 0.880660355091095
Loss of batch at epoch 2 : 0.9220744371414185
Loss of batch at epoch 2 : 0.9251210689544678
Loss of batch at epoch 2 : 0.888037383556366
Loss of batch at epoch 2 : 0.9093307852745056
Loss of batch at epoch 2 : 0.9376670122146606
Loss of batch at epoch 2 : 0.8504828810691833
Loss of batch at epoch 2 : 0.911675214767456
Loss of batch at epoch 2 : 0.9201096296310425
Loss of batch at epoch 2 : 0.9001054167747498
Loss of batch at epoch 2 : 0.8204549551010132
Loss of batch at epoch 2 : 0.7996395826339722
Loss of batch at epoch 2 : 0.9021327495574951
Loss of batch at epoch 2 : 0.8593423962593079
Loss of batch at epoch 2 : 0.8002451658248901
Loss of batch at epoch 2 : 0.8233367204666138
Loss of batch at epoch 2 : 0.7950799465179443
Loss of batch at epoch 2 : 0.8720545172691345
Loss of batch at epoch 2 : 0.9143496751785278
Loss of batch at epoch 2 : 0.7793796062469482
Loss of batch at epoch 2 : 0.8889724612236023
Loss of batch at epoch 2 : 0.7795051336288452
Loss of batch at epoch 2 : 0.8106856942176819
Loss of batch at epoch 2 : 0.8708162903785706
Loss of batch at epoch 2 : 0.8328155279159546
Loss of batch at epoch 2 : 0.8615931868553162
Loss of batch at epoch 2 : 0.819077730178833
Loss of batch at epoch 2 : 0.7756672501564026
Average train loss of epoch 2: 0.01867582479281778
Average validation loss of epoch 2: 0.016130171239576756
Loss of batch at epoch 3 : 0.8223344683647156
Loss of batch at epoch 3 : 0.7611050009727478
Loss of batch at epoch 3 : 0.8659085631370544
Loss of batch at epoch 3 : 0.7745107412338257
Loss of batch at epoch 3 : 0.7909923791885376
Loss of batch at epoch 3 : 0.7930766940116882
Loss of batch at epoch 3 : 0.7857675552368164
Loss of batch at epoch 3 : 0.7543696761131287
Loss of batch at epoch 3 : 0.7790290117263794
Loss of batch at epoch 3 : 0.7540545463562012
Loss of batch at epoch 3 : 0.7305105328559875
Loss of batch at epoch 3 : 0.7429285645484924
Loss of batch at epoch 3 : 0.7297177314758301
Loss of batch at epoch 3 : 0.7911790013313293
Loss of batch at epoch 3 : 0.6561919450759888
Loss of batch at epoch 3 : 0.7130876779556274
Loss of batch at epoch 3 : 0.7421456575393677
Loss of batch at epoch 3 : 0.7319508194923401
Loss of batch at epoch 3 : 0.7014729380607605
Loss of batch at epoch 3 : 0.8178159594535828
Loss of batch at epoch 3 : 0.7376492619514465
Loss of batch at epoch 3 : 0.7059212327003479
Loss of batch at epoch 3 : 0.7631975412368774
Loss of batch at epoch 3 : 0.7677647471427917
Loss of batch at epoch 3 : 0.7232280373573303
Loss of batch at epoch 3 : 0.7344385981559753
Loss of batch at epoch 3 : 0.6833577156066895
Loss of batch at epoch 3 : 0.7358694672584534
Loss of batch at epoch 3 : 0.7661259174346924
Loss of batch at epoch 3 : 0.7714072465896606
Loss of batch at epoch 3 : 0.6672371625900269
Loss of batch at epoch 3 : 0.7483556270599365
Loss of batch at epoch 3 : 0.7509570717811584
Loss of batch at epoch 3 : 0.7297717928886414
Loss of batch at epoch 3 : 0.726768434047699
Loss of batch at epoch 3 : 0.7778099179267883
Loss of batch at epoch 3 : 0.7571494579315186
Loss of batch at epoch 3 : 0.7984359860420227
Loss of batch at epoch 3 : 0.7606398463249207
Loss of batch at epoch 3 : 0.5846232175827026
Loss of batch at epoch 3 : 0.7210285067558289
Loss of batch at epoch 3 : 0.7163339853286743
Loss of batch at epoch 3 : 0.6766898036003113
Loss of batch at epoch 3 : 0.8194344639778137
Loss of batch at epoch 3 : 0.7065320611000061
Loss of batch at epoch 3 : 0.6417984366416931
Loss of batch at epoch 3 : 0.6502587795257568
Loss of batch at epoch 3 : 0.6638535261154175
Loss of batch at epoch 3 : 0.7301216125488281
Loss of batch at epoch 3 : 0.668257474899292
Loss of batch at epoch 3 : 0.6650800108909607
Loss of batch at epoch 3 : 0.6632701754570007
Loss of batch at epoch 3 : 0.7702337503433228
Loss of batch at epoch 3 : 0.6681471467018127
Average train loss of epoch 3: 0.014820722789351311
Average validation loss of epoch 3: 0.013700343944408276
Loss of batch at epoch 4 : 0.6464360356330872
Loss of batch at epoch 4 : 0.6515857577323914
Loss of batch at epoch 4 : 0.685315728187561
Loss of batch at epoch 4 : 0.6776664853096008
Loss of batch at epoch 4 : 0.6496478319168091
Loss of batch at epoch 4 : 0.6788482666015625
Loss of batch at epoch 4 : 0.71083664894104
Loss of batch at epoch 4 : 0.6440175175666809
Loss of batch at epoch 4 : 0.6465122103691101
Loss of batch at epoch 4 : 0.6392993330955505
Loss of batch at epoch 4 : 0.6433151960372925
Loss of batch at epoch 4 : 0.6542161703109741
Loss of batch at epoch 4 : 0.56217360496521
Loss of batch at epoch 4 : 0.6945128440856934
Loss of batch at epoch 4 : 0.6214210987091064
Loss of batch at epoch 4 : 0.6130013465881348
Loss of batch at epoch 4 : 0.627113401889801
Loss of batch at epoch 4 : 0.6621415019035339
Loss of batch at epoch 4 : 0.732288122177124
Loss of batch at epoch 4 : 0.6750473976135254
Loss of batch at epoch 4 : 0.6063442230224609
Loss of batch at epoch 4 : 0.6827592849731445
Loss of batch at epoch 4 : 0.7149235010147095
Loss of batch at epoch 4 : 0.6768646836280823
Loss of batch at epoch 4 : 0.6524531245231628
Loss of batch at epoch 4 : 0.6537964344024658
Loss of batch at epoch 4 : 0.6507291793823242
Loss of batch at epoch 4 : 0.6454105377197266
Loss of batch at epoch 4 : 0.6315290927886963
Loss of batch at epoch 4 : 0.6552004218101501
Loss of batch at epoch 4 : 0.62978196144104
Loss of batch at epoch 4 : 0.7969416975975037
Loss of batch at epoch 4 : 0.5989741086959839
Loss of batch at epoch 4 : 0.7023006677627563
Loss of batch at epoch 4 : 0.6164622902870178
Loss of batch at epoch 4 : 0.6439599394798279
Loss of batch at epoch 4 : 0.7226109504699707
Loss of batch at epoch 4 : 0.6310935616493225
Loss of batch at epoch 4 : 0.6256095767021179
Loss of batch at epoch 4 : 0.6328107118606567
Loss of batch at epoch 4 : 0.6679673790931702
Loss of batch at epoch 4 : 0.7218948602676392
Loss of batch at epoch 4 : 0.5981197953224182
Loss of batch at epoch 4 : 0.6573086380958557
Loss of batch at epoch 4 : 0.6676288843154907
Loss of batch at epoch 4 : 0.6890065670013428
Loss of batch at epoch 4 : 0.6085512638092041
Loss of batch at epoch 4 : 0.6290228366851807
Loss of batch at epoch 4 : 0.5949587821960449
Loss of batch at epoch 4 : 0.5987450480461121
Loss of batch at epoch 4 : 0.6488060355186462
Loss of batch at epoch 4 : 0.6115036010742188
Loss of batch at epoch 4 : 0.6068036556243896
Loss of batch at epoch 4 : 0.6851545572280884
Average train loss of epoch 4: 0.013170809243667295
Average validation loss of epoch 4: 0.01270651977873009
Loss of batch at epoch 5 : 0.6789834499359131
Loss of batch at epoch 5 : 0.5737543106079102
Loss of batch at epoch 5 : 0.6381161212921143
Loss of batch at epoch 5 : 0.6770796775817871
Loss of batch at epoch 5 : 0.7025555968284607
Loss of batch at epoch 5 : 0.5731086134910583
Loss of batch at epoch 5 : 0.6912480592727661
Loss of batch at epoch 5 : 0.6646045446395874
Loss of batch at epoch 5 : 0.6503469944000244
Loss of batch at epoch 5 : 0.5876052975654602
Loss of batch at epoch 5 : 0.602330207824707
Loss of batch at epoch 5 : 0.5849075317382812
Loss of batch at epoch 5 : 0.6201985478401184
Loss of batch at epoch 5 : 0.593734860420227
Loss of batch at epoch 5 : 0.6047356724739075
Loss of batch at epoch 5 : 0.5646719932556152
Loss of batch at epoch 5 : 0.5927438139915466
Loss of batch at epoch 5 : 0.6890998482704163
Loss of batch at epoch 5 : 0.570617139339447
Loss of batch at epoch 5 : 0.6199314594268799
Loss of batch at epoch 5 : 0.6379299163818359
Loss of batch at epoch 5 : 0.6117582321166992
Loss of batch at epoch 5 : 0.6071576476097107
Loss of batch at epoch 5 : 0.6221261620521545
Loss of batch at epoch 5 : 0.6191642880439758
Loss of batch at epoch 5 : 0.5738030672073364
Loss of batch at epoch 5 : 0.6132586002349854
Loss of batch at epoch 5 : 0.6678348779678345
Loss of batch at epoch 5 : 0.5357168912887573
Loss of batch at epoch 5 : 0.5580453276634216
Loss of batch at epoch 5 : 0.6515527367591858
Loss of batch at epoch 5 : 0.5786176919937134
Loss of batch at epoch 5 : 0.5740352272987366
Loss of batch at epoch 5 : 0.6272109746932983
Loss of batch at epoch 5 : 0.6494409441947937
Loss of batch at epoch 5 : 0.6387094855308533
Loss of batch at epoch 5 : 0.5902675986289978
Loss of batch at epoch 5 : 0.6154441833496094
Loss of batch at epoch 5 : 0.5401233434677124
Loss of batch at epoch 5 : 0.5701307058334351
Loss of batch at epoch 5 : 0.5871148109436035
Loss of batch at epoch 5 : 0.5870967507362366
Loss of batch at epoch 5 : 0.5791942477226257
Loss of batch at epoch 5 : 0.5670525431632996
Loss of batch at epoch 5 : 0.6200814843177795
Loss of batch at epoch 5 : 0.5431122779846191
Loss of batch at epoch 5 : 0.632850170135498
Loss of batch at epoch 5 : 0.547340452671051
Loss of batch at epoch 5 : 0.6059349775314331
Loss of batch at epoch 5 : 0.6005855202674866
Loss of batch at epoch 5 : 0.5796739459037781
Loss of batch at epoch 5 : 0.5670503377914429
Loss of batch at epoch 5 : 0.6220752596855164
Loss of batch at epoch 5 : 0.55517578125
Average train loss of epoch 5: 0.012231903702933188
Average validation loss of epoch 5: 0.011673054711184518
Loss of batch at epoch 6 : 0.5115091800689697
Loss of batch at epoch 6 : 0.5920974016189575
Loss of batch at epoch 6 : 0.6405127644538879
Loss of batch at epoch 6 : 0.5840727686882019
Loss of batch at epoch 6 : 0.6291074752807617
Loss of batch at epoch 6 : 0.548634946346283
Loss of batch at epoch 6 : 0.6130286455154419
Loss of batch at epoch 6 : 0.5878968834877014
Loss of batch at epoch 6 : 0.5129979848861694
Loss of batch at epoch 6 : 0.5802491903305054
Loss of batch at epoch 6 : 0.5713843107223511
Loss of batch at epoch 6 : 0.5698289275169373
Loss of batch at epoch 6 : 0.5228791236877441
Loss of batch at epoch 6 : 0.574915885925293
Loss of batch at epoch 6 : 0.5430390238761902
Loss of batch at epoch 6 : 0.5479229688644409
Loss of batch at epoch 6 : 0.6147438883781433
Loss of batch at epoch 6 : 0.5605098605155945
Loss of batch at epoch 6 : 0.6034265756607056
Loss of batch at epoch 6 : 0.5137686133384705
Loss of batch at epoch 6 : 0.5813350081443787
Loss of batch at epoch 6 : 0.5331169962882996
Loss of batch at epoch 6 : 0.5276604294776917
Loss of batch at epoch 6 : 0.5304206609725952
Loss of batch at epoch 6 : 0.5630741119384766
Loss of batch at epoch 6 : 0.6034930944442749
Loss of batch at epoch 6 : 0.5586374402046204
Loss of batch at epoch 6 : 0.5526831746101379
Loss of batch at epoch 6 : 0.5523479580879211
Loss of batch at epoch 6 : 0.5595855116844177
Loss of batch at epoch 6 : 0.5511471033096313
Loss of batch at epoch 6 : 0.56357342004776
Loss of batch at epoch 6 : 0.6260160207748413
Loss of batch at epoch 6 : 0.6025171875953674
Loss of batch at epoch 6 : 0.5154934525489807
Loss of batch at epoch 6 : 0.5360237956047058
Loss of batch at epoch 6 : 0.6091011762619019
Loss of batch at epoch 6 : 0.5669587850570679
Loss of batch at epoch 6 : 0.6214222311973572
Loss of batch at epoch 6 : 0.5351867079734802
Loss of batch at epoch 6 : 0.5928088426589966
Loss of batch at epoch 6 : 0.5658494234085083
Loss of batch at epoch 6 : 0.5777598023414612
Loss of batch at epoch 6 : 0.6203860640525818
Loss of batch at epoch 6 : 0.5385315418243408
Loss of batch at epoch 6 : 0.5608276128768921
Loss of batch at epoch 6 : 0.6085182428359985
Loss of batch at epoch 6 : 0.5479504466056824
Loss of batch at epoch 6 : 0.6114431023597717
Loss of batch at epoch 6 : 0.5171281099319458
Loss of batch at epoch 6 : 0.5538196563720703
Loss of batch at epoch 6 : 0.6026960015296936
Loss of batch at epoch 6 : 0.6133589744567871
Loss of batch at epoch 6 : 0.5110023021697998
Average train loss of epoch 6: 0.011476625694633865
Average validation loss of epoch 6: 0.011339238195708303
Loss of batch at epoch 7 : 0.5149629712104797
Loss of batch at epoch 7 : 0.5515027046203613
Loss of batch at epoch 7 : 0.5675613284111023
Loss of batch at epoch 7 : 0.5562055706977844
Loss of batch at epoch 7 : 0.5400503873825073
Loss of batch at epoch 7 : 0.6208204030990601
Loss of batch at epoch 7 : 0.5202146768569946
Loss of batch at epoch 7 : 0.6000516414642334
Loss of batch at epoch 7 : 0.5434274077415466
Loss of batch at epoch 7 : 0.5525873303413391
Loss of batch at epoch 7 : 0.5232071876525879
Loss of batch at epoch 7 : 0.5393126606941223
Loss of batch at epoch 7 : 0.5240523219108582
Loss of batch at epoch 7 : 0.6059023141860962
Loss of batch at epoch 7 : 0.5567368865013123
Loss of batch at epoch 7 : 0.5295361876487732
Loss of batch at epoch 7 : 0.5038629770278931
Loss of batch at epoch 7 : 0.6181195974349976
Loss of batch at epoch 7 : 0.5315547585487366
Loss of batch at epoch 7 : 0.5307511687278748
Loss of batch at epoch 7 : 0.5737293362617493
Loss of batch at epoch 7 : 0.5124804973602295
Loss of batch at epoch 7 : 0.4944213330745697
Loss of batch at epoch 7 : 0.516632616519928
Loss of batch at epoch 7 : 0.48070210218429565
Loss of batch at epoch 7 : 0.5417039394378662
Loss of batch at epoch 7 : 0.5433543920516968
Loss of batch at epoch 7 : 0.5481720566749573
Loss of batch at epoch 7 : 0.5853682160377502
Loss of batch at epoch 7 : 0.5532477498054504
Loss of batch at epoch 7 : 0.511078417301178
Loss of batch at epoch 7 : 0.5181872844696045
Loss of batch at epoch 7 : 0.5307070016860962
Loss of batch at epoch 7 : 0.5172183513641357
Loss of batch at epoch 7 : 0.5147035121917725
Loss of batch at epoch 7 : 0.5485198497772217
Loss of batch at epoch 7 : 0.5728806257247925
Loss of batch at epoch 7 : 0.5151495933532715
Loss of batch at epoch 7 : 0.5117617845535278
Loss of batch at epoch 7 : 0.5418505668640137
Loss of batch at epoch 7 : 0.5614799857139587
Loss of batch at epoch 7 : 0.5284726619720459
Loss of batch at epoch 7 : 0.6091917753219604
Loss of batch at epoch 7 : 0.5610473155975342
Loss of batch at epoch 7 : 0.5683183073997498
Loss of batch at epoch 7 : 0.5029283165931702
Loss of batch at epoch 7 : 0.6378397345542908
Loss of batch at epoch 7 : 0.509236752986908
Loss of batch at epoch 7 : 0.6207295060157776
Loss of batch at epoch 7 : 0.5325562357902527
Loss of batch at epoch 7 : 0.508196234703064
Loss of batch at epoch 7 : 0.5751693844795227
Loss of batch at epoch 7 : 0.5178419351577759
Loss of batch at epoch 7 : 0.4907585680484772
Average train loss of epoch 7: 0.01097313408712739
Average validation loss of epoch 7: 0.011022726694742838
Loss of batch at epoch 8 : 0.46774524450302124
Loss of batch at epoch 8 : 0.531216025352478
Loss of batch at epoch 8 : 0.6594016551971436
Loss of batch at epoch 8 : 0.5990193486213684
Loss of batch at epoch 8 : 0.5279436111450195
Loss of batch at epoch 8 : 0.5129547119140625
Loss of batch at epoch 8 : 0.5445247292518616
Loss of batch at epoch 8 : 0.5570229291915894
Loss of batch at epoch 8 : 0.5233259201049805
Loss of batch at epoch 8 : 0.5525369048118591
Loss of batch at epoch 8 : 0.5120993256568909
Loss of batch at epoch 8 : 0.602759838104248
Loss of batch at epoch 8 : 0.5581493973731995
Loss of batch at epoch 8 : 0.5166260004043579
Loss of batch at epoch 8 : 0.5181695818901062
Loss of batch at epoch 8 : 0.5590471029281616
Loss of batch at epoch 8 : 0.5539685487747192
Loss of batch at epoch 8 : 0.49896925687789917
Loss of batch at epoch 8 : 0.5023387670516968
Loss of batch at epoch 8 : 0.5192385911941528
Loss of batch at epoch 8 : 0.5290735363960266
Loss of batch at epoch 8 : 0.5151899456977844
Loss of batch at epoch 8 : 0.5486382246017456
Loss of batch at epoch 8 : 0.5265699625015259
Loss of batch at epoch 8 : 0.526681661605835
Loss of batch at epoch 8 : 0.5183998942375183
Loss of batch at epoch 8 : 0.48895448446273804
Loss of batch at epoch 8 : 0.5941452383995056
Loss of batch at epoch 8 : 0.6026578545570374
Loss of batch at epoch 8 : 0.4918472468852997
Loss of batch at epoch 8 : 0.4879641830921173
Loss of batch at epoch 8 : 0.4576750099658966
Loss of batch at epoch 8 : 0.5352206230163574
Loss of batch at epoch 8 : 0.49974021315574646
Loss of batch at epoch 8 : 0.5356252789497375
Loss of batch at epoch 8 : 0.583449125289917
Loss of batch at epoch 8 : 0.5560349225997925
Loss of batch at epoch 8 : 0.477168470621109
Loss of batch at epoch 8 : 0.5314831137657166
Loss of batch at epoch 8 : 0.5744656920433044
Loss of batch at epoch 8 : 0.4688807725906372
Loss of batch at epoch 8 : 0.47165295481681824
Loss of batch at epoch 8 : 0.4968346655368805
Loss of batch at epoch 8 : 0.5419462323188782
Loss of batch at epoch 8 : 0.4668334722518921
Loss of batch at epoch 8 : 0.4808456003665924
Loss of batch at epoch 8 : 0.5262187123298645
Loss of batch at epoch 8 : 0.5148968696594238
Loss of batch at epoch 8 : 0.47587066888809204
Loss of batch at epoch 8 : 0.5605549216270447
Loss of batch at epoch 8 : 0.4971762001514435
Loss of batch at epoch 8 : 0.49184849858283997
Loss of batch at epoch 8 : 0.5704036951065063
Loss of batch at epoch 8 : 0.4804990589618683
Average train loss of epoch 8: 0.010620800927114451
Average validation loss of epoch 8: 0.010462194179445003
Loss of batch at epoch 9 : 0.5013492107391357
Loss of batch at epoch 9 : 0.5323691368103027
Loss of batch at epoch 9 : 0.4767824113368988
Loss of batch at epoch 9 : 0.5100181698799133
Loss of batch at epoch 9 : 0.504943311214447
Loss of batch at epoch 9 : 0.5234199166297913
Loss of batch at epoch 9 : 0.5098804235458374
Loss of batch at epoch 9 : 0.46258267760276794
Loss of batch at epoch 9 : 0.501404881477356
Loss of batch at epoch 9 : 0.49528270959854126
Loss of batch at epoch 9 : 0.4628683924674988
Loss of batch at epoch 9 : 0.4527401626110077
Loss of batch at epoch 9 : 0.4806309640407562
Loss of batch at epoch 9 : 0.4610983729362488
Loss of batch at epoch 9 : 0.5502057075500488
Loss of batch at epoch 9 : 0.4907112419605255
Loss of batch at epoch 9 : 0.5058892369270325
Loss of batch at epoch 9 : 0.5071520805358887
Loss of batch at epoch 9 : 0.5790112018585205
Loss of batch at epoch 9 : 0.517216682434082
Loss of batch at epoch 9 : 0.563117504119873
Loss of batch at epoch 9 : 0.5407344102859497
Loss of batch at epoch 9 : 0.5341179966926575
Loss of batch at epoch 9 : 0.5456743836402893
Loss of batch at epoch 9 : 0.5644676685333252
Loss of batch at epoch 9 : 0.45430871844291687
Loss of batch at epoch 9 : 0.511040985584259
Loss of batch at epoch 9 : 0.4668459892272949
Loss of batch at epoch 9 : 0.49451541900634766
Loss of batch at epoch 9 : 0.46452978253364563
Loss of batch at epoch 9 : 0.5174303650856018
Loss of batch at epoch 9 : 0.5035646557807922
Loss of batch at epoch 9 : 0.4904550611972809
Loss of batch at epoch 9 : 0.48172029852867126
Loss of batch at epoch 9 : 0.5675609111785889
Loss of batch at epoch 9 : 0.48220568895339966
Loss of batch at epoch 9 : 0.5113699436187744
Loss of batch at epoch 9 : 0.5262918472290039
Loss of batch at epoch 9 : 0.5205041766166687
Loss of batch at epoch 9 : 0.4860938787460327
Loss of batch at epoch 9 : 0.5122384428977966
Loss of batch at epoch 9 : 0.4431706964969635
Loss of batch at epoch 9 : 0.5416215658187866
Loss of batch at epoch 9 : 0.5137789249420166
Loss of batch at epoch 9 : 0.4784561097621918
Loss of batch at epoch 9 : 0.5182411670684814
Loss of batch at epoch 9 : 0.5475287437438965
Loss of batch at epoch 9 : 0.47813689708709717
Loss of batch at epoch 9 : 0.46555495262145996
Loss of batch at epoch 9 : 0.46598827838897705
Loss of batch at epoch 9 : 0.49132832884788513
Loss of batch at epoch 9 : 0.4987019896507263
Loss of batch at epoch 9 : 0.5014046430587769
Loss of batch at epoch 9 : 0.4996386766433716
Average train loss of epoch 9: 0.010159780945325627
Average validation loss of epoch 9: 0.010346197520040904
Loss of batch at epoch 10 : 0.5185339450836182
Loss of batch at epoch 10 : 0.5446841716766357
Loss of batch at epoch 10 : 0.49604082107543945
Loss of batch at epoch 10 : 0.5539905428886414
Loss of batch at epoch 10 : 0.4370843172073364
Loss of batch at epoch 10 : 0.4440814256668091
Loss of batch at epoch 10 : 0.47758379578590393
Loss of batch at epoch 10 : 0.5227785706520081
Loss of batch at epoch 10 : 0.5238894820213318
Loss of batch at epoch 10 : 0.4656059145927429
Loss of batch at epoch 10 : 0.5021464824676514
Loss of batch at epoch 10 : 0.46622204780578613
Loss of batch at epoch 10 : 0.4566190242767334
Loss of batch at epoch 10 : 0.4222092032432556
Loss of batch at epoch 10 : 0.4723318815231323
Loss of batch at epoch 10 : 0.4741783142089844
Loss of batch at epoch 10 : 0.45728909969329834
Loss of batch at epoch 10 : 0.4652995765209198
Loss of batch at epoch 10 : 0.4845294952392578
Loss of batch at epoch 10 : 0.5184032320976257
Loss of batch at epoch 10 : 0.49405092000961304
Loss of batch at epoch 10 : 0.5303641557693481
Loss of batch at epoch 10 : 0.5175692439079285
Loss of batch at epoch 10 : 0.5194676518440247
Loss of batch at epoch 10 : 0.4690572917461395
Loss of batch at epoch 10 : 0.5103264451026917
Loss of batch at epoch 10 : 0.4279177486896515
Loss of batch at epoch 10 : 0.4555104076862335
Loss of batch at epoch 10 : 0.4768712520599365
Loss of batch at epoch 10 : 0.49342429637908936
Loss of batch at epoch 10 : 0.47504639625549316
Loss of batch at epoch 10 : 0.5361582040786743
Loss of batch at epoch 10 : 0.4415033459663391
Loss of batch at epoch 10 : 0.4515734910964966
Loss of batch at epoch 10 : 0.5114017128944397
Loss of batch at epoch 10 : 0.46651437878608704
Loss of batch at epoch 10 : 0.5140163898468018
Loss of batch at epoch 10 : 0.501816987991333
Loss of batch at epoch 10 : 0.5378506183624268
Loss of batch at epoch 10 : 0.5153763890266418
Loss of batch at epoch 10 : 0.6048533320426941
Loss of batch at epoch 10 : 0.46808677911758423
Loss of batch at epoch 10 : 0.48874181509017944
Loss of batch at epoch 10 : 0.46898791193962097
Loss of batch at epoch 10 : 0.5264542102813721
Loss of batch at epoch 10 : 0.5022408962249756
Loss of batch at epoch 10 : 0.5115817189216614
Loss of batch at epoch 10 : 0.461108922958374
Loss of batch at epoch 10 : 0.4560850262641907
Loss of batch at epoch 10 : 0.5421818494796753
Loss of batch at epoch 10 : 0.5377441644668579
Loss of batch at epoch 10 : 0.49019888043403625
Loss of batch at epoch 10 : 0.5696366429328918
Loss of batch at epoch 10 : 0.534332811832428
Average train loss of epoch 10: 0.00997444192716842
Average validation loss of epoch 10: 0.009955333138154412
Loss of batch at epoch 11 : 0.4272933304309845
Loss of batch at epoch 11 : 0.5232427716255188
Loss of batch at epoch 11 : 0.49683690071105957
Loss of batch at epoch 11 : 0.5013357400894165
Loss of batch at epoch 11 : 0.5047292709350586
Loss of batch at epoch 11 : 0.48013684153556824
Loss of batch at epoch 11 : 0.49769720435142517
Loss of batch at epoch 11 : 0.4808824956417084
Loss of batch at epoch 11 : 0.4883222281932831
Loss of batch at epoch 11 : 0.5013778805732727
Loss of batch at epoch 11 : 0.4840565323829651
Loss of batch at epoch 11 : 0.49822860956192017
Loss of batch at epoch 11 : 0.4799277186393738
Loss of batch at epoch 11 : 0.4346417784690857
Loss of batch at epoch 11 : 0.48090097308158875
Loss of batch at epoch 11 : 0.48089247941970825
Loss of batch at epoch 11 : 0.5538454055786133
Loss of batch at epoch 11 : 0.4384608864784241
Loss of batch at epoch 11 : 0.46440303325653076
Loss of batch at epoch 11 : 0.4576023519039154
Loss of batch at epoch 11 : 0.47030144929885864
Loss of batch at epoch 11 : 0.5066779851913452
Loss of batch at epoch 11 : 0.43399569392204285
Loss of batch at epoch 11 : 0.47618937492370605
Loss of batch at epoch 11 : 0.45837414264678955
Loss of batch at epoch 11 : 0.43864333629608154
Loss of batch at epoch 11 : 0.46199288964271545
Loss of batch at epoch 11 : 0.5015910267829895
Loss of batch at epoch 11 : 0.45854276418685913
Loss of batch at epoch 11 : 0.5146926045417786
Loss of batch at epoch 11 : 0.5540274381637573
Loss of batch at epoch 11 : 0.5100197792053223
Loss of batch at epoch 11 : 0.46242186427116394
Loss of batch at epoch 11 : 0.44677233695983887
Loss of batch at epoch 11 : 0.4918253719806671
Loss of batch at epoch 11 : 0.43353110551834106
Loss of batch at epoch 11 : 0.44206660985946655
Loss of batch at epoch 11 : 0.4709767699241638
Loss of batch at epoch 11 : 0.48323166370391846
Loss of batch at epoch 11 : 0.5342691540718079
Loss of batch at epoch 11 : 0.538056492805481
Loss of batch at epoch 11 : 0.4801922142505646
Loss of batch at epoch 11 : 0.5095354914665222
Loss of batch at epoch 11 : 0.48424434661865234
Loss of batch at epoch 11 : 0.4458765685558319
Loss of batch at epoch 11 : 0.44877544045448303
Loss of batch at epoch 11 : 0.4771282374858856
Loss of batch at epoch 11 : 0.4745357632637024
Loss of batch at epoch 11 : 0.43743616342544556
Loss of batch at epoch 11 : 0.43107008934020996
Loss of batch at epoch 11 : 0.4956238865852356
Loss of batch at epoch 11 : 0.46978944540023804
Loss of batch at epoch 11 : 0.46536877751350403
Loss of batch at epoch 11 : 0.5654377341270447
Average train loss of epoch 11: 0.0096893310546875
Average validation loss of epoch 11: 0.009860343804664483
Loss of batch at epoch 12 : 0.4683722257614136
Loss of batch at epoch 12 : 0.49465087056159973
Loss of batch at epoch 12 : 0.5233550667762756
Loss of batch at epoch 12 : 0.4374157190322876
Loss of batch at epoch 12 : 0.4683859646320343
Loss of batch at epoch 12 : 0.49551811814308167
Loss of batch at epoch 12 : 0.5034574270248413
Loss of batch at epoch 12 : 0.4470903277397156
Loss of batch at epoch 12 : 0.45186203718185425
Loss of batch at epoch 12 : 0.5134443044662476
Loss of batch at epoch 12 : 0.4523364007472992
Loss of batch at epoch 12 : 0.45564138889312744
Loss of batch at epoch 12 : 0.4708501994609833
Loss of batch at epoch 12 : 0.42878225445747375
Loss of batch at epoch 12 : 0.4866856336593628
Loss of batch at epoch 12 : 0.4411531984806061
Loss of batch at epoch 12 : 0.4760810434818268
Loss of batch at epoch 12 : 0.45878249406814575
Loss of batch at epoch 12 : 0.5006534457206726
Loss of batch at epoch 12 : 0.4255232512950897
Loss of batch at epoch 12 : 0.45170319080352783
Loss of batch at epoch 12 : 0.4446682631969452
Loss of batch at epoch 12 : 0.5486893653869629
Loss of batch at epoch 12 : 0.4110357463359833
Loss of batch at epoch 12 : 0.4825580418109894
Loss of batch at epoch 12 : 0.43019211292266846
Loss of batch at epoch 12 : 0.44982486963272095
Loss of batch at epoch 12 : 0.4582548141479492
Loss of batch at epoch 12 : 0.4536103904247284
Loss of batch at epoch 12 : 0.4229181110858917
Loss of batch at epoch 12 : 0.48256802558898926
Loss of batch at epoch 12 : 0.423777312040329
Loss of batch at epoch 12 : 0.5013244152069092
Loss of batch at epoch 12 : 0.46634700894355774
Loss of batch at epoch 12 : 0.4701708257198334
Loss of batch at epoch 12 : 0.45263198018074036
Loss of batch at epoch 12 : 0.4973316788673401
Loss of batch at epoch 12 : 0.49259620904922485
Loss of batch at epoch 12 : 0.45469650626182556
Loss of batch at epoch 12 : 0.4701526165008545
Loss of batch at epoch 12 : 0.4344436526298523
Loss of batch at epoch 12 : 0.4852871000766754
Loss of batch at epoch 12 : 0.4377705454826355
Loss of batch at epoch 12 : 0.4514634907245636
Loss of batch at epoch 12 : 0.4212249517440796
Loss of batch at epoch 12 : 0.4805590808391571
Loss of batch at epoch 12 : 0.46696218848228455
Loss of batch at epoch 12 : 0.44065192341804504
Loss of batch at epoch 12 : 0.4158710837364197
Loss of batch at epoch 12 : 0.4927883744239807
Loss of batch at epoch 12 : 0.4846321642398834
Loss of batch at epoch 12 : 0.5162321925163269
Loss of batch at epoch 12 : 0.448555052280426
Loss of batch at epoch 12 : 0.44300609827041626
Average train loss of epoch 12: 0.009366892984858906
Average validation loss of epoch 12: 0.009868503018260404
Loss of batch at epoch 13 : 0.46523845195770264
Loss of batch at epoch 13 : 0.4869415760040283
Loss of batch at epoch 13 : 0.4672820568084717
Loss of batch at epoch 13 : 0.430972695350647
Loss of batch at epoch 13 : 0.45881015062332153
Loss of batch at epoch 13 : 0.42386919260025024
Loss of batch at epoch 13 : 0.44077837467193604
Loss of batch at epoch 13 : 0.48117029666900635
Loss of batch at epoch 13 : 0.506572961807251
Loss of batch at epoch 13 : 0.4490835964679718
Loss of batch at epoch 13 : 0.4343752861022949
Loss of batch at epoch 13 : 0.4583593010902405
Loss of batch at epoch 13 : 0.4200986921787262
Loss of batch at epoch 13 : 0.3949177861213684
Loss of batch at epoch 13 : 0.4424278736114502
Loss of batch at epoch 13 : 0.5110387206077576
Loss of batch at epoch 13 : 0.4543633460998535
Loss of batch at epoch 13 : 0.46440714597702026
Loss of batch at epoch 13 : 0.5054336786270142
Loss of batch at epoch 13 : 0.4675227105617523
Loss of batch at epoch 13 : 0.4646609127521515
Loss of batch at epoch 13 : 0.42348816990852356
Loss of batch at epoch 13 : 0.4570148289203644
Loss of batch at epoch 13 : 0.4991181492805481
Loss of batch at epoch 13 : 0.4294893145561218
Loss of batch at epoch 13 : 0.4482796788215637
Loss of batch at epoch 13 : 0.5011935830116272
Loss of batch at epoch 13 : 0.41295236349105835
Loss of batch at epoch 13 : 0.4453492760658264
Loss of batch at epoch 13 : 0.43410220742225647
Loss of batch at epoch 13 : 0.43768319487571716
Loss of batch at epoch 13 : 0.408839613199234
Loss of batch at epoch 13 : 0.43755945563316345
Loss of batch at epoch 13 : 0.4391024708747864
Loss of batch at epoch 13 : 0.4102751612663269
Loss of batch at epoch 13 : 0.46510642766952515
Loss of batch at epoch 13 : 0.4231020510196686
Loss of batch at epoch 13 : 0.42754480242729187
Loss of batch at epoch 13 : 0.48601698875427246
Loss of batch at epoch 13 : 0.39427900314331055
Loss of batch at epoch 13 : 0.43001800775527954
Loss of batch at epoch 13 : 0.4209740161895752
Loss of batch at epoch 13 : 0.5023497939109802
Loss of batch at epoch 13 : 0.4722025990486145
Loss of batch at epoch 13 : 0.45642489194869995
Loss of batch at epoch 13 : 0.4669497013092041
Loss of batch at epoch 13 : 0.4929454028606415
Loss of batch at epoch 13 : 0.4665036201477051
Loss of batch at epoch 13 : 0.4790651202201843
Loss of batch at epoch 13 : 0.46211546659469604
Loss of batch at epoch 13 : 0.46215465664863586
Loss of batch at epoch 13 : 0.4672025144100189
Loss of batch at epoch 13 : 0.4084535241127014
Loss of batch at epoch 13 : 0.42864665389060974
Average train loss of epoch 13: 0.009120548011831065
Average validation loss of epoch 13: 0.009374301441590793
Loss of batch at epoch 14 : 0.4310379922389984
Loss of batch at epoch 14 : 0.40416428446769714
Loss of batch at epoch 14 : 0.43528252840042114
Loss of batch at epoch 14 : 0.4529808461666107
Loss of batch at epoch 14 : 0.4085165560245514
Loss of batch at epoch 14 : 0.45953869819641113
Loss of batch at epoch 14 : 0.46186572313308716
Loss of batch at epoch 14 : 0.4153370261192322
Loss of batch at epoch 14 : 0.4913374185562134
Loss of batch at epoch 14 : 0.4326961040496826
Loss of batch at epoch 14 : 0.45924457907676697
Loss of batch at epoch 14 : 0.4790840148925781
Loss of batch at epoch 14 : 0.4377622902393341
Loss of batch at epoch 14 : 0.4760535955429077
Loss of batch at epoch 14 : 0.4116377830505371
Loss of batch at epoch 14 : 0.4586842358112335
Loss of batch at epoch 14 : 0.410113126039505
Loss of batch at epoch 14 : 0.4118386507034302
Loss of batch at epoch 14 : 0.47014641761779785
Loss of batch at epoch 14 : 0.4772661030292511
Loss of batch at epoch 14 : 0.45532938838005066
Loss of batch at epoch 14 : 0.44971439242362976
Loss of batch at epoch 14 : 0.431136816740036
Loss of batch at epoch 14 : 0.42080479860305786
Loss of batch at epoch 14 : 0.44505834579467773
Loss of batch at epoch 14 : 0.45645618438720703
Loss of batch at epoch 14 : 0.43636083602905273
Loss of batch at epoch 14 : 0.41906869411468506
Loss of batch at epoch 14 : 0.440336674451828
Loss of batch at epoch 14 : 0.4604671895503998
Loss of batch at epoch 14 : 0.42598956823349
Loss of batch at epoch 14 : 0.4347827434539795
Loss of batch at epoch 14 : 0.4215227961540222
Loss of batch at epoch 14 : 0.46211472153663635
Loss of batch at epoch 14 : 0.4467121958732605
Loss of batch at epoch 14 : 0.45772475004196167
Loss of batch at epoch 14 : 0.426522433757782
Loss of batch at epoch 14 : 0.455506294965744
Loss of batch at epoch 14 : 0.45458847284317017
Loss of batch at epoch 14 : 0.4527822434902191
Loss of batch at epoch 14 : 0.4265196919441223
Loss of batch at epoch 14 : 0.469938188791275
Loss of batch at epoch 14 : 0.41874632239341736
Loss of batch at epoch 14 : 0.44108834862709045
Loss of batch at epoch 14 : 0.4098314344882965
Loss of batch at epoch 14 : 0.42866942286491394
Loss of batch at epoch 14 : 0.44702643156051636
Loss of batch at epoch 14 : 0.4457644522190094
Loss of batch at epoch 14 : 0.4018172323703766
Loss of batch at epoch 14 : 0.4602843225002289
Loss of batch at epoch 14 : 0.41297444701194763
Loss of batch at epoch 14 : 0.4419601559638977
Loss of batch at epoch 14 : 0.47196507453918457
Loss of batch at epoch 14 : 0.4123339056968689
Average train loss of epoch 14: 0.008897120423776344
Average validation loss of epoch 14: 0.009403451925977713
Loss of batch at epoch 15 : 0.4371257722377777
Loss of batch at epoch 15 : 0.4446241855621338
Loss of batch at epoch 15 : 0.48914459347724915
Loss of batch at epoch 15 : 0.4573517441749573
Loss of batch at epoch 15 : 0.4058261215686798
Loss of batch at epoch 15 : 0.40440821647644043
Loss of batch at epoch 15 : 0.41552454233169556
Loss of batch at epoch 15 : 0.4354219436645508
Loss of batch at epoch 15 : 0.3905104398727417
Loss of batch at epoch 15 : 0.41500285267829895
Loss of batch at epoch 15 : 0.4446502923965454
Loss of batch at epoch 15 : 0.4493773579597473
Loss of batch at epoch 15 : 0.45162177085876465
Loss of batch at epoch 15 : 0.4071854054927826
Loss of batch at epoch 15 : 0.44227832555770874
Loss of batch at epoch 15 : 0.3874063193798065
Loss of batch at epoch 15 : 0.4493674039840698
Loss of batch at epoch 15 : 0.4350918233394623
Loss of batch at epoch 15 : 0.39948543906211853
Loss of batch at epoch 15 : 0.416194349527359
Loss of batch at epoch 15 : 0.39426854252815247
Loss of batch at epoch 15 : 0.42377927899360657
Loss of batch at epoch 15 : 0.44047775864601135
Loss of batch at epoch 15 : 0.4474984407424927
Loss of batch at epoch 15 : 0.4625225067138672
Loss of batch at epoch 15 : 0.45973923802375793
Loss of batch at epoch 15 : 0.4064578115940094
Loss of batch at epoch 15 : 0.4194198250770569
Loss of batch at epoch 15 : 0.389525830745697
Loss of batch at epoch 15 : 0.4159802198410034
Loss of batch at epoch 15 : 0.4058942496776581
Loss of batch at epoch 15 : 0.40838050842285156
Loss of batch at epoch 15 : 0.46618929505348206
Loss of batch at epoch 15 : 0.44507306814193726
Loss of batch at epoch 15 : 0.4400530755519867
Loss of batch at epoch 15 : 0.379238098859787
Loss of batch at epoch 15 : 0.4171866476535797
Loss of batch at epoch 15 : 0.4229365885257721
Loss of batch at epoch 15 : 0.4011015295982361
Loss of batch at epoch 15 : 0.40351003408432007
Loss of batch at epoch 15 : 0.4076160490512848
Loss of batch at epoch 15 : 0.4489441215991974
Loss of batch at epoch 15 : 0.44898465275764465
Loss of batch at epoch 15 : 0.39452171325683594
Loss of batch at epoch 15 : 0.4471958577632904
Loss of batch at epoch 15 : 0.4588946998119354
Loss of batch at epoch 15 : 0.43100976943969727
Loss of batch at epoch 15 : 0.4263968765735626
Loss of batch at epoch 15 : 0.47805342078208923
Loss of batch at epoch 15 : 0.42967841029167175
Loss of batch at epoch 15 : 0.40893620252609253
Loss of batch at epoch 15 : 0.41003191471099854
Loss of batch at epoch 15 : 0.42626380920410156
Loss of batch at epoch 15 : 0.47118455171585083
Average train loss of epoch 15: 0.008631270353788757
Average validation loss of epoch 15: 0.009163842056736801
Loss of batch at epoch 16 : 0.4214966595172882
Loss of batch at epoch 16 : 0.4415000379085541
Loss of batch at epoch 16 : 0.3743768036365509
Loss of batch at epoch 16 : 0.391136109828949
Loss of batch at epoch 16 : 0.44770053029060364
Loss of batch at epoch 16 : 0.42733174562454224
Loss of batch at epoch 16 : 0.36342427134513855
Loss of batch at epoch 16 : 0.415287584066391
Loss of batch at epoch 16 : 0.42875248193740845
Loss of batch at epoch 16 : 0.38652485609054565
Loss of batch at epoch 16 : 0.42663341760635376
Loss of batch at epoch 16 : 0.4497917592525482
Loss of batch at epoch 16 : 0.4857066869735718
Loss of batch at epoch 16 : 0.4675806760787964
Loss of batch at epoch 16 : 0.3847310543060303
Loss of batch at epoch 16 : 0.42400220036506653
Loss of batch at epoch 16 : 0.436330646276474
Loss of batch at epoch 16 : 0.40496811270713806
Loss of batch at epoch 16 : 0.3636888265609741
Loss of batch at epoch 16 : 0.3926127254962921
Loss of batch at epoch 16 : 0.3998623192310333
Loss of batch at epoch 16 : 0.4425755739212036
Loss of batch at epoch 16 : 0.42999982833862305
Loss of batch at epoch 16 : 0.420164555311203
Loss of batch at epoch 16 : 0.4139121472835541
Loss of batch at epoch 16 : 0.4428045451641083
Loss of batch at epoch 16 : 0.43755391240119934
Loss of batch at epoch 16 : 0.43447303771972656
Loss of batch at epoch 16 : 0.44837841391563416
Loss of batch at epoch 16 : 0.39919230341911316
Loss of batch at epoch 16 : 0.40774035453796387
Loss of batch at epoch 16 : 0.4091777503490448
Loss of batch at epoch 16 : 0.4012260138988495
Loss of batch at epoch 16 : 0.3709338307380676
Loss of batch at epoch 16 : 0.38223353028297424
Loss of batch at epoch 16 : 0.3817686140537262
Loss of batch at epoch 16 : 0.46957921981811523
Loss of batch at epoch 16 : 0.47391968965530396
Loss of batch at epoch 16 : 0.40839555859565735
Loss of batch at epoch 16 : 0.4186097979545593
Loss of batch at epoch 16 : 0.4225454330444336
Loss of batch at epoch 16 : 0.42247655987739563
Loss of batch at epoch 16 : 0.43673741817474365
Loss of batch at epoch 16 : 0.4156929850578308
Loss of batch at epoch 16 : 0.42883387207984924
Loss of batch at epoch 16 : 0.38185206055641174
Loss of batch at epoch 16 : 0.44410592317581177
Loss of batch at epoch 16 : 0.4311407804489136
Loss of batch at epoch 16 : 0.4291822016239166
Loss of batch at epoch 16 : 0.38125255703926086
Loss of batch at epoch 16 : 0.45385822653770447
Loss of batch at epoch 16 : 0.42204734683036804
Loss of batch at epoch 16 : 0.4239462912082672
Loss of batch at epoch 16 : 0.3616384267807007
Average train loss of epoch 16: 0.008432181047093432
Average validation loss of epoch 16: 0.009324383655381123
Loss of batch at epoch 17 : 0.41000840067863464
Loss of batch at epoch 17 : 0.434716135263443
Loss of batch at epoch 17 : 0.45248350501060486
Loss of batch at epoch 17 : 0.42769837379455566
Loss of batch at epoch 17 : 0.3816255033016205
Loss of batch at epoch 17 : 0.41540318727493286
Loss of batch at epoch 17 : 0.4089439809322357
Loss of batch at epoch 17 : 0.42953890562057495
Loss of batch at epoch 17 : 0.3956638276576996
Loss of batch at epoch 17 : 0.43577641248703003
Loss of batch at epoch 17 : 0.4063127040863037
Loss of batch at epoch 17 : 0.4741596281528473
Loss of batch at epoch 17 : 0.3945149779319763
Loss of batch at epoch 17 : 0.38837820291519165
Loss of batch at epoch 17 : 0.44787660241127014
Loss of batch at epoch 17 : 0.3977154791355133
Loss of batch at epoch 17 : 0.3983112573623657
Loss of batch at epoch 17 : 0.40567928552627563
Loss of batch at epoch 17 : 0.41795727610588074
Loss of batch at epoch 17 : 0.3838067352771759
Loss of batch at epoch 17 : 0.41247108578681946
Loss of batch at epoch 17 : 0.39828282594680786
Loss of batch at epoch 17 : 0.3901005983352661
Loss of batch at epoch 17 : 0.40450334548950195
Loss of batch at epoch 17 : 0.38057541847229004
Loss of batch at epoch 17 : 0.3974224030971527
Loss of batch at epoch 17 : 0.42770349979400635
Loss of batch at epoch 17 : 0.34849366545677185
Loss of batch at epoch 17 : 0.38764798641204834
Loss of batch at epoch 17 : 0.42226457595825195
Loss of batch at epoch 17 : 0.359822541475296
Loss of batch at epoch 17 : 0.40343979001045227
Loss of batch at epoch 17 : 0.41377419233322144
Loss of batch at epoch 17 : 0.4255489110946655
Loss of batch at epoch 17 : 0.38084807991981506
Loss of batch at epoch 17 : 0.4418104290962219
Loss of batch at epoch 17 : 0.4155566692352295
Loss of batch at epoch 17 : 0.41315320134162903
Loss of batch at epoch 17 : 0.43321678042411804
Loss of batch at epoch 17 : 0.44494616985321045
Loss of batch at epoch 17 : 0.40731433033943176
Loss of batch at epoch 17 : 0.3742274045944214
Loss of batch at epoch 17 : 0.4315263032913208
Loss of batch at epoch 17 : 0.3636501133441925
Loss of batch at epoch 17 : 0.344190776348114
Loss of batch at epoch 17 : 0.3693889081478119
Loss of batch at epoch 17 : 0.4040088355541229
Loss of batch at epoch 17 : 0.39494630694389343
Loss of batch at epoch 17 : 0.4203645884990692
Loss of batch at epoch 17 : 0.4012240171432495
Loss of batch at epoch 17 : 0.3896416127681732
Loss of batch at epoch 17 : 0.4067718982696533
Loss of batch at epoch 17 : 0.4299299120903015
Loss of batch at epoch 17 : 0.3839855194091797
Average train loss of epoch 17: 0.008188693535870985
Average validation loss of epoch 17: 0.008656595692490086
Loss of batch at epoch 18 : 0.4121858775615692
Loss of batch at epoch 18 : 0.41378507018089294
Loss of batch at epoch 18 : 0.37523555755615234
Loss of batch at epoch 18 : 0.4068414866924286
Loss of batch at epoch 18 : 0.3763140141963959
Loss of batch at epoch 18 : 0.3968159258365631
Loss of batch at epoch 18 : 0.3802342712879181
Loss of batch at epoch 18 : 0.3650370240211487
Loss of batch at epoch 18 : 0.41316887736320496
Loss of batch at epoch 18 : 0.3955410420894623
Loss of batch at epoch 18 : 0.4217837452888489
Loss of batch at epoch 18 : 0.40800780057907104
Loss of batch at epoch 18 : 0.423412948846817
Loss of batch at epoch 18 : 0.388991117477417
Loss of batch at epoch 18 : 0.409483939409256
Loss of batch at epoch 18 : 0.4045172333717346
Loss of batch at epoch 18 : 0.37567138671875
Loss of batch at epoch 18 : 0.38451334834098816
Loss of batch at epoch 18 : 0.3994513154029846
Loss of batch at epoch 18 : 0.3923988342285156
Loss of batch at epoch 18 : 0.3792853057384491
Loss of batch at epoch 18 : 0.4446461498737335
Loss of batch at epoch 18 : 0.43294888734817505
Loss of batch at epoch 18 : 0.36767345666885376
Loss of batch at epoch 18 : 0.394765704870224
Loss of batch at epoch 18 : 0.3646857440471649
Loss of batch at epoch 18 : 0.3921920955181122
Loss of batch at epoch 18 : 0.38425758481025696
Loss of batch at epoch 18 : 0.3698422908782959
Loss of batch at epoch 18 : 0.4551030695438385
Loss of batch at epoch 18 : 0.370362251996994
Loss of batch at epoch 18 : 0.4157702326774597
Loss of batch at epoch 18 : 0.4208137094974518
Loss of batch at epoch 18 : 0.399652898311615
Loss of batch at epoch 18 : 0.4072954058647156
Loss of batch at epoch 18 : 0.39581605792045593
Loss of batch at epoch 18 : 0.4021245539188385
Loss of batch at epoch 18 : 0.42113620042800903
Loss of batch at epoch 18 : 0.43571344017982483
Loss of batch at epoch 18 : 0.3704148232936859
Loss of batch at epoch 18 : 0.37468641996383667
Loss of batch at epoch 18 : 0.37568339705467224
Loss of batch at epoch 18 : 0.41273564100265503
Loss of batch at epoch 18 : 0.4155207574367523
Loss of batch at epoch 18 : 0.4178616404533386
Loss of batch at epoch 18 : 0.38846027851104736
Loss of batch at epoch 18 : 0.394653856754303
Loss of batch at epoch 18 : 0.4236217141151428
Loss of batch at epoch 18 : 0.4250950515270233
Loss of batch at epoch 18 : 0.4033089578151703
Loss of batch at epoch 18 : 0.40084415674209595
Loss of batch at epoch 18 : 0.43668732047080994
Loss of batch at epoch 18 : 0.4026832580566406
Loss of batch at epoch 18 : 0.35214346647262573
Average train loss of epoch 18: 0.008062687447215302
Average validation loss of epoch 18: 0.008747757484615853
Loss of batch at epoch 19 : 0.4197694659233093
Loss of batch at epoch 19 : 0.40896469354629517
Loss of batch at epoch 19 : 0.37292948365211487
Loss of batch at epoch 19 : 0.4086153209209442
Loss of batch at epoch 19 : 0.40886208415031433
Loss of batch at epoch 19 : 0.4005441963672638
Loss of batch at epoch 19 : 0.39179638028144836
Loss of batch at epoch 19 : 0.45103973150253296
Loss of batch at epoch 19 : 0.40822434425354004
Loss of batch at epoch 19 : 0.4004272222518921
Loss of batch at epoch 19 : 0.3661324381828308
Loss of batch at epoch 19 : 0.37447646260261536
Loss of batch at epoch 19 : 0.3572463393211365
Loss of batch at epoch 19 : 0.38172879815101624
Loss of batch at epoch 19 : 0.4148220121860504
Loss of batch at epoch 19 : 0.3543093502521515
Loss of batch at epoch 19 : 0.37894877791404724
Loss of batch at epoch 19 : 0.361653596162796
Loss of batch at epoch 19 : 0.4234628677368164
Loss of batch at epoch 19 : 0.3827899396419525
Loss of batch at epoch 19 : 0.3972329795360565
Loss of batch at epoch 19 : 0.36180317401885986
Loss of batch at epoch 19 : 0.38469627499580383
Loss of batch at epoch 19 : 0.3601602613925934
Loss of batch at epoch 19 : 0.3781331777572632
Loss of batch at epoch 19 : 0.3916906416416168
Loss of batch at epoch 19 : 0.3754381537437439
Loss of batch at epoch 19 : 0.35864174365997314
Loss of batch at epoch 19 : 0.39535075426101685
Loss of batch at epoch 19 : 0.42194944620132446
Loss of batch at epoch 19 : 0.4105786681175232
Loss of batch at epoch 19 : 0.38603678345680237
Loss of batch at epoch 19 : 0.40106743574142456
Loss of batch at epoch 19 : 0.3994341194629669
Loss of batch at epoch 19 : 0.38910192251205444
Loss of batch at epoch 19 : 0.37285152077674866
Loss of batch at epoch 19 : 0.3781581521034241
Loss of batch at epoch 19 : 0.3946165144443512
Loss of batch at epoch 19 : 0.3821991980075836
Loss of batch at epoch 19 : 0.3757302463054657
Loss of batch at epoch 19 : 0.35982877016067505
Loss of batch at epoch 19 : 0.3759390115737915
Loss of batch at epoch 19 : 0.38654741644859314
Loss of batch at epoch 19 : 0.44550567865371704
Loss of batch at epoch 19 : 0.38362717628479004
Loss of batch at epoch 19 : 0.40963301062583923
Loss of batch at epoch 19 : 0.42477360367774963
Loss of batch at epoch 19 : 0.42379528284072876
Loss of batch at epoch 19 : 0.4095923900604248
Loss of batch at epoch 19 : 0.40187868475914
Loss of batch at epoch 19 : 0.39621424674987793
Loss of batch at epoch 19 : 0.4276440441608429
Loss of batch at epoch 19 : 0.3688112497329712
Loss of batch at epoch 19 : 0.462985098361969
Average train loss of epoch 19: 0.007938158521018339
Average validation loss of epoch 19: 0.008786661456329654
Loss of batch at epoch 20 : 0.3594226837158203
Loss of batch at epoch 20 : 0.3679194450378418
Loss of batch at epoch 20 : 0.3681789040565491
Loss of batch at epoch 20 : 0.4219611883163452
Loss of batch at epoch 20 : 0.3663654923439026
Loss of batch at epoch 20 : 0.38181084394454956
Loss of batch at epoch 20 : 0.3515389859676361
Loss of batch at epoch 20 : 0.38188087940216064
Loss of batch at epoch 20 : 0.4228197932243347
Loss of batch at epoch 20 : 0.4016108512878418
Loss of batch at epoch 20 : 0.36678293347358704
Loss of batch at epoch 20 : 0.3689376413822174
Loss of batch at epoch 20 : 0.37180861830711365
Loss of batch at epoch 20 : 0.35402464866638184
Loss of batch at epoch 20 : 0.3605307936668396
Loss of batch at epoch 20 : 0.38970136642456055
Loss of batch at epoch 20 : 0.4250127375125885
Loss of batch at epoch 20 : 0.38817426562309265
Loss of batch at epoch 20 : 0.42541539669036865
Loss of batch at epoch 20 : 0.36292049288749695
Loss of batch at epoch 20 : 0.3582589328289032
Loss of batch at epoch 20 : 0.3709774315357208
Loss of batch at epoch 20 : 0.4313989281654358
Loss of batch at epoch 20 : 0.41793906688690186
Loss of batch at epoch 20 : 0.4040702283382416
Loss of batch at epoch 20 : 0.4144896864891052
Loss of batch at epoch 20 : 0.3687863051891327
Loss of batch at epoch 20 : 0.40439170598983765
Loss of batch at epoch 20 : 0.39732038974761963
Loss of batch at epoch 20 : 0.4029368758201599
Loss of batch at epoch 20 : 0.3675743043422699
Loss of batch at epoch 20 : 0.39059898257255554
Loss of batch at epoch 20 : 0.3705701231956482
Loss of batch at epoch 20 : 0.38158586621284485
Loss of batch at epoch 20 : 0.35798317193984985
Loss of batch at epoch 20 : 0.406306654214859
Loss of batch at epoch 20 : 0.39157742261886597
Loss of batch at epoch 20 : 0.36098527908325195
Loss of batch at epoch 20 : 0.39968249201774597
Loss of batch at epoch 20 : 0.38827720284461975
Loss of batch at epoch 20 : 0.37170055508613586
Loss of batch at epoch 20 : 0.35631877183914185
Loss of batch at epoch 20 : 0.438679963350296
Loss of batch at epoch 20 : 0.38461732864379883
Loss of batch at epoch 20 : 0.3915601968765259
Loss of batch at epoch 20 : 0.3678087592124939
Loss of batch at epoch 20 : 0.402836412191391
Loss of batch at epoch 20 : 0.42690980434417725
Loss of batch at epoch 20 : 0.3614538609981537
Loss of batch at epoch 20 : 0.3825751543045044
Loss of batch at epoch 20 : 0.3545719385147095
Loss of batch at epoch 20 : 0.3621661365032196
Loss of batch at epoch 20 : 0.34940510988235474
Loss of batch at epoch 20 : 0.3578745424747467
Average train loss of epoch 20: 0.007741227267481125
Average validation loss of epoch 20: 0.008596388177839594
Loss of batch at epoch 21 : 0.37161773443222046
Loss of batch at epoch 21 : 0.3546832501888275
Loss of batch at epoch 21 : 0.3807185888290405
Loss of batch at epoch 21 : 0.42098942399024963
Loss of batch at epoch 21 : 0.37595683336257935
Loss of batch at epoch 21 : 0.3690246045589447
Loss of batch at epoch 21 : 0.37715601921081543
Loss of batch at epoch 21 : 0.3790099024772644
Loss of batch at epoch 21 : 0.3597768545150757
Loss of batch at epoch 21 : 0.3946314752101898
Loss of batch at epoch 21 : 0.36401447653770447
Loss of batch at epoch 21 : 0.38741788268089294
Loss of batch at epoch 21 : 0.3688570559024811
Loss of batch at epoch 21 : 0.40365779399871826
Loss of batch at epoch 21 : 0.3541683852672577
Loss of batch at epoch 21 : 0.3912205100059509
Loss of batch at epoch 21 : 0.3778102695941925
Loss of batch at epoch 21 : 0.36758893728256226
Loss of batch at epoch 21 : 0.37334194779396057
Loss of batch at epoch 21 : 0.3846575617790222
Loss of batch at epoch 21 : 0.3805617690086365
Loss of batch at epoch 21 : 0.40411508083343506
Loss of batch at epoch 21 : 0.3776147663593292
Loss of batch at epoch 21 : 0.3685826361179352
Loss of batch at epoch 21 : 0.3976958692073822
Loss of batch at epoch 21 : 0.37616050243377686
Loss of batch at epoch 21 : 0.3700338304042816
Loss of batch at epoch 21 : 0.36703675985336304
Loss of batch at epoch 21 : 0.4001310169696808
Loss of batch at epoch 21 : 0.38543936610221863
Loss of batch at epoch 21 : 0.39031079411506653
Loss of batch at epoch 21 : 0.36459094285964966
Loss of batch at epoch 21 : 0.39683789014816284
Loss of batch at epoch 21 : 0.3832096755504608
Loss of batch at epoch 21 : 0.3691851794719696
Loss of batch at epoch 21 : 0.3520093262195587
Loss of batch at epoch 21 : 0.3497563600540161
Loss of batch at epoch 21 : 0.3887660503387451
Loss of batch at epoch 21 : 0.3669699430465698
Loss of batch at epoch 21 : 0.3931925594806671
Loss of batch at epoch 21 : 0.34828177094459534
Loss of batch at epoch 21 : 0.34142637252807617
Loss of batch at epoch 21 : 0.35687199234962463
Loss of batch at epoch 21 : 0.35672736167907715
Loss of batch at epoch 21 : 0.4071076512336731
Loss of batch at epoch 21 : 0.3759521543979645
Loss of batch at epoch 21 : 0.35511085391044617
Loss of batch at epoch 21 : 0.366032212972641
Loss of batch at epoch 21 : 0.3421821594238281
Loss of batch at epoch 21 : 0.3687906563282013
Loss of batch at epoch 21 : 0.36071452498435974
Loss of batch at epoch 21 : 0.3399743139743805
Loss of batch at epoch 21 : 0.346640408039093
Loss of batch at epoch 21 : 0.42773470282554626
Average train loss of epoch 21: 0.00755490893477197
Average validation loss of epoch 21: 0.00824127293596364
Loss of batch at epoch 22 : 0.3719927966594696
Loss of batch at epoch 22 : 0.3954518437385559
Loss of batch at epoch 22 : 0.4058414399623871
Loss of batch at epoch 22 : 0.3685465455055237
Loss of batch at epoch 22 : 0.38388508558273315
Loss of batch at epoch 22 : 0.38389405608177185
Loss of batch at epoch 22 : 0.3343343138694763
Loss of batch at epoch 22 : 0.37857764959335327
Loss of batch at epoch 22 : 0.34640365839004517
Loss of batch at epoch 22 : 0.40610426664352417
Loss of batch at epoch 22 : 0.411405086517334
Loss of batch at epoch 22 : 0.34990331530570984
Loss of batch at epoch 22 : 0.3733344078063965
Loss of batch at epoch 22 : 0.34676408767700195
Loss of batch at epoch 22 : 0.3738366961479187
Loss of batch at epoch 22 : 0.3686446249485016
Loss of batch at epoch 22 : 0.3714413046836853
Loss of batch at epoch 22 : 0.3881693184375763
Loss of batch at epoch 22 : 0.38820797204971313
Loss of batch at epoch 22 : 0.33817562460899353
Loss of batch at epoch 22 : 0.3255152106285095
Loss of batch at epoch 22 : 0.3525639772415161
Loss of batch at epoch 22 : 0.34672603011131287
Loss of batch at epoch 22 : 0.3506644666194916
Loss of batch at epoch 22 : 0.3420957624912262
Loss of batch at epoch 22 : 0.3551965355873108
Loss of batch at epoch 22 : 0.38254404067993164
Loss of batch at epoch 22 : 0.3869624435901642
Loss of batch at epoch 22 : 0.34643691778182983
Loss of batch at epoch 22 : 0.39142441749572754
Loss of batch at epoch 22 : 0.3584970533847809
Loss of batch at epoch 22 : 0.3607931435108185
Loss of batch at epoch 22 : 0.38144397735595703
Loss of batch at epoch 22 : 0.3961375057697296
Loss of batch at epoch 22 : 0.3743700385093689
Loss of batch at epoch 22 : 0.3514805734157562
Loss of batch at epoch 22 : 0.37493330240249634
Loss of batch at epoch 22 : 0.39936116337776184
Loss of batch at epoch 22 : 0.3706313669681549
Loss of batch at epoch 22 : 0.35270828008651733
Loss of batch at epoch 22 : 0.35417526960372925
Loss of batch at epoch 22 : 0.3849336802959442
Loss of batch at epoch 22 : 0.3447253108024597
Loss of batch at epoch 22 : 0.3489528000354767
Loss of batch at epoch 22 : 0.3802725374698639
Loss of batch at epoch 22 : 0.35913360118865967
Loss of batch at epoch 22 : 0.3522249460220337
Loss of batch at epoch 22 : 0.34387895464897156
Loss of batch at epoch 22 : 0.3444899320602417
Loss of batch at epoch 22 : 0.3642839789390564
Loss of batch at epoch 22 : 0.3633727729320526
Loss of batch at epoch 22 : 0.33970367908477783
Loss of batch at epoch 22 : 0.37428927421569824
Loss of batch at epoch 22 : 0.3939025104045868
Average train loss of epoch 22: 0.007406174913994673
Average validation loss of epoch 22: 0.008394607389816131
Loss of batch at epoch 23 : 0.35635480284690857
Loss of batch at epoch 23 : 0.36978456377983093
Loss of batch at epoch 23 : 0.34656578302383423
Loss of batch at epoch 23 : 0.36552929878234863
Loss of batch at epoch 23 : 0.34277021884918213
Loss of batch at epoch 23 : 0.3646050691604614
Loss of batch at epoch 23 : 0.3692084848880768
Loss of batch at epoch 23 : 0.3400590121746063
Loss of batch at epoch 23 : 0.3602744936943054
Loss of batch at epoch 23 : 0.34758809208869934
Loss of batch at epoch 23 : 0.3393799364566803
Loss of batch at epoch 23 : 0.4029533267021179
Loss of batch at epoch 23 : 0.35090887546539307
Loss of batch at epoch 23 : 0.35105466842651367
Loss of batch at epoch 23 : 0.41433849930763245
Loss of batch at epoch 23 : 0.3684490919113159
Loss of batch at epoch 23 : 0.3696620464324951
Loss of batch at epoch 23 : 0.36157840490341187
Loss of batch at epoch 23 : 0.3512306809425354
Loss of batch at epoch 23 : 0.37647804617881775
Loss of batch at epoch 23 : 0.3633420169353485
Loss of batch at epoch 23 : 0.35209861397743225
Loss of batch at epoch 23 : 0.32959550619125366
Loss of batch at epoch 23 : 0.3566582500934601
Loss of batch at epoch 23 : 0.3269821107387543
Loss of batch at epoch 23 : 0.4253833293914795
Loss of batch at epoch 23 : 0.33840784430503845
Loss of batch at epoch 23 : 0.3722069263458252
Loss of batch at epoch 23 : 0.3565841317176819
Loss of batch at epoch 23 : 0.36713653802871704
Loss of batch at epoch 23 : 0.3513588309288025
Loss of batch at epoch 23 : 0.3743995726108551
Loss of batch at epoch 23 : 0.3805922567844391
Loss of batch at epoch 23 : 0.3561660051345825
Loss of batch at epoch 23 : 0.36460307240486145
Loss of batch at epoch 23 : 0.3696281611919403
Loss of batch at epoch 23 : 0.36783137917518616
Loss of batch at epoch 23 : 0.36986273527145386
Loss of batch at epoch 23 : 0.3584960699081421
Loss of batch at epoch 23 : 0.33095088601112366
Loss of batch at epoch 23 : 0.357516348361969
Loss of batch at epoch 23 : 0.43290236592292786
Loss of batch at epoch 23 : 0.34816738963127136
Loss of batch at epoch 23 : 0.35310277342796326
Loss of batch at epoch 23 : 0.37953367829322815
Loss of batch at epoch 23 : 0.3561568856239319
Loss of batch at epoch 23 : 0.39581575989723206
Loss of batch at epoch 23 : 0.37811079621315
Loss of batch at epoch 23 : 0.3657783269882202
Loss of batch at epoch 23 : 0.34536927938461304
Loss of batch at epoch 23 : 0.38910555839538574
Loss of batch at epoch 23 : 0.3543548583984375
Loss of batch at epoch 23 : 0.36058852076530457
Loss of batch at epoch 23 : 0.3435342609882355
Average train loss of epoch 23: 0.007326770665665186
Average validation loss of epoch 23: 0.008254499146432587
Loss of batch at epoch 24 : 0.38583892583847046
Loss of batch at epoch 24 : 0.3372671902179718
Loss of batch at epoch 24 : 0.3571819067001343
Loss of batch at epoch 24 : 0.3792465031147003
Loss of batch at epoch 24 : 0.34971314668655396
Loss of batch at epoch 24 : 0.37567785382270813
Loss of batch at epoch 24 : 0.3416730761528015
Loss of batch at epoch 24 : 0.3782072365283966
Loss of batch at epoch 24 : 0.3566763401031494
Loss of batch at epoch 24 : 0.3867376446723938
Loss of batch at epoch 24 : 0.3382207751274109
Loss of batch at epoch 24 : 0.3503437340259552
Loss of batch at epoch 24 : 0.32491013407707214
Loss of batch at epoch 24 : 0.37520483136177063
Loss of batch at epoch 24 : 0.38857731223106384
Loss of batch at epoch 24 : 0.3122904896736145
Loss of batch at epoch 24 : 0.3213178217411041
Loss of batch at epoch 24 : 0.3610675036907196
Loss of batch at epoch 24 : 0.39276206493377686
Loss of batch at epoch 24 : 0.31397441029548645
Loss of batch at epoch 24 : 0.3580419719219208
Loss of batch at epoch 24 : 0.353269100189209
Loss of batch at epoch 24 : 0.34723880887031555
Loss of batch at epoch 24 : 0.38686856627464294
Loss of batch at epoch 24 : 0.3467184603214264
Loss of batch at epoch 24 : 0.3706270456314087
Loss of batch at epoch 24 : 0.33929839730262756
Loss of batch at epoch 24 : 0.37186935544013977
Loss of batch at epoch 24 : 0.3548325300216675
Loss of batch at epoch 24 : 0.34451380372047424
Loss of batch at epoch 24 : 0.3804435431957245
Loss of batch at epoch 24 : 0.34524375200271606
Loss of batch at epoch 24 : 0.31906092166900635
Loss of batch at epoch 24 : 0.34552624821662903
Loss of batch at epoch 24 : 0.35156142711639404
Loss of batch at epoch 24 : 0.33859044313430786
Loss of batch at epoch 24 : 0.35251158475875854
Loss of batch at epoch 24 : 0.34404754638671875
Loss of batch at epoch 24 : 0.3704017400741577
Loss of batch at epoch 24 : 0.3605102598667145
Loss of batch at epoch 24 : 0.3733063340187073
Loss of batch at epoch 24 : 0.40534454584121704
Loss of batch at epoch 24 : 0.3473413288593292
Loss of batch at epoch 24 : 0.34568852186203003
Loss of batch at epoch 24 : 0.37171074748039246
Loss of batch at epoch 24 : 0.36140674352645874
Loss of batch at epoch 24 : 0.3333205282688141
Loss of batch at epoch 24 : 0.3516581952571869
Loss of batch at epoch 24 : 0.37903937697410583
Loss of batch at epoch 24 : 0.36681997776031494
Loss of batch at epoch 24 : 0.3539462089538574
Loss of batch at epoch 24 : 0.37412670254707336
Loss of batch at epoch 24 : 0.3399695158004761
Loss of batch at epoch 24 : 0.3072011172771454
Average train loss of epoch 24: 0.007176603640612601
Average validation loss of epoch 24: 0.008347079408690583
Loss of batch at epoch 25 : 0.35227036476135254
Loss of batch at epoch 25 : 0.39601755142211914
Loss of batch at epoch 25 : 0.3606008291244507
Loss of batch at epoch 25 : 0.34479954838752747
Loss of batch at epoch 25 : 0.38267648220062256
Loss of batch at epoch 25 : 0.3318841755390167
Loss of batch at epoch 25 : 0.36131566762924194
Loss of batch at epoch 25 : 0.3694259822368622
Loss of batch at epoch 25 : 0.36975398659706116
Loss of batch at epoch 25 : 0.3371199369430542
Loss of batch at epoch 25 : 0.3555803894996643
Loss of batch at epoch 25 : 0.3702715337276459
Loss of batch at epoch 25 : 0.4252912402153015
Loss of batch at epoch 25 : 0.3312199115753174
Loss of batch at epoch 25 : 0.34005218744277954
Loss of batch at epoch 25 : 0.3812783360481262
Loss of batch at epoch 25 : 0.375493586063385
Loss of batch at epoch 25 : 0.329900324344635
Loss of batch at epoch 25 : 0.36082810163497925
Loss of batch at epoch 25 : 0.36594945192337036
Loss of batch at epoch 25 : 0.361617773771286
Loss of batch at epoch 25 : 0.37214016914367676
Loss of batch at epoch 25 : 0.36123523116111755
Loss of batch at epoch 25 : 0.35677099227905273
Loss of batch at epoch 25 : 0.3788158893585205
Loss of batch at epoch 25 : 0.3427284061908722
Loss of batch at epoch 25 : 0.42659658193588257
Loss of batch at epoch 25 : 0.36574786901474
Loss of batch at epoch 25 : 0.38148388266563416
Loss of batch at epoch 25 : 0.4000951945781708
Loss of batch at epoch 25 : 0.3921743333339691
Loss of batch at epoch 25 : 0.3612167537212372
Loss of batch at epoch 25 : 0.3641863167285919
Loss of batch at epoch 25 : 0.32996729016304016
Loss of batch at epoch 25 : 0.41593000292778015
Loss of batch at epoch 25 : 0.3661613166332245
Loss of batch at epoch 25 : 0.3785555958747864
Loss of batch at epoch 25 : 0.36799392104148865
Loss of batch at epoch 25 : 0.32363709807395935
Loss of batch at epoch 25 : 0.3858535885810852
Loss of batch at epoch 25 : 0.38089442253112793
Loss of batch at epoch 25 : 0.3622604310512543
Loss of batch at epoch 25 : 0.3781995177268982
Loss of batch at epoch 25 : 0.3487675189971924
Loss of batch at epoch 25 : 0.4017050862312317
Loss of batch at epoch 25 : 0.34007787704467773
Loss of batch at epoch 25 : 0.37866824865341187
Loss of batch at epoch 25 : 0.3647320866584778
Loss of batch at epoch 25 : 0.4310409426689148
Loss of batch at epoch 25 : 0.42989063262939453
Loss of batch at epoch 25 : 0.3840515911579132
Loss of batch at epoch 25 : 0.35223159193992615
Loss of batch at epoch 25 : 0.35945868492126465
Loss of batch at epoch 25 : 0.3879237473011017
Average train loss of epoch 25: 0.007458753778117196
Average validation loss of epoch 25: 0.008593499861180983

JOB STATISTICS
==============
Job ID: 5682130
Cluster: snellius
User/Group: scur0756/scur0756
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 5-12:04:30 core-walltime
Job Wall-clock time: 07:20:15
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 360.00 GB (20.00 GB/core)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
