wandb: Currently logged in as: r-v-doorn1 (royvdoorn). Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.
  warnings.warn(
Loss of batch at epoch 1 : 3.7185535430908203
Loss of batch at epoch 1 : 3.597386598587036
Loss of batch at epoch 1 : 3.5160841941833496
Loss of batch at epoch 1 : 3.4231765270233154
Loss of batch at epoch 1 : 3.348919153213501
Loss of batch at epoch 1 : 3.2347378730773926
Loss of batch at epoch 1 : 3.2260591983795166
Loss of batch at epoch 1 : 3.227403402328491
Loss of batch at epoch 1 : 3.1402649879455566
Loss of batch at epoch 1 : 3.0786654949188232
Loss of batch at epoch 1 : 3.0323076248168945
Loss of batch at epoch 1 : 2.9990644454956055
Loss of batch at epoch 1 : 2.9534168243408203
Loss of batch at epoch 1 : 2.9288251399993896
Loss of batch at epoch 1 : 2.912327527999878
Loss of batch at epoch 1 : 2.815561532974243
Loss of batch at epoch 1 : 2.834594964981079
Loss of batch at epoch 1 : 2.837773561477661
Loss of batch at epoch 1 : 2.7601802349090576
Loss of batch at epoch 1 : 2.7571816444396973
Loss of batch at epoch 1 : 2.734886646270752
Loss of batch at epoch 1 : 2.6679394245147705
Loss of batch at epoch 1 : 2.6753368377685547
Loss of batch at epoch 1 : 2.6553843021392822
Loss of batch at epoch 1 : 2.6170542240142822
Loss of batch at epoch 1 : 2.5963473320007324
Loss of batch at epoch 1 : 2.5502817630767822
Loss of batch at epoch 1 : 2.5915324687957764
Loss of batch at epoch 1 : 2.502656936645508
Loss of batch at epoch 1 : 2.4853084087371826
Loss of batch at epoch 1 : 2.468823194503784
Loss of batch at epoch 1 : 2.4572510719299316
Loss of batch at epoch 1 : 2.397627830505371
Loss of batch at epoch 1 : 2.428583860397339
Loss of batch at epoch 1 : 2.3553855419158936
Loss of batch at epoch 1 : 2.378899097442627
Loss of batch at epoch 1 : 2.427666187286377
Loss of batch at epoch 1 : 2.3533852100372314
Loss of batch at epoch 1 : 2.3251891136169434
Loss of batch at epoch 1 : 2.352424383163452
Loss of batch at epoch 1 : 2.2986819744110107
Loss of batch at epoch 1 : 2.2498939037323
Loss of batch at epoch 1 : 2.2422425746917725
Loss of batch at epoch 1 : 2.253253698348999
Loss of batch at epoch 1 : 2.296708583831787
Loss of batch at epoch 1 : 2.2459347248077393
Loss of batch at epoch 1 : 2.1983959674835205
Loss of batch at epoch 1 : 2.205078363418579
Loss of batch at epoch 1 : 2.2532761096954346
Loss of batch at epoch 1 : 2.162017345428467
Loss of batch at epoch 1 : 2.2080233097076416
Loss of batch at epoch 1 : 2.1978566646575928
Loss of batch at epoch 1 : 2.1417553424835205
Loss of batch at epoch 1 : 2.08284592628479
Average train loss of epoch 1: 0.05354758071044739
Average validation loss of epoch 1: 0.04453296532935968
Loss of batch at epoch 2 : 2.1269690990448
Loss of batch at epoch 2 : 2.1410160064697266
Loss of batch at epoch 2 : 2.161576747894287
Loss of batch at epoch 2 : 2.0948410034179688
Loss of batch at epoch 2 : 2.1783030033111572
Loss of batch at epoch 2 : 2.102041482925415
Loss of batch at epoch 2 : 2.150688648223877
Loss of batch at epoch 2 : 2.1030519008636475
Loss of batch at epoch 2 : 2.0329391956329346
Loss of batch at epoch 2 : 2.076789617538452
Loss of batch at epoch 2 : 2.023571252822876
Loss of batch at epoch 2 : 2.02609920501709
Loss of batch at epoch 2 : 2.026245355606079
Loss of batch at epoch 2 : 2.0166196823120117
Loss of batch at epoch 2 : 2.0020060539245605
Loss of batch at epoch 2 : 1.9487918615341187
Loss of batch at epoch 2 : 2.0205442905426025
Loss of batch at epoch 2 : 2.0391366481781006
Loss of batch at epoch 2 : 2.0105667114257812
Loss of batch at epoch 2 : 1.9860115051269531
Loss of batch at epoch 2 : 1.981397271156311
Loss of batch at epoch 2 : 1.9775347709655762
Loss of batch at epoch 2 : 1.9791412353515625
Loss of batch at epoch 2 : 1.983445167541504
Loss of batch at epoch 2 : 1.932395339012146
Loss of batch at epoch 2 : 1.940544605255127
Loss of batch at epoch 2 : 1.9520208835601807
Loss of batch at epoch 2 : 1.9269678592681885
Loss of batch at epoch 2 : 1.9760769605636597
Loss of batch at epoch 2 : 1.912015438079834
Loss of batch at epoch 2 : 1.8801891803741455
Loss of batch at epoch 2 : 1.8957188129425049
Loss of batch at epoch 2 : 1.8897658586502075
Loss of batch at epoch 2 : 1.8681600093841553
Loss of batch at epoch 2 : 1.8814440965652466
Loss of batch at epoch 2 : 1.8710289001464844
Loss of batch at epoch 2 : 1.8500475883483887
Loss of batch at epoch 2 : 1.8463383913040161
Loss of batch at epoch 2 : 1.8377097845077515
Loss of batch at epoch 2 : 1.8584038019180298
Loss of batch at epoch 2 : 1.8054543733596802
Loss of batch at epoch 2 : 1.8175339698791504
Loss of batch at epoch 2 : 1.7985459566116333
Loss of batch at epoch 2 : 1.8021012544631958
Loss of batch at epoch 2 : 1.8197413682937622
Loss of batch at epoch 2 : 1.7747124433517456
Loss of batch at epoch 2 : 1.8608567714691162
Loss of batch at epoch 2 : 1.8133735656738281
Loss of batch at epoch 2 : 1.7901413440704346
Loss of batch at epoch 2 : 1.7491778135299683
Loss of batch at epoch 2 : 1.7587864398956299
Loss of batch at epoch 2 : 1.7713017463684082
Loss of batch at epoch 2 : 1.686950445175171
Loss of batch at epoch 2 : 1.7399861812591553
Average train loss of epoch 2: 0.0390204614093715
Average validation loss of epoch 2: 0.035536207333959714
Loss of batch at epoch 3 : 1.7333849668502808
Loss of batch at epoch 3 : 1.6969773769378662
Loss of batch at epoch 3 : 1.7633631229400635
Loss of batch at epoch 3 : 1.7071905136108398
Loss of batch at epoch 3 : 1.722617745399475
Loss of batch at epoch 3 : 1.6949663162231445
Loss of batch at epoch 3 : 1.7241812944412231
Loss of batch at epoch 3 : 1.6883533000946045
Loss of batch at epoch 3 : 1.700345516204834
Loss of batch at epoch 3 : 1.7249693870544434
Loss of batch at epoch 3 : 1.6718565225601196
Loss of batch at epoch 3 : 1.6845258474349976
Loss of batch at epoch 3 : 1.7200509309768677
Loss of batch at epoch 3 : 1.6844022274017334
Loss of batch at epoch 3 : 1.6508899927139282
Loss of batch at epoch 3 : 1.6232056617736816
Loss of batch at epoch 3 : 1.6673345565795898
Loss of batch at epoch 3 : 1.6640000343322754
Loss of batch at epoch 3 : 1.6509230136871338
Loss of batch at epoch 3 : 1.644903540611267
Loss of batch at epoch 3 : 1.624678373336792
Loss of batch at epoch 3 : 1.5932916402816772
Loss of batch at epoch 3 : 1.6583080291748047
Loss of batch at epoch 3 : 1.6671271324157715
Loss of batch at epoch 3 : 1.5405235290527344
Loss of batch at epoch 3 : 1.5893850326538086
Loss of batch at epoch 3 : 1.6200534105300903
Loss of batch at epoch 3 : 1.5824880599975586
Loss of batch at epoch 3 : 1.5956214666366577
Loss of batch at epoch 3 : 1.5998866558074951
Loss of batch at epoch 3 : 1.578005075454712
Loss of batch at epoch 3 : 1.5992722511291504
Loss of batch at epoch 3 : 1.600320816040039
Loss of batch at epoch 3 : 1.5906133651733398
Loss of batch at epoch 3 : 1.507177710533142
Loss of batch at epoch 3 : 1.5606213808059692
Loss of batch at epoch 3 : 1.5567114353179932
Loss of batch at epoch 3 : 1.5854367017745972
Loss of batch at epoch 3 : 1.5206724405288696
Loss of batch at epoch 3 : 1.527879238128662
Loss of batch at epoch 3 : 1.5475568771362305
Loss of batch at epoch 3 : 1.47073495388031
Loss of batch at epoch 3 : 1.5470274686813354
Loss of batch at epoch 3 : 1.5363162755966187
Loss of batch at epoch 3 : 1.4911037683486938
Loss of batch at epoch 3 : 1.5298101902008057
Loss of batch at epoch 3 : 1.4931687116622925
Loss of batch at epoch 3 : 1.5419809818267822
Loss of batch at epoch 3 : 1.5499740839004517
Loss of batch at epoch 3 : 1.5389020442962646
Loss of batch at epoch 3 : 1.4946186542510986
Loss of batch at epoch 3 : 1.5407310724258423
Loss of batch at epoch 3 : 1.5160189867019653
Loss of batch at epoch 3 : 1.532347321510315
Average train loss of epoch 3: 0.032429735726434136
Average validation loss of epoch 3: 0.030851132941968513
Loss of batch at epoch 4 : 1.5090558528900146
Loss of batch at epoch 4 : 1.5118584632873535
Loss of batch at epoch 4 : 1.4408366680145264
Loss of batch at epoch 4 : 1.5303645133972168
Loss of batch at epoch 4 : 1.4879851341247559
Loss of batch at epoch 4 : 1.4355032444000244
Loss of batch at epoch 4 : 1.425581455230713
Loss of batch at epoch 4 : 1.45084810256958
Loss of batch at epoch 4 : 1.4619266986846924
Loss of batch at epoch 4 : 1.42878258228302
Loss of batch at epoch 4 : 1.451683759689331
Loss of batch at epoch 4 : 1.4715020656585693
Loss of batch at epoch 4 : 1.417225956916809
Loss of batch at epoch 4 : 1.4810856580734253
Loss of batch at epoch 4 : 1.4325590133666992
Loss of batch at epoch 4 : 1.41696298122406
Loss of batch at epoch 4 : 1.4450575113296509
Loss of batch at epoch 4 : 1.3956339359283447
Loss of batch at epoch 4 : 1.372279167175293
Loss of batch at epoch 4 : 1.4123352766036987
Loss of batch at epoch 4 : 1.3831405639648438
Loss of batch at epoch 4 : 1.4210432767868042
Loss of batch at epoch 4 : 1.371786117553711
Loss of batch at epoch 4 : 1.4179118871688843
Loss of batch at epoch 4 : 1.3641353845596313
Loss of batch at epoch 4 : 1.4177833795547485
Loss of batch at epoch 4 : 1.3638464212417603
Loss of batch at epoch 4 : 1.3067094087600708
Loss of batch at epoch 4 : 1.4033921957015991
Loss of batch at epoch 4 : 1.4028306007385254
Loss of batch at epoch 4 : 1.3339372873306274
Loss of batch at epoch 4 : 1.3880263566970825
Loss of batch at epoch 4 : 1.3224096298217773
Loss of batch at epoch 4 : 1.3519600629806519
Loss of batch at epoch 4 : 1.3609715700149536
Loss of batch at epoch 4 : 1.311511516571045
Loss of batch at epoch 4 : 1.3410972356796265
Loss of batch at epoch 4 : 1.349798560142517
Loss of batch at epoch 4 : 1.269738793373108
Loss of batch at epoch 4 : 1.3463008403778076
Loss of batch at epoch 4 : 1.3632503747940063
Loss of batch at epoch 4 : 1.36033296585083
Loss of batch at epoch 4 : 1.3088581562042236
Loss of batch at epoch 4 : 1.2753633260726929
Loss of batch at epoch 4 : 1.3221135139465332
Loss of batch at epoch 4 : 1.2818413972854614
Loss of batch at epoch 4 : 1.2974683046340942
Loss of batch at epoch 4 : 1.3169015645980835
Loss of batch at epoch 4 : 1.326915979385376
Loss of batch at epoch 4 : 1.3003566265106201
Loss of batch at epoch 4 : 1.27419114112854
Loss of batch at epoch 4 : 1.271890640258789
Loss of batch at epoch 4 : 1.2332301139831543
Loss of batch at epoch 4 : 1.260378360748291
Average train loss of epoch 4: 0.027782112560314952
Average validation loss of epoch 4: 0.026219827157479746
Loss of batch at epoch 5 : 1.2725528478622437
Loss of batch at epoch 5 : 1.2387417554855347
Loss of batch at epoch 5 : 1.2519950866699219
Loss of batch at epoch 5 : 1.253409743309021
Loss of batch at epoch 5 : 1.2811609506607056
Loss of batch at epoch 5 : 1.2905373573303223
Loss of batch at epoch 5 : 1.263920545578003
Loss of batch at epoch 5 : 1.2840993404388428
Loss of batch at epoch 5 : 1.2629314661026
Loss of batch at epoch 5 : 1.2515088319778442
Loss of batch at epoch 5 : 1.2174100875854492
Loss of batch at epoch 5 : 1.276405930519104
Loss of batch at epoch 5 : 1.251166582107544
Loss of batch at epoch 5 : 1.2293858528137207
Loss of batch at epoch 5 : 1.2849754095077515
Loss of batch at epoch 5 : 1.2381237745285034
Loss of batch at epoch 5 : 1.1823898553848267
Loss of batch at epoch 5 : 1.2304027080535889
Loss of batch at epoch 5 : 1.2175683975219727
Loss of batch at epoch 5 : 1.2629783153533936
Loss of batch at epoch 5 : 1.2245887517929077
Loss of batch at epoch 5 : 1.1874159574508667
Loss of batch at epoch 5 : 1.2606866359710693
Loss of batch at epoch 5 : 1.2126665115356445
Loss of batch at epoch 5 : 1.161260724067688
Loss of batch at epoch 5 : 1.2042022943496704
Loss of batch at epoch 5 : 1.1895908117294312
Loss of batch at epoch 5 : 1.2612066268920898
Loss of batch at epoch 5 : 1.1566232442855835
Loss of batch at epoch 5 : 1.2359471321105957
Loss of batch at epoch 5 : 1.158347725868225
Loss of batch at epoch 5 : 1.1587873697280884
Loss of batch at epoch 5 : 1.1858469247817993
Loss of batch at epoch 5 : 1.1680716276168823
Loss of batch at epoch 5 : 1.1503797769546509
Loss of batch at epoch 5 : 1.1692299842834473
Loss of batch at epoch 5 : 1.195315957069397
Loss of batch at epoch 5 : 1.179466724395752
Loss of batch at epoch 5 : 1.1646531820297241
Loss of batch at epoch 5 : 1.2138041257858276
Loss of batch at epoch 5 : 1.120283603668213
Loss of batch at epoch 5 : 1.1175535917282104
Loss of batch at epoch 5 : 1.1275185346603394
Loss of batch at epoch 5 : 1.23397958278656
Loss of batch at epoch 5 : 1.1981083154678345
Loss of batch at epoch 5 : 1.198414921760559
Loss of batch at epoch 5 : 1.1503772735595703
Loss of batch at epoch 5 : 1.1436054706573486
Loss of batch at epoch 5 : 1.187817931175232
Loss of batch at epoch 5 : 1.0753053426742554
Loss of batch at epoch 5 : 1.1372302770614624
Loss of batch at epoch 5 : 1.1772866249084473
Loss of batch at epoch 5 : 1.1786977052688599
Loss of batch at epoch 5 : 1.1694979667663574
Average train loss of epoch 5: 0.024307481738682378
Average validation loss of epoch 5: 0.02315532639371827
Loss of batch at epoch 6 : 1.1462422609329224
Loss of batch at epoch 6 : 1.176336646080017
Loss of batch at epoch 6 : 1.101599097251892
Loss of batch at epoch 6 : 1.0666412115097046
Loss of batch at epoch 6 : 1.1246116161346436
Loss of batch at epoch 6 : 1.077856421470642
Loss of batch at epoch 6 : 1.0740031003952026
Loss of batch at epoch 6 : 1.1131068468093872
Loss of batch at epoch 6 : 1.1172782182693481
Loss of batch at epoch 6 : 1.1055647134780884
Loss of batch at epoch 6 : 1.0500142574310303
Loss of batch at epoch 6 : 1.0968226194381714
Loss of batch at epoch 6 : 1.059901475906372
Loss of batch at epoch 6 : 1.153990626335144
Loss of batch at epoch 6 : 1.077083945274353
Loss of batch at epoch 6 : 1.0703307390213013
Loss of batch at epoch 6 : 1.1082861423492432
Loss of batch at epoch 6 : 1.1459983587265015
Loss of batch at epoch 6 : 1.1694585084915161
Loss of batch at epoch 6 : 1.0775867700576782
Loss of batch at epoch 6 : 1.0280036926269531
Loss of batch at epoch 6 : 1.0712543725967407
Loss of batch at epoch 6 : 1.0747056007385254
Loss of batch at epoch 6 : 1.1203951835632324
Loss of batch at epoch 6 : 1.0148602724075317
Loss of batch at epoch 6 : 1.019397258758545
Loss of batch at epoch 6 : 1.0628430843353271
Loss of batch at epoch 6 : 1.04025399684906
Loss of batch at epoch 6 : 1.094104290008545
Loss of batch at epoch 6 : 1.10361909866333
Loss of batch at epoch 6 : 1.0574257373809814
Loss of batch at epoch 6 : 1.0459760427474976
Loss of batch at epoch 6 : 1.0345278978347778
Loss of batch at epoch 6 : 1.074939250946045
Loss of batch at epoch 6 : 0.9972917437553406
Loss of batch at epoch 6 : 1.043447732925415
Loss of batch at epoch 6 : 1.0625325441360474
Loss of batch at epoch 6 : 0.9978541731834412
Loss of batch at epoch 6 : 0.9727198481559753
Loss of batch at epoch 6 : 1.0158458948135376
Loss of batch at epoch 6 : 1.052544116973877
Loss of batch at epoch 6 : 1.0039695501327515
Loss of batch at epoch 6 : 1.037339210510254
Loss of batch at epoch 6 : 1.0666838884353638
Loss of batch at epoch 6 : 0.9727880954742432
Loss of batch at epoch 6 : 1.0148154497146606
Loss of batch at epoch 6 : 0.96904456615448
Loss of batch at epoch 6 : 0.9973390102386475
Loss of batch at epoch 6 : 1.0377025604248047
Loss of batch at epoch 6 : 0.983661413192749
Loss of batch at epoch 6 : 1.0166105031967163
Loss of batch at epoch 6 : 1.0329701900482178
Loss of batch at epoch 6 : 1.049579381942749
Loss of batch at epoch 6 : 0.9907310009002686
Average train loss of epoch 6: 0.021385547561018747
Average validation loss of epoch 6: 0.020330669903996016
Loss of batch at epoch 7 : 1.0284067392349243
Loss of batch at epoch 7 : 1.040580153465271
Loss of batch at epoch 7 : 0.9544109106063843
Loss of batch at epoch 7 : 0.9878806471824646
Loss of batch at epoch 7 : 0.9839422702789307
Loss of batch at epoch 7 : 0.9821963906288147
Loss of batch at epoch 7 : 0.9870800375938416
Loss of batch at epoch 7 : 0.9477233290672302
Loss of batch at epoch 7 : 1.0165824890136719
Loss of batch at epoch 7 : 0.947808563709259
Loss of batch at epoch 7 : 1.0082207918167114
Loss of batch at epoch 7 : 0.9544116854667664
Loss of batch at epoch 7 : 0.9573114514350891
Loss of batch at epoch 7 : 1.0105223655700684
Loss of batch at epoch 7 : 0.9866791367530823
Loss of batch at epoch 7 : 0.9875078797340393
Loss of batch at epoch 7 : 0.953331708908081
Loss of batch at epoch 7 : 1.0363166332244873
Loss of batch at epoch 7 : 0.9759924411773682
Loss of batch at epoch 7 : 0.9964671730995178
Loss of batch at epoch 7 : 0.9249624013900757
Loss of batch at epoch 7 : 0.9873453378677368
Loss of batch at epoch 7 : 0.9542819261550903
Loss of batch at epoch 7 : 0.9411632418632507
Loss of batch at epoch 7 : 0.9902109503746033
Loss of batch at epoch 7 : 0.9215152859687805
Loss of batch at epoch 7 : 0.9778532981872559
Loss of batch at epoch 7 : 0.906944215297699
Loss of batch at epoch 7 : 0.9296500086784363
Loss of batch at epoch 7 : 0.9346469640731812
Loss of batch at epoch 7 : 0.9930868744850159
Loss of batch at epoch 7 : 0.9808409810066223
Loss of batch at epoch 7 : 0.8831987977027893
Loss of batch at epoch 7 : 0.9726204872131348
Loss of batch at epoch 7 : 0.9481629133224487
Loss of batch at epoch 7 : 0.9543873071670532
Loss of batch at epoch 7 : 0.9899495840072632
Loss of batch at epoch 7 : 0.9230461716651917
Loss of batch at epoch 7 : 0.9842866063117981
Loss of batch at epoch 7 : 0.9220866560935974
Loss of batch at epoch 7 : 0.9341270923614502
Loss of batch at epoch 7 : 0.9126535654067993
Loss of batch at epoch 7 : 0.9354692101478577
Loss of batch at epoch 7 : 0.9436421394348145
Loss of batch at epoch 7 : 0.9290831685066223
Loss of batch at epoch 7 : 0.964967668056488
Loss of batch at epoch 7 : 0.8770697116851807
Loss of batch at epoch 7 : 0.9259573817253113
Loss of batch at epoch 7 : 0.9408959150314331
Loss of batch at epoch 7 : 0.8901793360710144
Loss of batch at epoch 7 : 0.9904601573944092
Loss of batch at epoch 7 : 0.9632928967475891
Loss of batch at epoch 7 : 0.9109897613525391
Loss of batch at epoch 7 : 0.9461774230003357
Average train loss of epoch 7: 0.019353464880124946
Average validation loss of epoch 7: 0.018602958833328402
Loss of batch at epoch 8 : 0.8735181093215942
Loss of batch at epoch 8 : 0.9099716544151306
Loss of batch at epoch 8 : 0.8950325846672058
Loss of batch at epoch 8 : 0.9923115968704224
Loss of batch at epoch 8 : 0.8817658424377441
Loss of batch at epoch 8 : 0.9025179743766785
Loss of batch at epoch 8 : 0.8802037239074707
Loss of batch at epoch 8 : 0.9286423921585083
Loss of batch at epoch 8 : 0.8933913111686707
Loss of batch at epoch 8 : 0.9130568504333496
Loss of batch at epoch 8 : 0.8771652579307556
Loss of batch at epoch 8 : 0.8446229696273804
Loss of batch at epoch 8 : 0.9107802510261536
Loss of batch at epoch 8 : 0.8680829405784607
Loss of batch at epoch 8 : 0.9497812390327454
Loss of batch at epoch 8 : 0.8804548382759094
Loss of batch at epoch 8 : 0.8582289814949036
Loss of batch at epoch 8 : 0.9504730105400085
Loss of batch at epoch 8 : 0.8751549124717712
Loss of batch at epoch 8 : 0.8818379044532776
Loss of batch at epoch 8 : 0.9032286405563354
Loss of batch at epoch 8 : 0.869204580783844
Loss of batch at epoch 8 : 0.8849751949310303
Loss of batch at epoch 8 : 0.9177250266075134
Loss of batch at epoch 8 : 0.873623251914978
Loss of batch at epoch 8 : 0.8797144889831543
Loss of batch at epoch 8 : 0.8798859119415283
Loss of batch at epoch 8 : 0.9128227233886719
Loss of batch at epoch 8 : 0.8635548949241638
Loss of batch at epoch 8 : 0.8443364500999451
Loss of batch at epoch 8 : 0.889163076877594
Loss of batch at epoch 8 : 0.8791930675506592
Loss of batch at epoch 8 : 0.8471167087554932
Loss of batch at epoch 8 : 0.8422145247459412
Loss of batch at epoch 8 : 0.8902839422225952
Loss of batch at epoch 8 : 0.8822461366653442
Loss of batch at epoch 8 : 0.9092792272567749
Loss of batch at epoch 8 : 0.8605100512504578
Loss of batch at epoch 8 : 0.8813303112983704
Loss of batch at epoch 8 : 0.8550459742546082
Loss of batch at epoch 8 : 0.845528781414032
Loss of batch at epoch 8 : 0.8191553950309753
Loss of batch at epoch 8 : 0.8835647106170654
Loss of batch at epoch 8 : 0.8708052039146423
Loss of batch at epoch 8 : 0.9086098670959473
Loss of batch at epoch 8 : 0.9664515852928162
Loss of batch at epoch 8 : 0.9106841087341309
Loss of batch at epoch 8 : 0.8438852429389954
Loss of batch at epoch 8 : 0.7858452200889587
Loss of batch at epoch 8 : 0.8205056190490723
Loss of batch at epoch 8 : 0.8517082333564758
Loss of batch at epoch 8 : 0.8631513118743896
Loss of batch at epoch 8 : 0.8517756462097168
Loss of batch at epoch 8 : 0.8360165953636169
Average train loss of epoch 8: 0.017770774334201715
Average validation loss of epoch 8: 0.017286154557558824
Loss of batch at epoch 9 : 0.8436622023582458
Loss of batch at epoch 9 : 0.868923544883728
Loss of batch at epoch 9 : 0.8738740086555481
Loss of batch at epoch 9 : 0.8237283229827881
Loss of batch at epoch 9 : 0.8245608806610107
Loss of batch at epoch 9 : 0.8353347182273865
Loss of batch at epoch 9 : 0.8435704112052917
Loss of batch at epoch 9 : 0.8261063694953918
Loss of batch at epoch 9 : 0.9699465036392212
Loss of batch at epoch 9 : 0.8214461803436279
Loss of batch at epoch 9 : 0.8025728464126587
Loss of batch at epoch 9 : 0.8804975748062134
Loss of batch at epoch 9 : 0.8385840654373169
Loss of batch at epoch 9 : 0.8860347867012024
Loss of batch at epoch 9 : 0.7888168096542358
Loss of batch at epoch 9 : 0.8381674289703369
Loss of batch at epoch 9 : 0.8263800740242004
Loss of batch at epoch 9 : 0.8367869257926941
Loss of batch at epoch 9 : 0.8283560872077942
Loss of batch at epoch 9 : 0.857843816280365
Loss of batch at epoch 9 : 0.7781185507774353
Loss of batch at epoch 9 : 0.8392136693000793
Loss of batch at epoch 9 : 0.7925096750259399
Loss of batch at epoch 9 : 0.8229644894599915
Loss of batch at epoch 9 : 0.7965165376663208
Loss of batch at epoch 9 : 0.7998905777931213
Loss of batch at epoch 9 : 0.803916335105896
Loss of batch at epoch 9 : 0.7782750129699707
Loss of batch at epoch 9 : 0.8109201788902283
Loss of batch at epoch 9 : 0.8198906779289246
Loss of batch at epoch 9 : 0.7513993978500366
Loss of batch at epoch 9 : 0.7616259455680847
Loss of batch at epoch 9 : 0.8302597999572754
Loss of batch at epoch 9 : 0.8239015936851501
Loss of batch at epoch 9 : 0.7871055603027344
Loss of batch at epoch 9 : 0.8616439700126648
Loss of batch at epoch 9 : 0.8019406199455261
Loss of batch at epoch 9 : 0.7697630524635315
Loss of batch at epoch 9 : 0.7812439799308777
Loss of batch at epoch 9 : 0.8009135723114014
Loss of batch at epoch 9 : 0.7618833184242249
Loss of batch at epoch 9 : 0.8313122391700745
Loss of batch at epoch 9 : 0.8232928514480591
Loss of batch at epoch 9 : 0.744499683380127
Loss of batch at epoch 9 : 0.8016448020935059
Loss of batch at epoch 9 : 0.8047035932540894
Loss of batch at epoch 9 : 0.9595776796340942
Loss of batch at epoch 9 : 0.72748863697052
Loss of batch at epoch 9 : 0.827845573425293
Loss of batch at epoch 9 : 0.8608166575431824
Loss of batch at epoch 9 : 0.7859295606613159
Loss of batch at epoch 9 : 0.7790483832359314
Loss of batch at epoch 9 : 0.8011126518249512
Loss of batch at epoch 9 : 0.7466907501220703
Average train loss of epoch 9: 0.01649852863793234
Average validation loss of epoch 9: 0.016139632523661913
Loss of batch at epoch 10 : 0.8133811950683594
Loss of batch at epoch 10 : 0.7928601503372192
Loss of batch at epoch 10 : 0.7774994373321533
Loss of batch at epoch 10 : 0.7921161651611328
Loss of batch at epoch 10 : 0.8162378668785095
Loss of batch at epoch 10 : 0.760590672492981
Loss of batch at epoch 10 : 0.8160815238952637
Loss of batch at epoch 10 : 0.7627198100090027
Loss of batch at epoch 10 : 0.840192437171936
Loss of batch at epoch 10 : 0.7842349410057068
Loss of batch at epoch 10 : 0.7608376741409302
Loss of batch at epoch 10 : 0.7600849866867065
Loss of batch at epoch 10 : 0.8028262853622437
Loss of batch at epoch 10 : 0.8068763017654419
Loss of batch at epoch 10 : 0.8100776076316833
Loss of batch at epoch 10 : 0.7835392951965332
Loss of batch at epoch 10 : 0.7711789011955261
Loss of batch at epoch 10 : 0.7832216024398804
Loss of batch at epoch 10 : 0.7655631303787231
Loss of batch at epoch 10 : 0.8121547698974609
Loss of batch at epoch 10 : 0.7883220911026001
Loss of batch at epoch 10 : 0.7839561700820923
Loss of batch at epoch 10 : 0.81486576795578
Loss of batch at epoch 10 : 0.7863154411315918
Loss of batch at epoch 10 : 0.7836118936538696
Loss of batch at epoch 10 : 0.7306329011917114
Loss of batch at epoch 10 : 0.7912114262580872
Loss of batch at epoch 10 : 0.7496966123580933
Loss of batch at epoch 10 : 0.7334594130516052
Loss of batch at epoch 10 : 0.7286065220832825
Loss of batch at epoch 10 : 0.7749954462051392
Loss of batch at epoch 10 : 0.7855076789855957
Loss of batch at epoch 10 : 0.813244640827179
Loss of batch at epoch 10 : 0.7856502532958984
Loss of batch at epoch 10 : 0.7761045098304749
Loss of batch at epoch 10 : 0.7452790141105652
Loss of batch at epoch 10 : 0.7059314250946045
Loss of batch at epoch 10 : 0.7429423332214355
Loss of batch at epoch 10 : 0.8042338490486145
Loss of batch at epoch 10 : 0.7579337954521179
Loss of batch at epoch 10 : 0.8174306750297546
Loss of batch at epoch 10 : 0.7585361003875732
Loss of batch at epoch 10 : 0.7460023164749146
Loss of batch at epoch 10 : 0.7563475370407104
Loss of batch at epoch 10 : 0.7593228220939636
Loss of batch at epoch 10 : 0.7264513969421387
Loss of batch at epoch 10 : 0.7596554756164551
Loss of batch at epoch 10 : 0.6484196782112122
Loss of batch at epoch 10 : 0.7522038817405701
Loss of batch at epoch 10 : 0.7359718084335327
Loss of batch at epoch 10 : 0.7576295733451843
Loss of batch at epoch 10 : 0.7309743165969849
Loss of batch at epoch 10 : 0.7093393206596375
Loss of batch at epoch 10 : 0.7435394525527954
Average train loss of epoch 10: 0.015532712245539464
Average validation loss of epoch 10: 0.015394177099671027
Loss of batch at epoch 11 : 0.7497981786727905
Loss of batch at epoch 11 : 0.7507513165473938
Loss of batch at epoch 11 : 0.7811174988746643
Loss of batch at epoch 11 : 0.736173152923584
Loss of batch at epoch 11 : 0.7484330534934998
Loss of batch at epoch 11 : 0.7283329367637634
Loss of batch at epoch 11 : 0.7577630877494812
Loss of batch at epoch 11 : 0.7888815402984619
Loss of batch at epoch 11 : 0.6837157607078552
Loss of batch at epoch 11 : 0.6826024055480957
Loss of batch at epoch 11 : 0.7858189940452576
Loss of batch at epoch 11 : 0.7692611813545227
Loss of batch at epoch 11 : 0.7700658440589905
Loss of batch at epoch 11 : 0.7642249464988708
Loss of batch at epoch 11 : 0.7694606184959412
Loss of batch at epoch 11 : 0.7385384440422058
Loss of batch at epoch 11 : 0.8126595616340637
Loss of batch at epoch 11 : 0.6713901162147522
Loss of batch at epoch 11 : 0.7902387976646423
Loss of batch at epoch 11 : 0.7533926963806152
Loss of batch at epoch 11 : 0.6789612770080566
Loss of batch at epoch 11 : 0.7454331517219543
Loss of batch at epoch 11 : 0.6891143918037415
Loss of batch at epoch 11 : 0.7377180457115173
Loss of batch at epoch 11 : 0.7133470773696899
Loss of batch at epoch 11 : 0.7526407837867737
Loss of batch at epoch 11 : 0.714753270149231
Loss of batch at epoch 11 : 0.6783175468444824
Loss of batch at epoch 11 : 0.7438320517539978
Loss of batch at epoch 11 : 0.7737689018249512
Loss of batch at epoch 11 : 0.7589555978775024
Loss of batch at epoch 11 : 0.6811328530311584
Loss of batch at epoch 11 : 0.7514652013778687
Loss of batch at epoch 11 : 0.7056224346160889
Loss of batch at epoch 11 : 0.6932715177536011
Loss of batch at epoch 11 : 0.786316990852356
Loss of batch at epoch 11 : 0.7236009240150452
Loss of batch at epoch 11 : 0.6739664673805237
Loss of batch at epoch 11 : 0.70902019739151
Loss of batch at epoch 11 : 0.7553775310516357
Loss of batch at epoch 11 : 0.7733064293861389
Loss of batch at epoch 11 : 0.6589463353157043
Loss of batch at epoch 11 : 0.6992116570472717
Loss of batch at epoch 11 : 0.697821855545044
Loss of batch at epoch 11 : 0.7228835225105286
Loss of batch at epoch 11 : 0.7421921491622925
Loss of batch at epoch 11 : 0.7176015377044678
Loss of batch at epoch 11 : 0.6671075820922852
Loss of batch at epoch 11 : 0.7357615828514099
Loss of batch at epoch 11 : 0.6827815175056458
Loss of batch at epoch 11 : 0.6938538551330566
Loss of batch at epoch 11 : 0.7091503143310547
Loss of batch at epoch 11 : 0.7303587198257446
Loss of batch at epoch 11 : 0.7574878334999084
Average train loss of epoch 11: 0.014745220842425551
Average validation loss of epoch 11: 0.01463816382668235
Loss of batch at epoch 12 : 0.7095293402671814
Loss of batch at epoch 12 : 0.7387633919715881
Loss of batch at epoch 12 : 0.7466793060302734
Loss of batch at epoch 12 : 0.7453308701515198
Loss of batch at epoch 12 : 0.6637375950813293
Loss of batch at epoch 12 : 0.7054483890533447
Loss of batch at epoch 12 : 0.7102514505386353
Loss of batch at epoch 12 : 0.6980305910110474
Loss of batch at epoch 12 : 0.6827584505081177
Loss of batch at epoch 12 : 0.6989441514015198
Loss of batch at epoch 12 : 0.6612635254859924
Loss of batch at epoch 12 : 0.6827587485313416
Loss of batch at epoch 12 : 0.6633610129356384
Loss of batch at epoch 12 : 0.6540156602859497
Loss of batch at epoch 12 : 0.6851264834403992
Loss of batch at epoch 12 : 0.7111881375312805
Loss of batch at epoch 12 : 0.6888194680213928
Loss of batch at epoch 12 : 0.7110809683799744
Loss of batch at epoch 12 : 0.6297855973243713
Loss of batch at epoch 12 : 0.7090600728988647
Loss of batch at epoch 12 : 0.7442328929901123
Loss of batch at epoch 12 : 0.7995870113372803
Loss of batch at epoch 12 : 0.6969819068908691
Loss of batch at epoch 12 : 0.6951500177383423
Loss of batch at epoch 12 : 0.6606441736221313
Loss of batch at epoch 12 : 0.6843495965003967
Loss of batch at epoch 12 : 0.7037521004676819
Loss of batch at epoch 12 : 0.7103834748268127
Loss of batch at epoch 12 : 0.6910375952720642
Loss of batch at epoch 12 : 0.6298931837081909
Loss of batch at epoch 12 : 0.6770187020301819
Loss of batch at epoch 12 : 0.6241863369941711
Loss of batch at epoch 12 : 0.6519520878791809
Loss of batch at epoch 12 : 0.6335117220878601
Loss of batch at epoch 12 : 0.6476823687553406
Loss of batch at epoch 12 : 0.7290737628936768
Loss of batch at epoch 12 : 0.6855642199516296
Loss of batch at epoch 12 : 0.6660184264183044
Loss of batch at epoch 12 : 0.7249863147735596
Loss of batch at epoch 12 : 0.6900113821029663
Loss of batch at epoch 12 : 0.7009445428848267
Loss of batch at epoch 12 : 0.7003512978553772
Loss of batch at epoch 12 : 0.6695990562438965
Loss of batch at epoch 12 : 0.6803746223449707
Loss of batch at epoch 12 : 0.679443359375
Loss of batch at epoch 12 : 0.6562267541885376
Loss of batch at epoch 12 : 0.6336894035339355
Loss of batch at epoch 12 : 0.6715930104255676
Loss of batch at epoch 12 : 0.6709708571434021
Loss of batch at epoch 12 : 0.6872756481170654
Loss of batch at epoch 12 : 0.7091000080108643
Loss of batch at epoch 12 : 0.7359100580215454
Loss of batch at epoch 12 : 0.6715841293334961
Loss of batch at epoch 12 : 0.6365450620651245
Average train loss of epoch 12: 0.01387063383254834
Average validation loss of epoch 12: 0.014099824308144927
Loss of batch at epoch 13 : 0.7029810547828674
Loss of batch at epoch 13 : 0.658381462097168
Loss of batch at epoch 13 : 0.642828643321991
Loss of batch at epoch 13 : 0.7221410274505615
Loss of batch at epoch 13 : 0.6793808341026306
Loss of batch at epoch 13 : 0.7126803398132324
Loss of batch at epoch 13 : 0.6848689913749695
Loss of batch at epoch 13 : 0.6690512895584106
Loss of batch at epoch 13 : 0.6545048952102661
Loss of batch at epoch 13 : 0.7093896865844727
Loss of batch at epoch 13 : 0.7017839550971985
Loss of batch at epoch 13 : 0.6800075769424438
Loss of batch at epoch 13 : 0.6664390563964844
Loss of batch at epoch 13 : 0.6476598978042603
Loss of batch at epoch 13 : 0.6899210810661316
Loss of batch at epoch 13 : 0.7462950944900513
Loss of batch at epoch 13 : 0.6785630583763123
Loss of batch at epoch 13 : 0.6520469188690186
Loss of batch at epoch 13 : 0.6637134552001953
Loss of batch at epoch 13 : 0.6718759536743164
Loss of batch at epoch 13 : 0.6384243965148926
Loss of batch at epoch 13 : 0.6228818297386169
Loss of batch at epoch 13 : 0.6554164290428162
Loss of batch at epoch 13 : 0.6422408223152161
Loss of batch at epoch 13 : 0.7102644443511963
Loss of batch at epoch 13 : 0.6460213661193848
Loss of batch at epoch 13 : 0.6212744116783142
Loss of batch at epoch 13 : 0.5882703065872192
Loss of batch at epoch 13 : 0.6488975286483765
Loss of batch at epoch 13 : 0.7448386549949646
Loss of batch at epoch 13 : 0.7046136260032654
Loss of batch at epoch 13 : 0.6112285256385803
Loss of batch at epoch 13 : 0.6710909605026245
Loss of batch at epoch 13 : 0.5786522626876831
Loss of batch at epoch 13 : 0.6405009031295776
Loss of batch at epoch 13 : 0.7078729271888733
Loss of batch at epoch 13 : 0.6273360252380371
Loss of batch at epoch 13 : 0.6516258716583252
Loss of batch at epoch 13 : 0.6638896465301514
Loss of batch at epoch 13 : 0.6635668277740479
Loss of batch at epoch 13 : 0.6369733214378357
Loss of batch at epoch 13 : 0.6365322470664978
Loss of batch at epoch 13 : 0.6116313338279724
Loss of batch at epoch 13 : 0.6336920261383057
Loss of batch at epoch 13 : 0.6210572719573975
Loss of batch at epoch 13 : 0.6262098550796509
Loss of batch at epoch 13 : 0.6623494625091553
Loss of batch at epoch 13 : 0.6348715424537659
Loss of batch at epoch 13 : 0.6029756665229797
Loss of batch at epoch 13 : 0.6275883913040161
Loss of batch at epoch 13 : 0.6271005868911743
Loss of batch at epoch 13 : 0.7006453275680542
Loss of batch at epoch 13 : 0.6584912538528442
Loss of batch at epoch 13 : 0.5859296917915344
Average train loss of epoch 13: 0.013270901600935282
Average validation loss of epoch 13: 0.013143756975629915
Loss of batch at epoch 14 : 0.6107118129730225
Loss of batch at epoch 14 : 0.6247694492340088
Loss of batch at epoch 14 : 0.5872319936752319
Loss of batch at epoch 14 : 0.6336683630943298
Loss of batch at epoch 14 : 0.6099650263786316
Loss of batch at epoch 14 : 0.5599868297576904
Loss of batch at epoch 14 : 0.6190786957740784
Loss of batch at epoch 14 : 0.6831339597702026
Loss of batch at epoch 14 : 0.599408745765686
Loss of batch at epoch 14 : 0.6055183410644531
Loss of batch at epoch 14 : 0.6667526960372925
Loss of batch at epoch 14 : 0.6227766275405884
Loss of batch at epoch 14 : 0.6091874241828918
Loss of batch at epoch 14 : 0.6349566578865051
Loss of batch at epoch 14 : 0.596655011177063
Loss of batch at epoch 14 : 0.6663377285003662
Loss of batch at epoch 14 : 0.612177312374115
Loss of batch at epoch 14 : 0.6267428398132324
Loss of batch at epoch 14 : 0.7202996611595154
Loss of batch at epoch 14 : 0.6242626905441284
Loss of batch at epoch 14 : 0.6580480933189392
Loss of batch at epoch 14 : 0.6644582748413086
Loss of batch at epoch 14 : 0.6082174777984619
Loss of batch at epoch 14 : 0.6852810382843018
Loss of batch at epoch 14 : 0.6330615282058716
Loss of batch at epoch 14 : 0.5808389186859131
Loss of batch at epoch 14 : 0.6580861806869507
Loss of batch at epoch 14 : 0.6493434906005859
Loss of batch at epoch 14 : 0.6582874059677124
Loss of batch at epoch 14 : 0.6491217017173767
Loss of batch at epoch 14 : 0.6125087738037109
Loss of batch at epoch 14 : 0.6428797245025635
Loss of batch at epoch 14 : 0.6041213274002075
Loss of batch at epoch 14 : 0.6226496696472168
Loss of batch at epoch 14 : 0.6217851638793945
Loss of batch at epoch 14 : 0.6519864797592163
Loss of batch at epoch 14 : 0.6216903924942017
Loss of batch at epoch 14 : 0.6115551590919495
Loss of batch at epoch 14 : 0.574668288230896
Loss of batch at epoch 14 : 0.6726656556129456
Loss of batch at epoch 14 : 0.6782165169715881
Loss of batch at epoch 14 : 0.6728495359420776
Loss of batch at epoch 14 : 0.6261895298957825
Loss of batch at epoch 14 : 0.6281936168670654
Loss of batch at epoch 14 : 0.6073997616767883
Loss of batch at epoch 14 : 0.5874708890914917
Loss of batch at epoch 14 : 0.6526169180870056
Loss of batch at epoch 14 : 0.6102666854858398
Loss of batch at epoch 14 : 0.6354414224624634
Loss of batch at epoch 14 : 0.6238255500793457
Loss of batch at epoch 14 : 0.6070438027381897
Loss of batch at epoch 14 : 0.6021502017974854
Loss of batch at epoch 14 : 0.6267638206481934
Loss of batch at epoch 14 : 0.6451529264450073
Average train loss of epoch 14: 0.01269546634141325
Average validation loss of epoch 14: 0.012595419931893398
Loss of batch at epoch 15 : 0.6151335835456848
Loss of batch at epoch 15 : 0.6059510111808777
Loss of batch at epoch 15 : 0.6622588634490967
Loss of batch at epoch 15 : 0.6028351783752441
Loss of batch at epoch 15 : 0.5858545899391174
Loss of batch at epoch 15 : 0.6034314632415771
Loss of batch at epoch 15 : 0.6207354068756104
Loss of batch at epoch 15 : 0.6213932633399963
Loss of batch at epoch 15 : 0.6358031630516052
Loss of batch at epoch 15 : 0.574122965335846
Loss of batch at epoch 15 : 0.6002941131591797
Loss of batch at epoch 15 : 0.5812287330627441
Loss of batch at epoch 15 : 0.5797053575515747
Loss of batch at epoch 15 : 0.625004231929779
Loss of batch at epoch 15 : 0.5840480923652649
Loss of batch at epoch 15 : 0.6512858271598816
Loss of batch at epoch 15 : 0.6320686340332031
Loss of batch at epoch 15 : 0.6708742380142212
Loss of batch at epoch 15 : 0.6648320555686951
Loss of batch at epoch 15 : 0.6073989272117615
Loss of batch at epoch 15 : 0.5804187059402466
Loss of batch at epoch 15 : 0.6053740978240967
Loss of batch at epoch 15 : 0.6079291701316833
Loss of batch at epoch 15 : 0.6082750558853149
Loss of batch at epoch 15 : 0.6482157707214355
Loss of batch at epoch 15 : 0.6293483972549438
Loss of batch at epoch 15 : 0.6201978325843811
Loss of batch at epoch 15 : 0.5886724591255188
Loss of batch at epoch 15 : 0.563488781452179
Loss of batch at epoch 15 : 0.5509595274925232
Loss of batch at epoch 15 : 0.5954075455665588
Loss of batch at epoch 15 : 0.5708825588226318
Loss of batch at epoch 15 : 0.5918333530426025
Loss of batch at epoch 15 : 0.5878663063049316
Loss of batch at epoch 15 : 0.5790525078773499
Loss of batch at epoch 15 : 0.6168553829193115
Loss of batch at epoch 15 : 0.5884019732475281
Loss of batch at epoch 15 : 0.6121585965156555
Loss of batch at epoch 15 : 0.6006689071655273
Loss of batch at epoch 15 : 0.6533622145652771
Loss of batch at epoch 15 : 0.6149001121520996
Loss of batch at epoch 15 : 0.6310904026031494
Loss of batch at epoch 15 : 0.5799024105072021
Loss of batch at epoch 15 : 0.5816911458969116
Loss of batch at epoch 15 : 0.6815509796142578
Loss of batch at epoch 15 : 0.6062368750572205
Loss of batch at epoch 15 : 0.5602337121963501
Loss of batch at epoch 15 : 0.6408965587615967
Loss of batch at epoch 15 : 0.6044391393661499
Loss of batch at epoch 15 : 0.5782947540283203
Loss of batch at epoch 15 : 0.5912744402885437
Loss of batch at epoch 15 : 0.5771251916885376
Loss of batch at epoch 15 : 0.5693686008453369
Loss of batch at epoch 15 : 0.6667639017105103
Average train loss of epoch 15: 0.012250707966788123
Average validation loss of epoch 15: 0.012268551270969789
Loss of batch at epoch 16 : 0.6190162301063538
Loss of batch at epoch 16 : 0.5770257711410522
Loss of batch at epoch 16 : 0.5553664565086365
Loss of batch at epoch 16 : 0.5855298042297363
Loss of batch at epoch 16 : 0.5963990092277527
Loss of batch at epoch 16 : 0.5956349968910217
Loss of batch at epoch 16 : 0.581442654132843
Loss of batch at epoch 16 : 0.5934569239616394
Loss of batch at epoch 16 : 0.5574703216552734
Loss of batch at epoch 16 : 0.6041145920753479
Loss of batch at epoch 16 : 0.6110912561416626
Loss of batch at epoch 16 : 0.5748113989830017
Loss of batch at epoch 16 : 0.6173623204231262
Loss of batch at epoch 16 : 0.5950939059257507
Loss of batch at epoch 16 : 0.590458333492279
Loss of batch at epoch 16 : 0.6041082739830017
Loss of batch at epoch 16 : 0.6328235864639282
Loss of batch at epoch 16 : 0.5930464863777161
Loss of batch at epoch 16 : 0.5688337683677673
Loss of batch at epoch 16 : 0.5668960809707642
Loss of batch at epoch 16 : 0.6156235337257385
Loss of batch at epoch 16 : 0.608325183391571
Loss of batch at epoch 16 : 0.5382745265960693
Loss of batch at epoch 16 : 0.5848463177680969
Loss of batch at epoch 16 : 0.5899695754051208
Loss of batch at epoch 16 : 0.5544440150260925
Loss of batch at epoch 16 : 0.5920489430427551
Loss of batch at epoch 16 : 0.5735034942626953
Loss of batch at epoch 16 : 0.6487629413604736
Loss of batch at epoch 16 : 0.555519163608551
Loss of batch at epoch 16 : 0.6677609086036682
Loss of batch at epoch 16 : 0.5156635642051697
Loss of batch at epoch 16 : 0.5549030303955078
Loss of batch at epoch 16 : 0.5793091654777527
Loss of batch at epoch 16 : 0.5707273483276367
Loss of batch at epoch 16 : 0.5563486814498901
Loss of batch at epoch 16 : 0.6207990050315857
Loss of batch at epoch 16 : 0.5760427713394165
Loss of batch at epoch 16 : 0.5874267220497131
Loss of batch at epoch 16 : 0.5406803488731384
Loss of batch at epoch 16 : 0.6223381757736206
Loss of batch at epoch 16 : 0.6074265241622925
Loss of batch at epoch 16 : 0.5782486796379089
Loss of batch at epoch 16 : 0.5833238959312439
Loss of batch at epoch 16 : 0.5396990776062012
Loss of batch at epoch 16 : 0.5493753552436829
Loss of batch at epoch 16 : 0.5853564143180847
Loss of batch at epoch 16 : 0.5819765329360962
Loss of batch at epoch 16 : 0.5582703948020935
Loss of batch at epoch 16 : 0.6033287644386292
Loss of batch at epoch 16 : 0.6169242858886719
Loss of batch at epoch 16 : 0.5864453911781311
Loss of batch at epoch 16 : 0.5879034996032715
Loss of batch at epoch 16 : 0.5393465161323547
Average train loss of epoch 16: 0.011796460568326192
Average validation loss of epoch 16: 0.012251311279707886
Loss of batch at epoch 17 : 0.5964465737342834
Loss of batch at epoch 17 : 0.5723880529403687
Loss of batch at epoch 17 : 0.5862232446670532
Loss of batch at epoch 17 : 0.5964191555976868
Loss of batch at epoch 17 : 0.543007493019104
Loss of batch at epoch 17 : 0.5496405959129333
Loss of batch at epoch 17 : 0.5526465177536011
Loss of batch at epoch 17 : 0.5812859535217285
Loss of batch at epoch 17 : 0.5414301156997681
Loss of batch at epoch 17 : 0.5696038007736206
Loss of batch at epoch 17 : 0.6163154244422913
Loss of batch at epoch 17 : 0.5464656949043274
Loss of batch at epoch 17 : 0.5763593912124634
Loss of batch at epoch 17 : 0.5393576622009277
Loss of batch at epoch 17 : 0.579727053642273
Loss of batch at epoch 17 : 0.550156831741333
Loss of batch at epoch 17 : 0.6153426170349121
Loss of batch at epoch 17 : 0.6227304935455322
Loss of batch at epoch 17 : 0.5537624359130859
Loss of batch at epoch 17 : 0.562676727771759
Loss of batch at epoch 17 : 0.5339445471763611
Loss of batch at epoch 17 : 0.5977135300636292
Loss of batch at epoch 17 : 0.5196958184242249
Loss of batch at epoch 17 : 0.596221923828125
Loss of batch at epoch 17 : 0.5862213373184204
Loss of batch at epoch 17 : 0.5392811894416809
Loss of batch at epoch 17 : 0.5301720499992371
Loss of batch at epoch 17 : 0.532403826713562
Loss of batch at epoch 17 : 0.5651359558105469
Loss of batch at epoch 17 : 0.5701309442520142
Loss of batch at epoch 17 : 0.5897466540336609
Loss of batch at epoch 17 : 0.5634855031967163
Loss of batch at epoch 17 : 0.5640235543251038
Loss of batch at epoch 17 : 0.512873113155365
Loss of batch at epoch 17 : 0.622639000415802
Loss of batch at epoch 17 : 0.5665668249130249
Loss of batch at epoch 17 : 0.5868143439292908
Loss of batch at epoch 17 : 0.5253729224205017
Loss of batch at epoch 17 : 0.6187803745269775
Loss of batch at epoch 17 : 0.534970223903656
Loss of batch at epoch 17 : 0.5297319889068604
Loss of batch at epoch 17 : 0.5993766784667969
Loss of batch at epoch 17 : 0.5656743049621582
Loss of batch at epoch 17 : 0.5391832590103149
Loss of batch at epoch 17 : 0.6078846454620361
Loss of batch at epoch 17 : 0.6137163639068604
Loss of batch at epoch 17 : 0.5216138362884521
Loss of batch at epoch 17 : 0.5514436364173889
Loss of batch at epoch 17 : 0.5890198349952698
Loss of batch at epoch 17 : 0.5949456691741943
Loss of batch at epoch 17 : 0.5691179037094116
Loss of batch at epoch 17 : 0.5216516852378845
Loss of batch at epoch 17 : 0.5583174824714661
Loss of batch at epoch 17 : 0.5994935631752014
Average train loss of epoch 17: 0.011452333708144196
Average validation loss of epoch 17: 0.011660298915824504
Loss of batch at epoch 18 : 0.46604564785957336
Loss of batch at epoch 18 : 0.5869373679161072
Loss of batch at epoch 18 : 0.54731684923172
Loss of batch at epoch 18 : 0.5426672697067261
Loss of batch at epoch 18 : 0.5883898138999939
Loss of batch at epoch 18 : 0.5946000814437866
Loss of batch at epoch 18 : 0.63629150390625
Loss of batch at epoch 18 : 0.5383504033088684
Loss of batch at epoch 18 : 0.5274314284324646
Loss of batch at epoch 18 : 0.5560230612754822
Loss of batch at epoch 18 : 0.5323407053947449
Loss of batch at epoch 18 : 0.5837472677230835
Loss of batch at epoch 18 : 0.5714263319969177
Loss of batch at epoch 18 : 0.5266818404197693
Loss of batch at epoch 18 : 0.5294737815856934
Loss of batch at epoch 18 : 0.5208219885826111
Loss of batch at epoch 18 : 0.5120408535003662
Loss of batch at epoch 18 : 0.5412865281105042
Loss of batch at epoch 18 : 0.5366489887237549
Loss of batch at epoch 18 : 0.6002514958381653
Loss of batch at epoch 18 : 0.5825194716453552
Loss of batch at epoch 18 : 0.5741357207298279
Loss of batch at epoch 18 : 0.5820280909538269
Loss of batch at epoch 18 : 0.5639119744300842
Loss of batch at epoch 18 : 0.5189096331596375
Loss of batch at epoch 18 : 0.5984475612640381
Loss of batch at epoch 18 : 0.5445501208305359
Loss of batch at epoch 18 : 0.527301013469696
Loss of batch at epoch 18 : 0.5145589709281921
Loss of batch at epoch 18 : 0.584537923336029
Loss of batch at epoch 18 : 0.5755366086959839
Loss of batch at epoch 18 : 0.5264536738395691
Loss of batch at epoch 18 : 0.5298490524291992
Loss of batch at epoch 18 : 0.4993704855442047
Loss of batch at epoch 18 : 0.5556380152702332
Loss of batch at epoch 18 : 0.5099438428878784
Loss of batch at epoch 18 : 0.5788301229476929
Loss of batch at epoch 18 : 0.5874205827713013
Loss of batch at epoch 18 : 0.526481568813324
Loss of batch at epoch 18 : 0.5504463315010071
Loss of batch at epoch 18 : 0.5317916870117188
Loss of batch at epoch 18 : 0.5295402407646179
Loss of batch at epoch 18 : 0.5561812520027161
Loss of batch at epoch 18 : 0.5239771008491516
Loss of batch at epoch 18 : 0.5668182969093323
Loss of batch at epoch 18 : 0.6171523332595825
Loss of batch at epoch 18 : 0.4852026700973511
Loss of batch at epoch 18 : 0.5279233455657959
Loss of batch at epoch 18 : 0.5650022029876709
Loss of batch at epoch 18 : 0.5668134093284607
Loss of batch at epoch 18 : 0.5295454263687134
Loss of batch at epoch 18 : 0.5300823450088501
Loss of batch at epoch 18 : 0.5438105463981628
Loss of batch at epoch 18 : 0.4485940933227539
Average train loss of epoch 18: 0.011050066901642142
Average validation loss of epoch 18: 0.01130389765858249
Loss of batch at epoch 19 : 0.5268596410751343
Loss of batch at epoch 19 : 0.5288737416267395
Loss of batch at epoch 19 : 0.5590753555297852
Loss of batch at epoch 19 : 0.5867112278938293
Loss of batch at epoch 19 : 0.5374284982681274
Loss of batch at epoch 19 : 0.5451031923294067
Loss of batch at epoch 19 : 0.5171232223510742
Loss of batch at epoch 19 : 0.5209422707557678
Loss of batch at epoch 19 : 0.5822039246559143
Loss of batch at epoch 19 : 0.5130361914634705
Loss of batch at epoch 19 : 0.5170414447784424
Loss of batch at epoch 19 : 0.5163431167602539
Loss of batch at epoch 19 : 0.5553659796714783
Loss of batch at epoch 19 : 0.560161292552948
Loss of batch at epoch 19 : 0.4869459271430969
Loss of batch at epoch 19 : 0.4968152940273285
Loss of batch at epoch 19 : 0.5315728783607483
Loss of batch at epoch 19 : 0.5494405031204224
Loss of batch at epoch 19 : 0.49002134799957275
Loss of batch at epoch 19 : 0.4994276463985443
Loss of batch at epoch 19 : 0.5104764699935913
Loss of batch at epoch 19 : 0.5146880745887756
Loss of batch at epoch 19 : 0.4826836585998535
Loss of batch at epoch 19 : 0.5524812936782837
Loss of batch at epoch 19 : 0.5133696794509888
Loss of batch at epoch 19 : 0.5190343856811523
Loss of batch at epoch 19 : 0.48242276906967163
Loss of batch at epoch 19 : 0.48746365308761597
Loss of batch at epoch 19 : 0.5484174489974976
Loss of batch at epoch 19 : 0.5288837552070618
Loss of batch at epoch 19 : 0.5256535410881042
Loss of batch at epoch 19 : 0.5448901653289795
Loss of batch at epoch 19 : 0.5480307340621948
Loss of batch at epoch 19 : 0.4701746702194214
Loss of batch at epoch 19 : 0.5171594619750977
Loss of batch at epoch 19 : 0.49376076459884644
Loss of batch at epoch 19 : 0.5152556300163269
Loss of batch at epoch 19 : 0.6057262420654297
Loss of batch at epoch 19 : 0.5501836538314819
Loss of batch at epoch 19 : 0.5170473456382751
Loss of batch at epoch 19 : 0.5464562177658081
Loss of batch at epoch 19 : 0.5167019367218018
Loss of batch at epoch 19 : 0.52480548620224
Loss of batch at epoch 19 : 0.5053393840789795
Loss of batch at epoch 19 : 0.5034191608428955
Loss of batch at epoch 19 : 0.5772018432617188
Loss of batch at epoch 19 : 0.5081979632377625
Loss of batch at epoch 19 : 0.511342465877533
Loss of batch at epoch 19 : 0.5270887613296509
Loss of batch at epoch 19 : 0.5068728923797607
Loss of batch at epoch 19 : 0.5756339430809021
Loss of batch at epoch 19 : 0.5452615022659302
Loss of batch at epoch 19 : 0.5724472403526306
Loss of batch at epoch 19 : 0.5313385128974915
Average train loss of epoch 19: 0.010642419919048877
Average validation loss of epoch 19: 0.011067314180059466
Loss of batch at epoch 20 : 0.4483877122402191
Loss of batch at epoch 20 : 0.4756886065006256
Loss of batch at epoch 20 : 0.508689820766449
Loss of batch at epoch 20 : 0.5511333346366882
Loss of batch at epoch 20 : 0.49179181456565857
Loss of batch at epoch 20 : 0.5694647431373596
Loss of batch at epoch 20 : 0.5484912395477295
Loss of batch at epoch 20 : 0.5421811938285828
Loss of batch at epoch 20 : 0.5117760300636292
Loss of batch at epoch 20 : 0.5279712080955505
Loss of batch at epoch 20 : 0.5077623128890991
Loss of batch at epoch 20 : 0.49230584502220154
Loss of batch at epoch 20 : 0.5105831027030945
Loss of batch at epoch 20 : 0.5310360193252563
Loss of batch at epoch 20 : 0.5104432106018066
Loss of batch at epoch 20 : 0.5477585196495056
Loss of batch at epoch 20 : 0.5228098630905151
Loss of batch at epoch 20 : 0.5343469977378845
Loss of batch at epoch 20 : 0.5542523860931396
Loss of batch at epoch 20 : 0.5078690648078918
Loss of batch at epoch 20 : 0.4779031276702881
Loss of batch at epoch 20 : 0.5303046703338623
Loss of batch at epoch 20 : 0.49803590774536133
Loss of batch at epoch 20 : 0.4949290454387665
Loss of batch at epoch 20 : 0.4974919557571411
Loss of batch at epoch 20 : 0.5259377360343933
Loss of batch at epoch 20 : 0.5292893052101135
Loss of batch at epoch 20 : 0.5095991492271423
Loss of batch at epoch 20 : 0.5512192845344543
Loss of batch at epoch 20 : 0.49126842617988586
Loss of batch at epoch 20 : 0.5208583474159241
Loss of batch at epoch 20 : 0.4950718581676483
Loss of batch at epoch 20 : 0.49902141094207764
Loss of batch at epoch 20 : 0.5140792727470398
Loss of batch at epoch 20 : 0.4834665060043335
Loss of batch at epoch 20 : 0.5623213052749634
Loss of batch at epoch 20 : 0.48239666223526
Loss of batch at epoch 20 : 0.5352141857147217
Loss of batch at epoch 20 : 0.5150646567344666
Loss of batch at epoch 20 : 0.47750750184059143
Loss of batch at epoch 20 : 0.48874589800834656
Loss of batch at epoch 20 : 0.55389803647995
Loss of batch at epoch 20 : 0.48971402645111084
Loss of batch at epoch 20 : 0.5513713359832764
Loss of batch at epoch 20 : 0.5000106692314148
Loss of batch at epoch 20 : 0.5180498957633972
Loss of batch at epoch 20 : 0.6278271079063416
Loss of batch at epoch 20 : 0.48215988278388977
Loss of batch at epoch 20 : 0.5298611521720886
Loss of batch at epoch 20 : 0.501369297504425
Loss of batch at epoch 20 : 0.5456783175468445
Loss of batch at epoch 20 : 0.5187082886695862
Loss of batch at epoch 20 : 0.4969594180583954
Loss of batch at epoch 20 : 0.5326148867607117
Average train loss of epoch 20: 0.010426695797316969
Average validation loss of epoch 20: 0.011003947017168758
Loss of batch at epoch 21 : 0.49992847442626953
Loss of batch at epoch 21 : 0.5055189728736877
Loss of batch at epoch 21 : 0.5646349191665649
Loss of batch at epoch 21 : 0.5666096210479736
Loss of batch at epoch 21 : 0.491293340921402
Loss of batch at epoch 21 : 0.5487849712371826
Loss of batch at epoch 21 : 0.5013086795806885
Loss of batch at epoch 21 : 0.5378615260124207
Loss of batch at epoch 21 : 0.524721622467041
Loss of batch at epoch 21 : 0.48484113812446594
Loss of batch at epoch 21 : 0.514844536781311
Loss of batch at epoch 21 : 0.5558133721351624
Loss of batch at epoch 21 : 0.48023372888565063
Loss of batch at epoch 21 : 0.4783968925476074
Loss of batch at epoch 21 : 0.5245146751403809
Loss of batch at epoch 21 : 0.4938696622848511
Loss of batch at epoch 21 : 0.4994274079799652
Loss of batch at epoch 21 : 0.4882326126098633
Loss of batch at epoch 21 : 0.4503675401210785
Loss of batch at epoch 21 : 0.5289602279663086
Loss of batch at epoch 21 : 0.5501989722251892
Loss of batch at epoch 21 : 0.48190945386886597
Loss of batch at epoch 21 : 0.47674092650413513
Loss of batch at epoch 21 : 0.5293876528739929
Loss of batch at epoch 21 : 0.5419124960899353
Loss of batch at epoch 21 : 0.5537354350090027
Loss of batch at epoch 21 : 0.49000319838523865
Loss of batch at epoch 21 : 0.5238499641418457
Loss of batch at epoch 21 : 0.508886456489563
Loss of batch at epoch 21 : 0.518259584903717
Loss of batch at epoch 21 : 0.5220552086830139
Loss of batch at epoch 21 : 0.507146954536438
Loss of batch at epoch 21 : 0.49177882075309753
Loss of batch at epoch 21 : 0.5203511714935303
Loss of batch at epoch 21 : 0.5323435664176941
Loss of batch at epoch 21 : 0.5068061351776123
Loss of batch at epoch 21 : 0.5424898266792297
Loss of batch at epoch 21 : 0.5645004510879517
Loss of batch at epoch 21 : 0.5077715516090393
Loss of batch at epoch 21 : 0.5416712760925293
Loss of batch at epoch 21 : 0.49990400671958923
Loss of batch at epoch 21 : 0.4848567843437195
Loss of batch at epoch 21 : 0.47597336769104004
Loss of batch at epoch 21 : 0.47784656286239624
Loss of batch at epoch 21 : 0.4519871473312378
Loss of batch at epoch 21 : 0.5492762327194214
Loss of batch at epoch 21 : 0.4852067828178406
Loss of batch at epoch 21 : 0.4970167875289917
Loss of batch at epoch 21 : 0.5242454409599304
Loss of batch at epoch 21 : 0.5075843334197998
Loss of batch at epoch 21 : 0.5420616269111633
Loss of batch at epoch 21 : 0.46874305605888367
Loss of batch at epoch 21 : 0.485478013753891
Loss of batch at epoch 21 : 0.4934763014316559
Average train loss of epoch 21: 0.01030456352091441
Average validation loss of epoch 21: 0.01043287993280173
Loss of batch at epoch 22 : 0.48538172245025635
Loss of batch at epoch 22 : 0.5004361271858215
Loss of batch at epoch 22 : 0.4991917312145233
Loss of batch at epoch 22 : 0.48237356543540955
Loss of batch at epoch 22 : 0.5126361846923828
Loss of batch at epoch 22 : 0.4984687864780426
Loss of batch at epoch 22 : 0.4863496720790863
Loss of batch at epoch 22 : 0.4810161292552948
Loss of batch at epoch 22 : 0.5013561248779297
Loss of batch at epoch 22 : 0.5142472982406616
Loss of batch at epoch 22 : 0.514601469039917
Loss of batch at epoch 22 : 0.46090736985206604
Loss of batch at epoch 22 : 0.4706176519393921
Loss of batch at epoch 22 : 0.48508551716804504
Loss of batch at epoch 22 : 0.5005753636360168
Loss of batch at epoch 22 : 0.5275821089744568
Loss of batch at epoch 22 : 0.4949515461921692
Loss of batch at epoch 22 : 0.4713970720767975
Loss of batch at epoch 22 : 0.4858899414539337
Loss of batch at epoch 22 : 0.5031782984733582
Loss of batch at epoch 22 : 0.5196465849876404
Loss of batch at epoch 22 : 0.4937240481376648
Loss of batch at epoch 22 : 0.48600900173187256
Loss of batch at epoch 22 : 0.5151038765907288
Loss of batch at epoch 22 : 0.45802438259124756
Loss of batch at epoch 22 : 0.45038625597953796
Loss of batch at epoch 22 : 0.5101091861724854
Loss of batch at epoch 22 : 0.47751063108444214
Loss of batch at epoch 22 : 0.4810260236263275
Loss of batch at epoch 22 : 0.5323882699012756
Loss of batch at epoch 22 : 0.5208553075790405
Loss of batch at epoch 22 : 0.49291685223579407
Loss of batch at epoch 22 : 0.4705403745174408
Loss of batch at epoch 22 : 0.5215283036231995
Loss of batch at epoch 22 : 0.49498450756073
Loss of batch at epoch 22 : 0.4799498915672302
Loss of batch at epoch 22 : 0.44011956453323364
Loss of batch at epoch 22 : 0.4830700159072876
Loss of batch at epoch 22 : 0.47598907351493835
Loss of batch at epoch 22 : 0.5059469938278198
Loss of batch at epoch 22 : 0.501154899597168
Loss of batch at epoch 22 : 0.4857110381126404
Loss of batch at epoch 22 : 0.528407633304596
Loss of batch at epoch 22 : 0.45927226543426514
Loss of batch at epoch 22 : 0.4564669728279114
Loss of batch at epoch 22 : 0.44217947125434875
Loss of batch at epoch 22 : 0.47582805156707764
Loss of batch at epoch 22 : 0.47786378860473633
Loss of batch at epoch 22 : 0.4761563539505005
Loss of batch at epoch 22 : 0.46854251623153687
Loss of batch at epoch 22 : 0.46644169092178345
Loss of batch at epoch 22 : 0.49835824966430664
Loss of batch at epoch 22 : 0.4926053583621979
Loss of batch at epoch 22 : 0.4477674663066864
Average train loss of epoch 22: 0.009844220868681152
Average validation loss of epoch 22: 0.010248074226507836
Loss of batch at epoch 23 : 0.4459223449230194
Loss of batch at epoch 23 : 0.47688278555870056
Loss of batch at epoch 23 : 0.4825766682624817
Loss of batch at epoch 23 : 0.4311425983905792
Loss of batch at epoch 23 : 0.47555023431777954
Loss of batch at epoch 23 : 0.46532294154167175
Loss of batch at epoch 23 : 0.48814335465431213
Loss of batch at epoch 23 : 0.45776551961898804
Loss of batch at epoch 23 : 0.5112916827201843
Loss of batch at epoch 23 : 0.4530734717845917
Loss of batch at epoch 23 : 0.5139210820198059
Loss of batch at epoch 23 : 0.44073426723480225
Loss of batch at epoch 23 : 0.4728379249572754
Loss of batch at epoch 23 : 0.46389040350914
Loss of batch at epoch 23 : 0.5001568794250488
Loss of batch at epoch 23 : 0.45987722277641296
Loss of batch at epoch 23 : 0.4447489082813263
Loss of batch at epoch 23 : 0.46657320857048035
Loss of batch at epoch 23 : 0.4346286356449127
Loss of batch at epoch 23 : 0.5004028677940369
Loss of batch at epoch 23 : 0.4985711872577667
Loss of batch at epoch 23 : 0.5351874828338623
Loss of batch at epoch 23 : 0.47264495491981506
Loss of batch at epoch 23 : 0.5136804580688477
Loss of batch at epoch 23 : 0.4723241925239563
Loss of batch at epoch 23 : 0.44333207607269287
Loss of batch at epoch 23 : 0.4708160161972046
Loss of batch at epoch 23 : 0.46650710701942444
Loss of batch at epoch 23 : 0.4999169409275055
Loss of batch at epoch 23 : 0.5241990685462952
Loss of batch at epoch 23 : 0.49122172594070435
Loss of batch at epoch 23 : 0.4904356300830841
Loss of batch at epoch 23 : 0.4822692573070526
Loss of batch at epoch 23 : 0.4648837745189667
Loss of batch at epoch 23 : 0.4843660295009613
Loss of batch at epoch 23 : 0.46934372186660767
Loss of batch at epoch 23 : 0.43403658270835876
Loss of batch at epoch 23 : 0.46900245547294617
Loss of batch at epoch 23 : 0.4923064112663269
Loss of batch at epoch 23 : 0.49371322989463806
Loss of batch at epoch 23 : 0.4845993220806122
Loss of batch at epoch 23 : 0.4549926817417145
Loss of batch at epoch 23 : 0.48299774527549744
Loss of batch at epoch 23 : 0.5338729023933411
Loss of batch at epoch 23 : 0.49651384353637695
Loss of batch at epoch 23 : 0.45245224237442017
Loss of batch at epoch 23 : 0.5116280913352966
Loss of batch at epoch 23 : 0.453697144985199
Loss of batch at epoch 23 : 0.4696115553379059
Loss of batch at epoch 23 : 0.4790492355823517
Loss of batch at epoch 23 : 0.47876545786857605
Loss of batch at epoch 23 : 0.5020665526390076
Loss of batch at epoch 23 : 0.4816358685493469
Loss of batch at epoch 23 : 0.5137249231338501
Average train loss of epoch 23: 0.00965265269774479
Average validation loss of epoch 23: 0.0102938706625993
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 5590175.0 ON gcn50 CANCELLED AT 2024-03-19T01:15:07 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 5590175 ON gcn50 CANCELLED AT 2024-03-19T01:15:07 DUE TO TIME LIMIT ***
slurmstepd: error: container_p_join: open failed for /slurm/5590175/.ns: No such file or directory
slurmstepd: error: container_g_join(5590175): No such file or directory

JOB STATISTICS
==============
Job ID: 5590175
Cluster: snellius
User/Group: scur0756/scur0756
State: TIMEOUT (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:10
CPU Efficiency: 0.00% of 6-00:07:48 core-walltime
Job Wall-clock time: 08:00:26
Memory Utilized: 100.74 GB
Memory Efficiency: 27.98% of 360.00 GB
