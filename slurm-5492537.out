wandb: Currently logged in as: r-v-doorn1 (royvdoorn). Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.
  warnings.warn(
Loss of batch at epoch 1 : 0.9181942343711853
Loss of batch at epoch 1 : 0.9113262891769409
Loss of batch at epoch 1 : 0.9033259153366089
Loss of batch at epoch 1 : 0.8920485973358154
Loss of batch at epoch 1 : 0.8881925344467163
Loss of batch at epoch 1 : 0.8945592641830444
Loss of batch at epoch 1 : 0.8891192078590393
Loss of batch at epoch 1 : 0.8820322751998901
Loss of batch at epoch 1 : 0.8867174983024597
Loss of batch at epoch 1 : 0.8871033191680908
Loss of batch at epoch 1 : 0.887542724609375
Loss of batch at epoch 1 : 0.8829951286315918
Loss of batch at epoch 1 : 0.8866015672683716
Loss of batch at epoch 1 : 0.8835147619247437
Loss of batch at epoch 1 : 0.8777098655700684
Loss of batch at epoch 1 : 0.8861654996871948
Loss of batch at epoch 1 : 0.8808547854423523
Loss of batch at epoch 1 : 0.8786793947219849
Loss of batch at epoch 1 : 0.8818182945251465
Loss of batch at epoch 1 : 0.8821187019348145
Loss of batch at epoch 1 : 0.8852001428604126
Loss of batch at epoch 1 : 0.8734726905822754
Loss of batch at epoch 1 : 0.8844271898269653
Loss of batch at epoch 1 : 0.8786769509315491
Loss of batch at epoch 1 : 0.8808985352516174
Loss of batch at epoch 1 : 0.8777180910110474
Loss of batch at epoch 1 : 0.8778163194656372
Loss of batch at epoch 1 : 0.8789803385734558
Loss of batch at epoch 1 : 0.8742026090621948
Loss of batch at epoch 1 : 0.8784918189048767
Loss of batch at epoch 1 : 0.8701543807983398
Loss of batch at epoch 1 : 0.8779370188713074
Loss of batch at epoch 1 : 0.8777864575386047
Loss of batch at epoch 1 : 0.8726593255996704
Loss of batch at epoch 1 : 0.877894937992096
Loss of batch at epoch 1 : 0.8704195022583008
Loss of batch at epoch 1 : 0.871971845626831
Loss of batch at epoch 1 : 0.8762120008468628
Loss of batch at epoch 1 : 0.875174880027771
Loss of batch at epoch 1 : 0.8751001358032227
Loss of batch at epoch 1 : 0.8724349737167358
Loss of batch at epoch 1 : 0.8757044672966003
Loss of batch at epoch 1 : 0.8788304328918457
Loss of batch at epoch 1 : 0.8776136636734009
Loss of batch at epoch 1 : 0.8718802332878113
Loss of batch at epoch 1 : 0.8656243085861206
Loss of batch at epoch 1 : 0.8766210079193115
Loss of batch at epoch 1 : 0.8799803256988525
Loss of batch at epoch 1 : 0.8711078763008118
Loss of batch at epoch 1 : 0.8679084777832031
Loss of batch at epoch 1 : 0.8850430250167847
Loss of batch at epoch 1 : 0.8716576099395752
Loss of batch at epoch 1 : 0.8698625564575195
Loss of batch at epoch 1 : 0.8743353486061096
Loss of batch at epoch 1 : 0.872633159160614
Loss of batch at epoch 1 : 0.8790680170059204
Loss of batch at epoch 1 : 0.8737415075302124
Loss of batch at epoch 1 : 0.8748300075531006
Loss of batch at epoch 1 : 0.8747542500495911
Loss of batch at epoch 1 : 0.8742241859436035
Loss of batch at epoch 1 : 0.871318519115448
Loss of batch at epoch 1 : 0.8761870861053467
Loss of batch at epoch 1 : 0.8680821061134338
Loss of batch at epoch 1 : 0.8713108897209167
Loss of batch at epoch 1 : 0.8728442192077637
Loss of batch at epoch 1 : 0.8736447095870972
Loss of batch at epoch 1 : 0.8660750389099121
Loss of batch at epoch 1 : 0.8728700280189514
Loss of batch at epoch 1 : 0.8688191771507263
Loss of batch at epoch 1 : 0.8727004528045654
Loss of batch at epoch 1 : 0.8660657405853271
Loss of batch at epoch 1 : 0.868911862373352
Loss of batch at epoch 1 : 0.8718000054359436
Loss of batch at epoch 1 : 0.874153733253479
Loss of batch at epoch 1 : 0.868438184261322
Loss of batch at epoch 1 : 0.8729653358459473
Loss of batch at epoch 1 : 0.8748101592063904
Loss of batch at epoch 1 : 0.8745829463005066
Loss of batch at epoch 1 : 0.8722469806671143
Loss of batch at epoch 1 : 0.8690860271453857
Loss of batch at epoch 1 : 0.8712208867073059
Loss of batch at epoch 1 : 0.876392662525177
Loss of batch at epoch 1 : 0.8769161105155945
Loss of batch at epoch 1 : 0.8697130084037781
Loss of batch at epoch 1 : 0.8693556785583496
Loss of batch at epoch 1 : 0.8694884777069092
Loss of batch at epoch 1 : 0.8739181756973267
Loss of batch at epoch 1 : 0.8746423125267029
Loss of batch at epoch 1 : 0.8748517036437988
Loss of batch at epoch 1 : 0.8743327856063843
Loss of batch at epoch 1 : 0.8725520968437195
Loss of batch at epoch 1 : 0.8695071339607239
Loss of batch at epoch 1 : 0.8743191957473755
Loss of batch at epoch 1 : 0.8752577900886536
Loss of batch at epoch 1 : 0.8740699291229248
Loss of batch at epoch 1 : 0.8713867664337158
Loss of batch at epoch 1 : 0.8655034899711609
Loss of batch at epoch 1 : 0.8752334117889404
Loss of batch at epoch 1 : 0.8683691024780273
Loss of batch at epoch 1 : 0.8704257011413574
Loss of batch at epoch 1 : 0.8678219318389893
Loss of batch at epoch 1 : 0.8646471500396729
Loss of batch at epoch 1 : 0.8759511709213257
Loss of batch at epoch 1 : 0.869252622127533
Loss of batch at epoch 1 : 0.8671734929084778
Loss of batch at epoch 1 : 0.8659243583679199
Loss of batch at epoch 1 : 0.8665852546691895
Loss of batch at epoch 1 : 0.8775967955589294
[2024-03-09 13:05:09,716] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -9) local_rank: 0 (pid: 381477) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
train.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-03-09_13:05:09
  host      : gcn9.local.snellius.surf.nl
  rank      : 0 (local_rank: 0)
  exitcode  : -9 (pid: 381477)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 381477
=======================================================
slurmstepd: error: Detected 1 oom_kill event in StepId=5492537.0. Some of the step tasks have been OOM Killed.
srun: error: gcn9: task 0: Out Of Memory
srun: Terminating StepId=5492537.0

JOB STATISTICS
==============
Job ID: 5492537
Cluster: snellius
User/Group: scur0756/scur0756
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 05:22:12 core-walltime
Job Wall-clock time: 00:17:54
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 180.00 GB (10.00 GB/core)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
