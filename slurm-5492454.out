wandb: Currently logged in as: r-v-doorn1 (royvdoorn). Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:43: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.
  warnings.warn(
Loss of batch at epoch 1 : 0.9125273823738098
Loss of batch at epoch 1 : 0.9108324646949768
Loss of batch at epoch 1 : 0.8999574184417725
Loss of batch at epoch 1 : 0.8922865986824036
Loss of batch at epoch 1 : 0.8966341614723206
Loss of batch at epoch 1 : 0.8884060382843018
Loss of batch at epoch 1 : 0.8838929533958435
Loss of batch at epoch 1 : 0.8915135860443115
Loss of batch at epoch 1 : 0.8874301910400391
Loss of batch at epoch 1 : 0.886237621307373
Loss of batch at epoch 1 : 0.8903351426124573
Loss of batch at epoch 1 : 0.8779656887054443
Loss of batch at epoch 1 : 0.8863179087638855
Loss of batch at epoch 1 : 0.8804485201835632
Loss of batch at epoch 1 : 0.8835148215293884
Loss of batch at epoch 1 : 0.8809126615524292
Loss of batch at epoch 1 : 0.8868680000305176
Loss of batch at epoch 1 : 0.8836197853088379
Loss of batch at epoch 1 : 0.883398175239563
Loss of batch at epoch 1 : 0.8866377472877502
Loss of batch at epoch 1 : 0.878936767578125
Loss of batch at epoch 1 : 0.8868532180786133
Loss of batch at epoch 1 : 0.8773735761642456
Loss of batch at epoch 1 : 0.8835977911949158
Loss of batch at epoch 1 : 0.8790701627731323
Loss of batch at epoch 1 : 0.8856787085533142
Loss of batch at epoch 1 : 0.8773746490478516
Loss of batch at epoch 1 : 0.8739396929740906
Loss of batch at epoch 1 : 0.8838917016983032
Loss of batch at epoch 1 : 0.8771271705627441
Loss of batch at epoch 1 : 0.8769697546958923
Loss of batch at epoch 1 : 0.877944827079773
Loss of batch at epoch 1 : 0.8791405558586121
Loss of batch at epoch 1 : 0.8786725401878357
Loss of batch at epoch 1 : 0.8766676187515259
Loss of batch at epoch 1 : 0.8807494044303894
Loss of batch at epoch 1 : 0.8769059777259827
Loss of batch at epoch 1 : 0.8717718124389648
Loss of batch at epoch 1 : 0.874341607093811
Loss of batch at epoch 1 : 0.8726897835731506
Loss of batch at epoch 1 : 0.8753899335861206
Loss of batch at epoch 1 : 0.8725256323814392
Loss of batch at epoch 1 : 0.8774300813674927
Loss of batch at epoch 1 : 0.8735640048980713
Loss of batch at epoch 1 : 0.8704989552497864
Loss of batch at epoch 1 : 0.8755203485488892
Loss of batch at epoch 1 : 0.8791272044181824
Loss of batch at epoch 1 : 0.874758243560791
Loss of batch at epoch 1 : 0.8828741312026978
Loss of batch at epoch 1 : 0.8770738244056702
Loss of batch at epoch 1 : 0.879096508026123
Loss of batch at epoch 1 : 0.8703482151031494
Loss of batch at epoch 1 : 0.8751242756843567
Loss of batch at epoch 1 : 0.8732601404190063
Loss of batch at epoch 1 : 0.8732380270957947
Loss of batch at epoch 1 : 0.876897394657135
Loss of batch at epoch 1 : 0.8785192370414734
Loss of batch at epoch 1 : 0.8704291582107544
Loss of batch at epoch 1 : 0.8736735582351685
Loss of batch at epoch 1 : 0.8744820952415466
Loss of batch at epoch 1 : 0.8716003894805908
Loss of batch at epoch 1 : 0.8656792640686035
Loss of batch at epoch 1 : 0.8704893589019775
Loss of batch at epoch 1 : 0.8729039430618286
Loss of batch at epoch 1 : 0.8716269731521606
Loss of batch at epoch 1 : 0.8815973997116089
Loss of batch at epoch 1 : 0.8837206363677979
Loss of batch at epoch 1 : 0.8740277886390686
Loss of batch at epoch 1 : 0.8747364282608032
Loss of batch at epoch 1 : 0.8713734149932861
Loss of batch at epoch 1 : 0.8731939792633057
Loss of batch at epoch 1 : 0.8782609105110168
Loss of batch at epoch 1 : 0.8754488229751587
Loss of batch at epoch 1 : 0.8708208203315735
Loss of batch at epoch 1 : 0.8702247142791748
Loss of batch at epoch 1 : 0.8841003179550171
Loss of batch at epoch 1 : 0.8738505244255066
Loss of batch at epoch 1 : 0.8704948425292969
Loss of batch at epoch 1 : 0.8690066337585449
Loss of batch at epoch 1 : 0.8731725811958313
Loss of batch at epoch 1 : 0.871260404586792
Loss of batch at epoch 1 : 0.8682863712310791
Loss of batch at epoch 1 : 0.8737775683403015
Loss of batch at epoch 1 : 0.8786458969116211
Loss of batch at epoch 1 : 0.87571120262146
Loss of batch at epoch 1 : 0.8739228844642639
Loss of batch at epoch 1 : 0.8691403865814209
Loss of batch at epoch 1 : 0.8733018040657043
Loss of batch at epoch 1 : 0.8782362937927246
Loss of batch at epoch 1 : 0.8803964257240295
Loss of batch at epoch 1 : 0.8728953003883362
Loss of batch at epoch 1 : 0.8712627291679382
Loss of batch at epoch 1 : 0.8762011528015137
Loss of batch at epoch 1 : 0.8737640380859375
Loss of batch at epoch 1 : 0.8671906590461731
Loss of batch at epoch 1 : 0.8759405016899109
Loss of batch at epoch 1 : 0.8734453320503235
Loss of batch at epoch 1 : 0.8705970048904419
Loss of batch at epoch 1 : 0.8667129278182983
Loss of batch at epoch 1 : 0.8786261677742004
Loss of batch at epoch 1 : 0.8770025968551636
Loss of batch at epoch 1 : 0.8751357197761536
Loss of batch at epoch 1 : 0.876386284828186
Loss of batch at epoch 1 : 0.8691170811653137
Loss of batch at epoch 1 : 0.867149293422699
Loss of batch at epoch 1 : 0.8715824484825134
Loss of batch at epoch 1 : 0.8651649951934814
Loss of batch at epoch 1 : 0.8737637996673584
[2024-03-09 11:59:02,069] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -9) local_rank: 0 (pid: 788138) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/local/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 806, in main
    run(args)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py", line 797, in run
    elastic_launch(
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
train.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-03-09_11:59:02
  host      : gcn22.local.snellius.surf.nl
  rank      : 0 (local_rank: 0)
  exitcode  : -9 (pid: 788138)
  error_file: <N/A>
  traceback : Signal 9 (SIGKILL) received by PID 788138
=======================================================
slurmstepd: error: Detected 1 oom_kill event in StepId=5492454.0. Some of the step tasks have been OOM Killed.
srun: error: gcn22: task 0: Out Of Memory
srun: Terminating StepId=5492454.0

JOB STATISTICS
==============
Job ID: 5492454
Cluster: snellius
User/Group: scur0756/scur0756
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 05:01:48 core-walltime
Job Wall-clock time: 00:16:46
Memory Utilized: 0.00 MB (estimated maximum)
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
WARNING: Efficiency statistics may be misleading for RUNNING jobs.
